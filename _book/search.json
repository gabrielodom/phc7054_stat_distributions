[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Primer on Statistical Distributions",
    "section": "",
    "text": "Preface\n\nThis is a Quarto book. To learn more about Quarto books visit https://quarto.org/docs/books.\n\nThis is a collection of notes about deriving basic properties of statistical distributions. I tried to write it so that a student who has had 2-3 semesters of undergraduate calculus can understand. It’s not deeply theoretical, but it does include theory.\nThere are probably mistakes in derivations and typos in formulas. As with anything you find on the internet, buyer beware. This is a free website, so–as the old saying goes–“you get what you pay for”.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html",
    "href": "chapters/bernoulli_20250310.html",
    "title": "1  The Bernoulli Distribution",
    "section": "",
    "text": "1.1 Deriving the Distribution\nIn the mid-1600s, mathematicians like Pascal and Fermat were obsessed with games of chance.1 The simplest such game is flipping a single coin. Let \\(P[A]\\) denote the probability of event \\(A\\) occurring. Because flipping a coin has only two outcomes (heads or tails; we ignore the microscopic possibility of a coin landing on its edge for practical gambling scenarios), we can define \\(p \\equiv P[\\text{head}]\\), which necessarily implies that \\(1 - p = P[\\text{tails}]\\). For ease of notation, we let \\(k\\in\\{0,1\\} = 1\\) when the coin hands on leads and \\(k = 0\\) for tails. Thus, we define a Bernoulli Trial as one random value drawn from the following distribution: \\[\nf_{\\text{Bern}}(k|p) = p^k(1-p)^{1-k},\\ k\\in\\{0,1\\},\\ p \\in (0,1) \\subset \\mathbb{R}.\n\\]\nNotice a few things:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#deriving-the-distribution",
    "href": "chapters/bernoulli_20250310.html#deriving-the-distribution",
    "title": "1  The Bernoulli Distribution",
    "section": "",
    "text": "The Bernoulli Probability Mass Function is denoted \\(f_{\\text{Bern}}\\); \\(f\\) is a function, and its argument \\(k\\) is discrete. The domain of \\(f\\) is 0 or 1 (\\(k\\) can only have the values in the set \\(\\mathcal{S} = \\{0,1\\}\\)).\nFor any \\(k \\in \\mathcal{S}\\), \\(f(k|p) \\ge 0\\); this is the range of \\(f\\). This means that \\(f\\) maps from the set \\(\\mathcal{S}\\) to the set of all non-negative real numbers, which is symbolically denoted as \\(f:\\mathcal{S} \\to \\mathbb{R}_{\\ge}\\).\nThe probability of a “head” (success) is the only parameter of \\(f\\), and it is fixed at some value \\(p\\), which must be a real number between 0 and 1.\n\n\n1.1.1 An Example Sample from the Bernoulli Distribution\nNow let’s use R to take \\(n = 100\\) random samples from a Bernoulli Distribution with \\(p = 0.35\\), but we will only inspect the first five (for now):\n\nmyBernSample &lt;- rbinom(n = 100, size = 1, prob = 0.35)\nmyBernSample[1:5]\n[1] 1 0 0 1 0\n\nWe now pretend that we only know the results for the first five coin flips. We have flipped one coin five times, with the results \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#example-random-samples",
    "href": "chapters/bernoulli_20250310.html#example-random-samples",
    "title": "1  The Bernoulli Distribution",
    "section": "1.2 Example Random Samples",
    "text": "1.2 Example Random Samples\nWe now take some random samples from this distribution when \\(p = 0.5\\).\n\n\nCode\nset.seed(20150516)\n\nx &lt;- rbinom(n = 100, size = 1, prob = 0.5)\nsamples_ls &lt;- list(\n  n5   = x[1:5],\n  n15  = x[1:15],\n  n30  = x[1:30],\n  n100 = x\n)\n\nrm(x)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samples_ls$n5)\nhist(samples_ls$n15)\nhist(samples_ls$n30)\nhist(samples_ls$n100)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#formal-foundations",
    "href": "chapters/bernoulli_20250310.html#formal-foundations",
    "title": "1  The Bernoulli Distribution",
    "section": "1.3 Formal Foundations",
    "text": "1.3 Formal Foundations\n\n1.3.1 The Riemann-Stieltjes Integral\nLet \\(f\\) be a bounded function on the interval \\(\\mathcal{S} = [a, b] \\subset \\mathbb{R}\\), and let \\(G\\) be a monotone increasing (but not necessarily continuous) function on \\(\\mathcal{S}\\). The Riemann-Stieltjes integral of \\(f\\) with respect to \\(G\\) is denoted as \\[\n\\text{R-S}(f, G) \\equiv \\int_{x \\in \\mathcal{S}} f(x) \\text{d}G(x).\n\\] If \\(G\\) is continuous \\(\\forall x \\in \\mathcal{S}\\), then this integral simplifies to \\[\n\\int_{x \\in \\mathcal{S}} f(x) \\text{d}G(x) = \\int_{x \\in \\mathcal{S}} f(x) G^{\\prime}(x).\n\\] If, however, there exists \\(k &lt; m &lt; \\infty\\) points of discontinuity for \\(G\\) on \\(\\mathcal{S}\\), we define an \\(m\\)-partition of \\(\\mathcal{S}\\) as \\(\\{[y_0, y_1), [y_1, y_2), \\ldots, [y_{m - 2}, y_{m - 1}), [y_{m - 1}, y_m]\\}\\), where \\(\\{a = y_0, b = y_m\\}\\) and the \\(k\\) points of discontinuity are included in the sequence \\(\\{y_1, y_2, \\ldots, y_{m - 1}\\}\\). Then, this integral simplifies to \\[\n\\int_{x \\in \\mathcal{S}} f(x) \\text{d}G(x) = \\sum\\limits_{i = 1}^m f(x)\\left[ G(y_i) - G(y_{i - 1}) \\right].\n\\]\n\n\n1.3.2 Properties of Distributions\nLet \\(x\\) be an observed value \\(\\in \\mathcal{A}\\), and let \\(\\boldsymbol\\theta\\) be a vector of parameters in a parameter space \\(\\boldsymbol\\Theta \\subseteq \\mathbb{R}^q\\). Consider a function \\(f(\\textbf{x}|\\boldsymbol\\theta)\\) with anti-derivative \\(F\\), and note that \\(f\\) need not be continuous. This \\(f\\) represents a probability distribution iff2\n\n\\(\\forall x \\in \\mathcal{S}\\), \\(\\forall \\boldsymbol\\theta \\in \\boldsymbol\\Theta\\), \\(f(x|\\boldsymbol\\theta) \\ge 0\\).\n\\(\\forall \\boldsymbol\\theta \\in \\boldsymbol\\Theta\\), \\(\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) = 1\\), where \\(\\text{d}F\\) is the integrand of a Riemann-Stieltjes integral.\n\nAs long as (1) holds above, then \\(F\\) will be monotone increasing (because the anti-derivative of a non-negative function will always be flat or increasing). The probability density/mass functions for all statistical distributions share these two properties above. Because of the flexibility of the Riemann-Stieltjes integral, we don’t have to make the distinction between probability density functions and probability mass functions any longer. This is because\n\nIf \\(\\mathcal{S}\\) is a discrete set with cardinality \\(|\\mathcal{S}| = n\\), \\(f\\) is commonly referred to as a probability “mass” function. Then, because (1) holds, \\(\\exists\\) some ordering of the elements of \\(\\mathcal{S} \\ni 0 \\le F(x^{(1)}) \\le F(x^{(2)}) \\le \\cdots \\le F(x^{(n)}) \\le 1\\). We know that the total probability of all events is 1, and the total probability of no events is 0, so, by convention, we let \\(F(x^{(n)}) = 1\\) and \\(F(x^{(0)}) = 0\\). Thus, noticing the Telescoping Series3, \\[\n\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) = \\sum\\limits_{i = 1}^n F(x^{(i)}) - F(x^{(i - 1)}) = F(x^{(n)}) - F(x^{(0)}) = 1.\n\\]\nIf \\(\\mathcal{S} = [a,b]\\) is a continuous set, then \\(f\\) is a probability “density” function. For this continuous range, \\(F(a) = 0\\) and \\(F(b) = 1\\). Thus, \\[\n\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) = \\int_a^b F^{\\prime}(x) = F(b) - F(a) = 1.\n\\]\n\nThus, for the remainder of these notes, we will start all integral-based definitions with the Riemann-Stieltjes form, and then reduce this form into traditional sums or integrals, as is appropriate for the distribution at hand.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/bernoulli_20250310.html#show-that-this-is-a-distribution",
    "title": "1  The Bernoulli Distribution",
    "section": "1.4 Show that this is a Distribution",
    "text": "1.4 Show that this is a Distribution\nGiven the extensive review above, showing that \\(f_{\\text{Bern}}\\) is a probability distribution is anti-climactic.\n\n1.4.1 The Distribution is Non-negative\nClaim: The function \\(f_{\\text{Bern}}\\) must be non-negative for all values of its support given \\(p\\) in the parameter space \\((0,1)\\).\nArgument: If \\(k = 0\\), then \\(f_{\\text{Bern}}(k = 0|p) = p^0(1 - p)^1 = 1 - p \\ge 0\\). Similarly, if \\(k = 1\\), then \\(f_{\\text{Bern}}(k = 1|p) = p^1(1 - p)^0 = p \\ge 0\\).\n\n\n1.4.2 The Total Probability is 1\nClaim: The integral of the function \\(f_{\\text{Bern}}\\) over all possible values of \\(k\\) must be 1.\nArgument: Consider that \\[\n\\begin{aligned}\n\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) &= \\sum\\limits_{k = 0}^1 f_{\\text{Bern}}(k|p) \\\\\n  &= \\left[ p^k(1-p)^{1-k} \\right]_{k = 0} + \\left[ p^k(1-p)^{1-k} \\right]_{k = 1} \\\\\n  &= [p^0(1-p)^1] + [p^1(1-p)^0] \\\\\n  &= (1 - p) + p \\\\\n  &= 1.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/bernoulli_20250310.html#derive-the-moment-generating-function",
    "title": "1  The Bernoulli Distribution",
    "section": "1.5 Derive the Moment Generating Function",
    "text": "1.5 Derive the Moment Generating Function\n\n1.5.1 Review: What is the MGF?\nThe Moment Generating Function4 (MGF) is, as its name implies, a function to “generate” (i.e., calculate) moments. In statistics, I have not found great intuition on what a “moment” is, other than it relates to various measures of a probability distribution:\n\nThe 0\\(^{\\text{th}}\\) moment is the total area of the probability distribution [or 1],\nThe 1\\(^{\\text{st}}\\) moment is the expected value,\nThe 2\\(^{\\text{nd}}\\) (central) moment is the variance,\nThe 3\\(^{\\text{rd}}\\) moment is the skewness, and\nThe 4\\(^{\\text{th}}\\) moment is the kurtosis.\n\nPhysics has more intuition of moments, where the 1\\(^{\\text{st}}\\) moment is the center of mass for a body (the point at which you could balance the shape on a pencil) and the 2\\(^{\\text{nd}}\\) moment is the moment of inertia (how much mass is spread out away from the axis at the center of mass, where larger values mean the mass is spread out further away from the first moment).\nGiven a Cumulative Density Function \\(F_X(x|\\boldsymbol\\theta)\\), the MGF of \\(F_X\\) with respect to some value \\(t\\) in an \\(\\epsilon\\)-neighborhood5 of 0 is defined to be \\[\nM_X(t) \\equiv \\mathbb{E}\\left[ e^{tX} \\right] = \\int\\limits_{x \\in \\mathcal{S}(X)} e^{tx} \\text{d}F_X(x|\\boldsymbol\\theta),\n\\] where \\(\\text{d}F_X\\) is the integrand of a Riemann-Stieltjes integral (as discussed above).\nIf we have a distribution with \\(j\\) parameters, the process to calculate the first \\(j\\) moments is to take the first \\(j\\) derivatives of \\(M_X\\) and evaluate these functions (if they exist) at \\(t = 0\\). Then, these theoretical moments (functions of the distribution’s parameters \\(\\boldsymbol\\theta\\)) are set equal to the first \\(j = |\\boldsymbol\\theta|\\) sample moments, yielding a system of (often non-linear) equations to solve.\n\n\n1.5.2 MGF of the Bernoulli Distribution\nGiven the definition above, we can calculate the MGF: \\[\n\\begin{aligned}\nM_K(t) &\\equiv \\mathbb{E}\\left[ e^{tK} \\right] \\\\\n  &= \\int\\limits_{k \\in \\{0,1\\}} e^{tk} \\text{d}F_K(k|p) \\\\\n  &= \\sum\\limits_{k = 0}^1 e^{tk} p^k (1 - p)^{1 - k} \\\\\n  &= \\sum\\limits_{k = 0}^1 (pe^t)^k (1 - p)^{1 - k} \\\\\n  &= \\left[ (pe^t)^0 (1 - p)^1 \\right] + \\left[ (pe^t)^1 (1 - p)^0 \\right] \\\\\n  &= 1 - p + pe^t.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#method-of-moments-estimators",
    "href": "chapters/bernoulli_20250310.html#method-of-moments-estimators",
    "title": "1  The Bernoulli Distribution",
    "section": "1.6 Method of Moments Estimators",
    "text": "1.6 Method of Moments Estimators\nNow that we have the MGF of the Bernoulli Distribution, we follow the process to calculate the theoretical moment(s) and set them equal to their corresponding sample moment(s). Because the Bernoulli Distribution only has \\(j = 1\\) parameter, our systems to solve will be somewhat trivial.\n\n1.6.1 First Moment\nGiven the MGF calculated above, we begin with \\[\n\\begin{aligned}\nM_K(t) &= 1 - p + pe^t \\\\\n\\Longrightarrow\\qquad \\frac{\\partial}{\\partial t}M_K(t) &= pe^t \\\\\n\\Longrightarrow\\qquad \\frac{\\partial}{\\partial t}M_K(0) &= p \\\\\n&= \\mathbb{E}[X].\n\\end{aligned}\n\\]\n\n\n1.6.2 The Second Moment\nThe second (non-central) moment is then \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial t}M_K(t) &= pe^t \\\\ \\\\\n\\Longrightarrow\\qquad \\frac{\\partial^2}{\\partial t^2}M_K(t) &= pe^t \\\\\n\\Longrightarrow\\qquad \\frac{\\partial^2}{\\partial t^2}M_K(0) &= p \\\\\n&= \\mathbb{E}[X^2].\n\\end{aligned}\n\\]\nBecause this is the non-central moment, we find the second central moment by exploiting the common relationship between variance and moments; that is, \\[\n\\begin{aligned}\n\\text{Var}[X] &= \\mathbb{E}[X^2] - \\mathbb{E}^2[X] \\\\\n&= p - [p]^2 \\\\\n&= p(1 - p).\n\\end{aligned}\n\\]\n\n\n1.6.3 Solving the System\n\nFor distributions with two parameters, we would now equate these two population moments, \\(\\mathbb{E}[X]\\) and \\(\\text{Var}[X]\\), the two sample moments, \\(\\bar{x}\\) and \\(s^2\\), to yield the Method of Moments estimators for the two parameters of the distribution (which we will represent generically as \\(\\hat\\theta_{MoM}\\) and \\(\\hat\\phi_{MoM}\\)).\n\nHowever, the Bernoulli has only one parameter, so our “system” of equations is just \\[\n\\begin{aligned}\n\\bar{x} &= p \\\\\n\\Longrightarrow \\hat{p}_{MoM} &= \\bar{x}.\n\\end{aligned}\n\\] For the data observed above, the coin-flip results \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\) which came from a coin with \\(P[\\text{Heads}] = 0.35\\), \\(\\hat{p}_{MoM} = \\frac{1}{5}\\sum_{i = 1}^5 x_i = 0.4\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#the-likelihood-function",
    "href": "chapters/bernoulli_20250310.html#the-likelihood-function",
    "title": "1  The Bernoulli Distribution",
    "section": "1.7 The Likelihood Function",
    "text": "1.7 The Likelihood Function\nIn standard statistical inference, we assume that the population parameter is some fixed but unknown value and that our observed data are random; we must estimate the unknown (but fixed) parameter using statistics of the observed (but random) data. Likelihood functions (and the related Bayesian school of thought) turn this question “inside out”. The likelihood instead assumes that the parameter is a random variable (still unknown), but that the data are both observed and fixed.\n\n1.7.1 Reviewing the Repeated Sampling Paradigm\nLet’s recall the observed toy data: we flipped one coin five times and observed \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\). Is the coin fair? Traditional statistics would say “\\(p\\) is unknown, but if I can collect enough data then I can estimate it with a narrow confidence interval”. In a simple coin-flip example, this is reasonable: we can hire a person to repeatedly flip that same coin for hours and hours and record the results. Eventually, we will have a sample size large enough so that we can build a confidence interval small enough to say with any requested level of “confidence” that the coin is or isn’t fair.\nRecall the \\((1-\\alpha)\\)-level confidence interval for a Bernoulli \\(p\\) is \\[\n\\text{CI}(p|n,\\alpha) =\n  \\hat{p} \\pm \\frac{z_{\\alpha/2}}{\\sqrt{n}}\\sqrt{\\hat{p}(1 - \\hat{p})},\n\\] where \\(z_{\\alpha/2}\\) is the Standard Normal \\(z\\) corresponding to the quantiles \\(1 - \\alpha/2\\) and \\(\\alpha/2\\). As we saw above, the true parameter value was \\(p = 0.35\\), which (we remark) would be impossible to know in real life.\nWe will assume that we take each coin flip one at a time. How many times will we have to flip the coin before the 95% CI no longer contains 0.5?\n\n\nCode\nzAlpha &lt;- qnorm(p = 0.975)\nresults_ls &lt;- lapply(\n  X = seq.int(from = 2, to = length(myBernSample), by = 1),\n  FUN = function(n_i) {\n    \n    x &lt;- myBernSample[1:n_i]\n    pHat &lt;- mean(x)\n    CIwidth &lt;- ( zAlpha / sqrt(n_i) ) * sqrt( pHat * (1 - pHat) )\n    \n    data.frame(\n      N = n_i,\n      pHat = pHat,\n      CIlb = pHat - CIwidth,\n      CIub = pHat + CIwidth\n    )\n  }\n)\n\nresults_df &lt;- do.call(rbind, results_ls)\n\n# add trivial CI results for first coin flip\nresults_df &lt;- rbind(\n  data.frame(\n    N = 1, pHat = myBernSample[1],\n    CIlb = myBernSample[1], CIub = myBernSample[1]\n  ),\n  results_df\n)\n\n\nLet’s plot these results:\n\n\nCode\nlibrary(ggplot2)\nggplot(data = results_df) + \n  aes(x = N) +\n  ylim(c(0, 1)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  geom_abline(slope = 0, intercept = 0.5, colour = \"red\") + \n  geom_line(aes(y = CIlb)) + \n  geom_line(aes(y = CIub))\n\n\n\n\n\n\n\n\n\nAs we can see, we need between 85-90 coin flips before we can be 95% sure that the coin is “not fair” (that the true value of \\(p\\ne 0.5\\)). Also, we see that the confidence intervals are degenerate for a few of the samples with \\(n\\le 5\\) (that the bounds of the confidence interval for \\(p\\) are outside \\([0,1]\\), which is impossible).\n\n\n1.7.2 Making the Most Use of our Data\nFor the computer, flipping additional coins to create new data is trivially inexpensive. However, in real life, collecting one additional sample may be of enormous cost to the research team. In these cases, it doesn’t help us that we would theoretically be able to reject the claim that \\(p = 0.5\\) at some point in the future (with more samples), we need to be able to make a statement about the likelihood that the coin is fair with the samples we have right now. Let the event \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\) be encoded \\(\\textbf{x} = (1,0,1,0,0)\\). Thus, we apply the multiplication rule of independent events for these five coin flips, and define the likelihood function of \\(p\\) given the observed data:\n\\[\\begin{align}\n\\mathcal{L}(p|\\textbf{x}) &=\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 1} \\times\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 0} \\times \\\\\n  &\\qquad \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 1} \\times\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 0} \\times\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 0} \\\\\n  \n  &= \\left[ p^1 \\right] \\times \\left[ (1 - p)^1 \\right] \\times\n  \\left[ p^1 \\right] \\times \\left[ (1 - p)^1 \\right] \\times \\left[ (1 - p)^1 \\right] \\\\\n  &= p^2(1 - p)^3 \\\\\n  &= p^2(1 - 3p + 3p^2 - p^3) \\\\\n  &= p^2 - 3p^3 + 3p^4 - p^5.\n\\end{align}\\]\n\n\n1.7.3 Integrating the Likelihood\nThis function \\(\\mathcal{L}\\) contains almost all the information we have about \\(p\\): it has all the data, and it has our best guess about the data generating process (we think it’s a Bernoulli trial). A few things to notice:6\n\n\\(\\mathcal{L}\\) is a function of the parameter, \\(p\\), not of the data.\n\\(\\mathcal{L}\\) is NOT a probability function; even though \\(\\mathcal{L} \\ge 0\\ \\forall p\\), we have that the integral over the support of \\(p\\) is\n\n\\[\\begin{align}\n\\int_0^1 \\mathcal{L}(p|\\textbf{x})dp &=\n  \\int_0^1 \\left[ p^2 - 3p^3 + 3p^4 - p^5 \\right]dp \\\\\n  &= \\frac{1}{3}p^3 - \\frac{3}{4}p^4 + \\frac{3}{5}p^5 - \\frac{1}{6}p^6 \\Big\\rvert_0^1 \\\\\n  &= \\frac{1}{3} - \\frac{3}{4} + \\frac{3}{5} - \\frac{1}{6} \\\\\n  &= \\frac{20}{60} - \\frac{45}{60} + \\frac{36}{60} - \\frac{10}{60} \\\\\n  &= \\frac{1}{60} \\\\\n  &\\ne 1\n\\end{align}\\]\nThis exercise serves two purposes: first to show that \\(\\mathcal{L}\\) is not a probability distribution, and second to show the value of the multiplicative constant which would make a distribution. That is, \\(f(p|\\textbf{x}) = 60*\\mathcal{L}(p|\\textbf{x})\\) is a probability distribution. Now we can make probabilistic statements about the value of \\(p\\).\nWe can see what the probability distribution function looks like (it should look like a Beta distribution, because it is):\n\n\nCode\np &lt;- seq(from = 0, to = 1, length.out = 101)\nf_p &lt;- 60 * p^2 * (1 - p)^3\n\nplot(x = p, y = f_p)\n\n\n\n\n\n\n\n\n\nAnd since we have calculated the indefinite integral already, we can plot the Cumulative Distribution Function:\n\n\nCode\nF_p &lt;- 60 * (p^3/3 - 3*p^4/4 + 3*p^5/5 - p^6/6)\nplot(x = p, y = F_p)\n\n\n\n\n\n\n\n\n\nFinally, we can make statements about the claim that \\(p = 0.5\\). For instance, what is \\(P[p &lt; 0.5]\\)?\n\nF_p[which(p == 0.5)]\n[1] 0.656\n\nWhat is \\(P[p &gt; 0.5]\\)?\n\n1 - F_p[which(p == 0.5)]\n[1] 0.344\n\nWhat is \\(P[0.4 &lt; p &lt; 0.6]\\)?\n\nF_p[which(p == 0.6)] - F_p[which(p == 0.4)]\n[1] 0.365\n\nWhat is an 80% credible set7 for \\(p\\)?\n\n# Lower\np[max(which(F_p &lt; 0.1))]\n[1] 0.2\n# Upper\np[min(which(F_p &gt; 0.9))]\n[1] 0.67",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#maximum-likelihood-estimators-the-most-likely-value-of-p",
    "href": "chapters/bernoulli_20250310.html#maximum-likelihood-estimators-the-most-likely-value-of-p",
    "title": "1  The Bernoulli Distribution",
    "section": "1.8 Maximum Likelihood Estimators: The “Most Likely” Value of \\(p\\)",
    "text": "1.8 Maximum Likelihood Estimators: The “Most Likely” Value of \\(p\\)\nWe have an integrated likelihood, which contains basically almost all there is to know about the data we’ve collected, but finding a closed form of the integral of \\(\\mathcal{L}\\) (necessary to find \\(f\\) and \\(F\\)) can be impossible in most real-world scenarios. Rather than trying to answer all the questions about \\(p\\), sometimes it’s still worthwhile to answer “what is the most likely value of \\(p\\) given the data we’ve observed?”\nThis is answered with maximum likelihood estimation, and we need two steps. Using (multivariable) differential calculus, we\n\nfind the value of \\(\\boldsymbol\\theta\\) which maximizes \\(\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x})\\), and\nshow that \\(\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x})\\) is concave down8 at this point.\n\nFor the first step, it is common practice to 1) disregard any multiplicative constants leading \\(\\mathcal{L}\\) (because the derivative in the next step will zero these constants out) and 2) to take the natural logarithm of the likelihood and maximize that instead. Because logarithms simply change the scale of the vertical axis, they do not affect the location of extreme values. Let’s begin (I show what happens to the multiplicative constant in square brackets):\n\\[\\begin{align}\n\\mathcal{L}(p|\\textbf{x}) &= [60\\times]\\ p^2(1 - p)^3,\\ p\\in[0,1] \\\\\n\\Longrightarrow \\qquad \\ell(p|\\textbf{x}) &= [\\log(60) +]\\ 2\\log(p) + 3\\log(1 - p),\\ p\\in(0,1) \\\\\n\\Longrightarrow \\qquad \\frac{\\partial\\ell}{\\partial p} &= [0+]\\ \\frac{2}{p} - \\frac{3}{1 - p} \\\\\n\\Longrightarrow \\qquad 0 &\\overset{\\text{set}}{=} \\frac{2}{p} - \\frac{3}{1 - p} \\\\\n\\Longrightarrow \\qquad 0 &= 2(1 - p) - 3p \\\\\n\\Longrightarrow \\qquad \\hat{p} &= 2/5\n\\end{align}\\]\nThe second step is to confirm that \\(\\hat{p} = \\frac{2}{5}\\) is a maximum of \\(\\mathcal{L}\\), by ensuring that the second derivative of \\(\\mathcal{L}\\) is negative around \\(\\hat{p}\\). For that, we return to the first derivative of the log-likelihood (I’m using negative exponents instead of fractions because the chain rule is easier to apply than the quotient rule for these fractions), and differentiate again:\n\\[\\begin{align}\n\\frac{\\partial\\ell}{\\partial p} &= 2p^{-1} - 3(1 - p)^{-1} \\\\\n\\Longrightarrow \\qquad \\frac{\\partial^2\\ell}{\\partial p^2} &= -2p^{-2} + 3(1 - p)^{-2}\\times(-1) \\\\\n&= -\\left( \\frac{2}{p^2} + \\frac{3}{(1 - p)^2} \\right) &lt;0\\ \\forall p \\in (0,1).\n\\end{align}\\]\nSo, for this trivial example, both Method of Moments and Maximum Likelihood Estimation yielded the same estimate for \\(\\hat{p}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#exercises",
    "href": "chapters/bernoulli_20250310.html#exercises",
    "title": "1  The Bernoulli Distribution",
    "section": "1.9 Exercises",
    "text": "1.9 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#footnotes",
    "href": "chapters/bernoulli_20250310.html#footnotes",
    "title": "1  The Bernoulli Distribution",
    "section": "",
    "text": "https://www.usu.edu/math/schneit/StatsStuff/Probability/probability2.html↩︎\nif and only if↩︎\n(https://en.wikipedia.org/wiki/Telescoping_series)↩︎\nhttps://en.wikipedia.org/wiki/Moment-generating_function↩︎\n\\(t \\in (-\\epsilon, \\epsilon) \\subset \\mathbb{R}\\) (where \\(\\epsilon\\) is an arbitrarily small value)↩︎\nWe could also notice that this is the kernel of a Beta distribution with \\(\\alpha = 3\\) and \\(\\beta = 4\\), with normalizing constant \\(\\frac{(3-1)!(4-1)!}{(3+4-1)!} = \\frac{2}{6*5*4} = \\frac{1}{60}\\), but that would make the next steps too easy…↩︎\nhttps://en.wikipedia.org/wiki/Credible_interval↩︎\nhttps://tutorial.math.lamar.edu/classes/calci/shapeofgraphptii.aspx↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html",
    "href": "chapters/binomial_20250310.html",
    "title": "2  The Binomial Distribution",
    "section": "",
    "text": "2.1 Deriving the Distribution\nIn the previous chapter, we explored the properties of a Bernoulli trial. We envisioned a scenario where a person flipped a coin five times, and the results were \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\). What we knew, but the hypothetical person did no know, was that this particular coin was not “fair”. In fact, these five observations were drawn from a Bernoulli process with \\(P[\\text{Heads}] = 0.35\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#deriving-the-distribution",
    "href": "chapters/binomial_20250310.html#deriving-the-distribution",
    "title": "2  The Binomial Distribution",
    "section": "",
    "text": "2.1.1 A Primer on Exchangeability\nWhat if we saw \\(\\{\\)Heads, Tails, Tails, Heads, Tails\\(\\}\\) instead? The total number of heads and tails flipped is the same, but the order is different. Does that affect our estimate of \\(p\\)? In order to generalize this experiment a bit, we need to use the principle of exchangeability.1 The general idea of exchangeability is that the order of the observed flips doesn’t matter; i.e., that the coin doesn’t remember flipping a “Head” first then a “Tail”. Recall that we encoded the observed flips as \\(\\textbf{x} = (1,0,1,0,0)\\). Therefore, if the order doesn’t matter, then all these rows will give us the same information about \\(p\\):\n\n# Thanks to ChatGPT for finding this package for me.\ncquad::sq(J = 5, s = 2)\n      [,1] [,2] [,3] [,4] [,5]\n [1,]    0    0    0    1    1\n [2,]    0    0    1    0    1\n [3,]    0    0    1    1    0\n [4,]    0    1    0    0    1\n [5,]    0    1    0    1    0\n [6,]    0    1    1    0    0\n [7,]    1    0    0    0    1\n [8,]    1    0    0    1    0\n [9,]    1    0    1    0    0\n[10,]    1    1    0    0    0\n\nWe see that there are 10 rows here, showing the 10 ways that we could flip \\(| \\textbf{x}| = 5\\) coins sequentially and only see 2 heads2. While each of these rows shows the outcomes of different events, the resulting probability functions will be the same because of the commutative property of multiplication. That is, the likelihood function for the first row: \\[\n\\prod\\limits_{k = (0, 0, 0, 1, 1)} \\left[ p^{k_i}(1 - p)^{1 - k_i} \\right] = p^{\\sum_k k_i}(1 - p)^{\\sum_k (1 - k_i)} = p^2(1 - p)^3;\n\\] yields the same polynomial as the likelihood function for the last row: \\[\n\\prod\\limits_{k = (1, 1, 0, 0, 0)} \\left[ p^{k_i}(1 - p)^{1 - k_i} \\right] = p^{\\sum_k k_i}(1 - p)^{\\sum_k (1 - k_i)} = p^2(1 - p)^3.\n\\] The likelihood functions will be the same for all 10 rows.\n\n\n2.1.2 The Binomial Coefficient\nLet’s pretend that a prophet tells us that that the next time we flip \\(n = 5\\) coins we will see \\(k = 2\\) heads. We haven’t flipped any coins yet, but we have a vision of the future. If we encode 1 for heads and 0 for tails, we know that what is about to happen when we flip these 5 coins can be described by one of the 10 rows above. But how did we get there?\nTo make this process easier to explain, let’s flip 5 coins and leave them on the table, so that we can “see” our results as they happen. The 10 rows of the matrix above are based on the logic of this process:\n\nBefore I flip any coins, there are \\(n = 5\\) coins in my hand. I haven’t flipped any coins yet, so all my options are available. There are 5 ways to flip one head.\nI flip the first coin, and after I set that coin aside, I have \\(n - 1 = 4\\) coins left for me to flip. There are still 4 ways to flip one head.\nI flip the second coin, and set it aside. I now have \\(n - 2 = 3\\) coins left to flip. There are 3 ways left to flip one head.\nI flip the third coin, and set it aside. Now things get interesting: I have \\(n = k = 2\\) coins left. If I have already flipped two heads in the first three flips, then I know the next two flips must be tails. If I haven’t flipped any heads in the first three flips, then I know the next two flips must be heads. If I’ve only flipped one head in the first three flips, then I know that one of the two next flips will be heads and the other will be tails (but I don’t know which is which).\nI flip the fourth coin and set it aside. The prophet already told me there would only be 2 heads in 5 flips, so the next flip is completely determined. If I have already flipped 2 heads with the first four coins, then this flip MUST be tails. If I’ve only flipped 1 head on the first four coins, then this flip MUST be heads. There is only one possible outcome, and it is predetermined to occur.\n\nIf we hadn’t been told by a prophet ahead of time that we would see two heads, then there would be \\(n\\) options for the first flip (I haven’t decided which coin to pick up yet, so that’s why I have 5 choices), \\(n - 1\\) for the second, all the way down to 1 way to flip at the end. That tells us there are \\(n!\\) ways these flips could have happened. There would have been \\(5\\times 4\\times 3\\times 2 = 120 = n!\\) (this \\(\\\\!\\) symbol denotes the factorial3 of an integer) possible orderings and configurations of heads and tails. However, in our process, we’ve already assumed exchangeability, so the order of the flips does not matter. Not only that, but we are further limited: the prophet informed us that we MUST see exactly \\(k = 2\\) heads and \\(n - k = 3\\) tails. Because we use multiplication to “add” new possibilities, we must use division to take away these excluded possibilities. Since we must have \\(k = 2\\) heads, we remove 2 opportunities to flip tails; since we must have \\(n - k = 3\\) tails, we remove 3 opportunities to flip heads. Therefore, the number of options will be: \\[\n\\frac{|\\text{all results}|}{|\\text{removed tails results}| \\times |\\text{removed heads results}|} = \\frac{5!}{2!\\times 3!} = \\frac{120}{2 \\times 6} = 10.\n\\]\n\nWe then define the Binomial Coefficient as \\[\n{n \\choose k} \\equiv \\frac{n!}{k!(n - k)!}.\n\\]\n\n\n2.1.3 Constructing the Distribution\nTo recap, we now have:\n\na statement about the likelihood of a single binary event, of which \\(k = 1\\) denotes one class and \\(k = 0\\) denotes its complement (the other binary class): \\(p^k(1 - p)^{1 - k}\\),\nan experiment that yields a set of \\(n\\) such independent and exchangeable binary events, and\na way to count all the ways that these events could possibly occur: \\(\\frac{n!}{k!(n - k)!}\\).\n\nLet us assume that the number of trials, \\(n\\), is known. We will now construct a probability function for the random variable \\(k = 0, 1, \\ldots, n\\). We still assume independence and exchangeability, so the probability of success, \\(p\\), is fixed. Then, this function will first have a the binomial coefficient, then the probability to observe \\(k\\) successes, and finally the probability to observe \\(n - k\\) failures. Thus, the Binomial Distribution is:\n\\[\nf(k|n,p) \\equiv {n \\choose k} p^{k}(1 - p)^{n - k}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#example-random-samples",
    "href": "chapters/binomial_20250310.html#example-random-samples",
    "title": "2  The Binomial Distribution",
    "section": "2.2 Example Random Samples",
    "text": "2.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nN &lt;- 10\nbins_int &lt;- seq.int(from = -1, to = N, by = 1)\n\nxSymm &lt;- rbinom(n = 100, size = N, prob = 0.5)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n15  = xSymm[1:15],\n  n30  = xSymm[1:30],\n  n100 = xSymm\n)\n\nxSkew &lt;- rbinom(n = 100, size = N, prob = 0.2)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n15  = xSkew[1:15],\n  n30  = xSkew[1:30],\n  n100 = xSkew\n)\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSymm_ls$n5, breaks = bins_int)\nhist(samplesSymm_ls$n15, breaks = bins_int)\nhist(samplesSymm_ls$n30, breaks = bins_int)\nhist(samplesSymm_ls$n100, breaks = bins_int)\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSkew_ls$n5, breaks = bins_int)\nhist(samplesSkew_ls$n15, breaks = bins_int)\nhist(samplesSkew_ls$n30, breaks = bins_int)\nhist(samplesSkew_ls$n100, breaks = bins_int)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#formal-foundations",
    "href": "chapters/binomial_20250310.html#formal-foundations",
    "title": "2  The Binomial Distribution",
    "section": "2.3 Formal Foundations",
    "text": "2.3 Formal Foundations\n\n2.3.1 Pascal’s Rule\nFor writing proofs involving combinations, we need the following property, known as Pascal’s Formula,4 which states that\n\\[\n{a \\choose b} = {a - 1 \\choose b} + {a - 1 \\choose b - 1}.\n\\]\nProof: For integers \\(a,b\\), we construct this identity directly via simplification: \\[\n\\begin{aligned}\n{a - 1 \\choose b} + {a - 1 \\choose b - 1} &=\n  \\frac{(a - 1)!}{b!(a - b - 1)!} + \\frac{(a - 1)!}{(b - 1)!(a - 1 - b + 1)!} \\\\\n  &= \\frac{a - b}{a - b}\\left[ \\frac{(a - 1)!}{b!(a - b - 1)!} \\right] + \\frac{b}{b} \\left[ \\frac{(a - 1)!}{(b - 1)!(a - b)!} \\right] \\\\\n  &= \\frac{a(a - 1)! - b(a - 1)!}{b!(a - b)(a - b - 1)!} + \\frac{b(a - 1)!}{b(b - 1)!(a - b)!} \\\\\n  &= \\frac{a! - b(a - 1)!}{b!(a - b)!} + \\frac{b(a - 1)!}{b!(a - b)!} \\\\\n  &= \\frac{a!}{b!(a - b)!} \\\\\n  &\\equiv {a \\choose b}.\n\\end{aligned}\n\\]\n\n\n2.3.2 Mathematical Induction\nThe next foundational proof requires a technique called “Proof by Induction”, or more generally, mathematical induction.5 This is the structure of such a proof:\n\nProof by Induction: Consider a sequence of equations indexed over the integers by \\(n\\). To show that the sequence of equations is true \\(\\forall n\\), we\n\nshow that the equation is true for \\(n = 1\\) [the “base case”],\nassume that the equation is true for \\(n = i\\) [the “hypothesis”], then\nprove that the equation is true for \\(n = i + 1\\) from the case when \\(n = i\\) [the “induction”].\n\n\nHere is a trivial example. Let’s prove \\(\\forall k \\in\\mathbb{N} \\ge 5\\) that \\(2^k &lt; \\Gamma(k + 1)\\) (the point of this proof is to show that the factorial function increases more rapidly to \\(\\infty\\) than the exponential function). Our base case is for \\(k = 5\\). We know that \\(2^5 = 32\\) and \\(\\Gamma(k + 1) = k! = 5! = 120\\). Because \\(32 &lt; 120\\), the base case is true. Our hypothesis, what we assume to be true, is that \\(2^i &lt; \\Gamma(i + 1)\\). To logically induct, we assume our hypothesis is true, and then show that our hypothesis implies that \\(2^{i + 1} &lt; \\Gamma(i + 2)\\). That is \\[\n\\begin{aligned}\n2^{i+1} &\\overset{?}{&lt;} \\Gamma(i + 2) \\\\\n\\Longrightarrow 2 \\times 2^i &\\overset{?}{&lt;} i \\times \\Gamma(i + 1) \\\\\n\\Longrightarrow \\frac{2}{i} \\times 2^i &&lt; \\Gamma(i + 1),\n\\end{aligned}\n\\] which is true for \\(i \\ge 5\\) because our hypothesis was that \\(2^i &lt; \\Gamma(i + 1)\\). Thus, \\(2^k &lt; \\Gamma(k + 1)\\ \\forall k \\in\\mathbb{N} \\ge 5\\), which completes our proof.\n\n\n2.3.3 Mathematical Induction Proof of the Binomial Theorem\nFor this section, we will also need to use the Binomial Theorem:6\n\\[\n(x +  y)^n = \\sum_{k = 0}^n {n \\choose k} x^k y^{n - k}.\n\\]\nBefore we can use this, we must prove that it is true.\n\n2.3.3.1 The Base Case\nLet \\(n = 1\\). Then\n\\[\n\\begin{aligned}\n\\sum_{k = 0}^1 {1 \\choose k} x^k y^{1 - k} &=\n  \\left[ {1 \\choose 0} x^0 y^{1 - 0} \\right] + \\left[ {1 \\choose 1} x^1 y^{1 - 1} \\right] \\\\\n  &= \\frac{1!}{0!\\times 1!} (1) y^1 + \\frac{1!}{1!\\times 0!} x^1(1) \\\\\n  &= y + x \\\\\n  &= (x + y)^1.\n\\end{aligned}\n\\]\n\n\n2.3.3.2 The Hypothesis\nWe assume that this equation is true for \\(n = i\\). That is, we assume that\n\\[\n\\sum_{k = 0}^i {i \\choose k} x^k y^{i - k} = (x + y)^i.\n\\]\n\n\n2.3.3.3 The Induction\nAssuming that the hypothesis for \\(n = i\\) is true, we will show that the equation also holds for \\(n = i + 1\\). Note that the end of the proof requires Pascal’s Rule to combine sums of combinations, and we comment that there is only one way to “choose” 0 things or all things. Thus,\n\\[\n\\begin{aligned}\n(x + y)^i &= \\sum_{k = 0}^i {i \\choose k} x^k y^{i - k} \\\\\n\\Longrightarrow (x + y)^{i + 1} &= (x + y)\\sum_{k = 0}^i {i \\choose k} x^k y^{i - k} \\\\\n  &= (x + y)\\left[ {i \\choose 0} x^0 y^{i - 0} + {i \\choose 1} x^1 y^{i - 1} + \\ldots + {i \\choose i - 1} x^{i - 1} y^1 + {i \\choose i} x^{i - 0} y^0 \\right] \\\\\n  &= x\\left[ {i \\choose 0} x^0 y^i + {i \\choose 1} x^1 y^{i - 1} + \\ldots + {i \\choose i - 1} x^{i - 1} y^1 + {i \\choose i} x^i y^0 \\right] + \\\\\n  &\\quad\\ \\  y\\left[ {i \\choose 0} x^0 y^i + {i \\choose 1} x^1 y^{i - 1} + \\ldots + {i \\choose i - 1} x^{i - 1} y^1 + {i \\choose i} x^i y^0 \\right] \\\\\n  &= \\left[ {i \\choose 0} x^1 y^i + {i \\choose 1} x^2 y^{i - 1} + \\ldots + {i \\choose i - 1} x^i y^1 + {i \\choose i} x^{i+1} y^0 \\right] + \\\\\n  &\\quad\\  \\left[ {i \\choose 0} x^0 y^{i + 1} + {i \\choose 1} x^1 y^i + \\ldots + {i \\choose i - 1} x^{i - 1} y^2 + {i \\choose i} x^i y^1 \\right] \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{Collect like terms...}} \\\\\n  &= {i \\choose 0} x^0 y^{i + 1} + \\\\\n  &\\qquad \\left[ {i \\choose 0} x^1 y^i + {i \\choose 1} x^1 y^i\\right] + \\ldots + \\left[ {i \\choose i - 1} x^i y^1 + {i \\choose i} x^i y^1 \\right] + \\\\\n  &\\qquad {i \\choose i} x^{i+1} y^0 \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{Only one way to choose all or none...}} \\\\\n  &= (1) x^0 y^{i + 1} + \\\\\n  &\\qquad \\left[ {i \\choose 0} + {i \\choose 1} \\right]x^1 y^i + \\ldots + \\left[ {i \\choose i - 1} + {i \\choose i} \\right]x^i y^1 + \\\\\n  &\\qquad (1) x^{i+1} y^0 \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{Pascal's Rule...}} \\\\\n  &= (1) x^0 y^{i + 1} + \\\\\n  &\\qquad \\left[ {i + 1 \\choose 1} \\right]x^1 y^i + \\ldots + \\left[ {i + 1 \\choose i} \\right]x^i y^1 + \\\\\n  &\\qquad (1) x^{i+1} y^0 \\\\\n  &= {i + 1 \\choose 0} x^0 y^{i + 1} + {i + 1 \\choose 1}x^1 y^i + \\ldots + {i + 1 \\choose i}x^i y^1 + {i + 1 \\choose i + 1} x^{i+1} y^0 \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{By definition...}} \\\\\n  &= \\sum_{k = 0}^{i + 1} {i + 1 \\choose k} x^k y^{i + 1 - k}.\n\\end{aligned}\n\\]\nTherefore, \\(\\forall n \\in \\mathbb{N}\\), \\[\n\\sum_{k = 0}^n {n \\choose k} x^k y^{n - k} = (x + y)^n.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/binomial_20250310.html#show-that-this-is-a-distribution",
    "title": "2  The Binomial Distribution",
    "section": "2.4 Show that this is a Distribution",
    "text": "2.4 Show that this is a Distribution\nLet \\(\\mathcal{S} = \\mathbb{N} \\cup 0\\), where \\(\\mathbb{N}\\) denotes the set of natural numbers.7 Let \\(f(k|n,p) = {n \\choose k} p^{k}(1 - p)^{n - k}\\) represent the probability function of the Binomial Distribution. We must now show that\n\n\\(\\forall k \\in \\mathcal{S}\\), and for \\(p \\in (0,1)\\), \\(f(k|n, p) \\ge 0\\), and\nfor \\(p \\in (0,1)\\), \\(\\int_{k \\in \\mathcal{S}} \\text{d}F(k|n,p) = 1\\).\n\n\n2.4.1 The Distribution is Non-negative\nConsider \\(f\\) defined above. First, we notice that the Binomial Coefficient is defined as a ratio of factorials; the standard definition of factorials only includes the natural numbers (\\(\\mathbb{N}\\)), so they are necessarily positive. The ratio of two positive numbers is positive. Second, we have that \\(k,\\ n - k \\ge 0\\), and that \\(p &gt; 0\\). Non-negative powers of positive numbers are also positive. Setting \\(p = 0\\) yields a degenerate distribution anyway, so we don’t bother with it. Putting these together for \\(p \\in (0,1)\\), we have that \\(f = 0\\) outside the support of \\(k\\) and \\(f &gt; 0\\) for \\(k \\le n, \\ni \\{k,\\ n\\} \\in \\mathcal{S}\\).\n\n\n2.4.2 The Total Probability is 1\nRecall the Binomial Theorem we proved above, and let \\(x = p\\) and \\(y = 1 - p\\). Then, \\[\n\\begin{aligned}\n\\int_{k \\in \\mathcal{S}} \\text{d}F(k|n,p) &= \\sum_{k = 0}^n {n \\choose k} p^{k}(1 - p)^{n - k} \\\\\n  &= \\left[ p + (1 - p) \\right]^n \\\\\n  &= 1^n \\\\\n  &= 1.\n\\end{aligned}\n\\]\nTherefore, because the function \\(f(k|n,p)\\) is always non-negative and it’s Riemann-Stieljes integral is 1, the Binomial Distribution is a true distribution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/binomial_20250310.html#derive-the-moment-generating-function",
    "title": "2  The Binomial Distribution",
    "section": "2.5 Derive the Moment Generating Function",
    "text": "2.5 Derive the Moment Generating Function\nDeriving the MGF for the Binomial is a straightforward application of the definition and Binomial Theorem. That is, \\[\n\\begin{aligned}\nM_k(t) &\\equiv \\mathbb{E}\\left[ e^{tX} \\right] \\\\\n  &= \\int\\limits_{k \\in \\mathcal{S}(K)} e^{tk} \\text{d}F_K(k|n,p) \\\\\n  &= \\sum\\limits_{k = 0}^n e^{tk} {n \\choose k} p^{k}(1 - p)^{n - k} \\\\\n  &= \\sum\\limits_{k = 0}^n {n \\choose k} \\left[e^t\\right]^k p^{k}(1 - p)^{n - k} \\\\\n  &= \\sum\\limits_{k = 0}^n {n \\choose k} \\left[e^tp\\right]^k (1 - p)^{n - k} \\\\\n  &= \\left[ e^tp + (1 - p) \\right]^n.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#method-of-moments-estimators",
    "href": "chapters/binomial_20250310.html#method-of-moments-estimators",
    "title": "2  The Binomial Distribution",
    "section": "2.6 Method of Moments Estimators",
    "text": "2.6 Method of Moments Estimators\nNow that we have this MGF, we can find the Method of Moments (MoM) estimator for \\(p\\), and we will comment on such an estimator for \\(n\\) when it is unknown.\n\n2.6.1 The First Moment\nWe have that \\[\n\\begin{aligned}\nM_k(t) &= \\left[ e^tp + (1 - p) \\right]^n \\\\\n\\Longrightarrow M^{\\prime}_k(t) &= \\frac{\\partial}{\\partial t} \\left[ e^tp + (1 - p) \\right]^n \\\\\n  &= n \\left[ e^tp + (1 - p) \\right]^{n - 1} \\frac{\\partial}{\\partial t} \\left[ e^tp + (1 - p) \\right] \\\\\n  &= n \\left[ e^tp + (1 - p) \\right]^{n - 1} e^tp \\\\\n\\Longrightarrow M^{\\prime}_k(0) &= n \\left[ (1)p + (1 - p) \\right]^{n - 1} (1)p \\\\\n  &= n(1)^{n - 1}p \\\\\n  &= np.\n\\end{aligned}\n\\] Therefore, \\(\\mathbb{E}[k] = np\\).\n\n\n2.6.2 The Second Non-Central Moment\nTaking the second derivative with respect to \\(t\\), we have \\[\n\\begin{aligned}\nM^{\\prime}_k(t) &= ne^tp \\left[ e^tp + (1 - p) \\right]^{n - 1} \\\\\n\\Longrightarrow M^{\\prime\\prime}_k(t) &= ne^tp \\frac{\\partial}{\\partial t} \\left[ e^tp + (1 - p) \\right]^{n - 1} + \\left[ e^tp + (1 - p) \\right]^{n - 1} \\frac{\\partial}{\\partial t} ne^tp \\\\\n  &= ne^tp \\times (n - 1) \\left[ e^tp + (1 - p) \\right]^{n - 2} e^tp + \\left[ e^tp + (1 - p) \\right]^{n - 1} ne^tp \\\\\n\\Longrightarrow M^{\\prime\\prime}_k(0) &= n(1)p \\times (n - 1) \\left[ (1)p + (1 - p) \\right]^{n - 2} (1)p + \\left[ (1)p + (1 - p) \\right]^{n - 1} n(1)p \\\\\n  &= np^2 (n - 1) (1)^{n - 2} + np (1)^{n - 1} \\\\\n  &= np \\left[(n - 1)p + 1\\right].\n\\end{aligned}\n\\] Therefore, \\(\\mathbb{E}[k^2] = np(np - p + 1)\\).\n\n\n2.6.3 The Second Central Moment\nThus \\[\n\\begin{aligned}\n\\text{Var}[k] &= \\mathbb{E}[k^2] - \\left(\\mathbb{E}[k]\\right)^2 \\\\\n  &= np(np - p + 1) - \\left( np \\right)^2 \\\\\n  &= np \\left[ np - p + 1 - np \\right] \\\\\n  &= np (1 - p).\n\\end{aligned}\n\\]\n\nTechnically, we don’t need the second central moment for this distribution to find the Method of Moments estimators, but it is good practice.\n\n\n\n2.6.4 Solving the System of Equations\nNow that we have the first two population moments, \\(\\mathbb{E}[k]\\) and \\(\\text{Var}[k]\\), we can set them equal to the first two sample moments. That is, we solve the system \\[\n\\left\\{ \\mathbb{E}[k] = \\frac{1}{N} \\sum_{i = 1}^N k_i;\\ \\mathbb{E}[k^2] = \\frac{1}{N} \\sum_{i = 1}^N k_i^2 \\right\\},\n\\] where \\(N\\) is the number of Bernoulli trials in each Binomial experiment and \\(k_i\\) is the number of successes out of \\(N\\) attempts in Binomial experiment \\(i\\). For our example data, we were discussing the first such experiment, with observed data \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\); so we are on Binomial experiment \\(i\\), the number of coin flips was \\(N = 5\\), and we observed \\(k_i = 2\\) heads.\nGiven repeated \\(n\\) Binomial experiments of \\(N\\) Bernoulli trials each, we then solve the following system of equations: \\[\n\\left\\{ np = \\frac{1}{N} \\sum_{i = 1}^N k_i;\\ np(np - p + 1) = \\frac{1}{N} \\sum_{i = 1}^N k_i^2 \\right\\}.\n\\] Very often, \\(n\\) is known, so this simplifies to solving \\(\\hat{p}_{MoM} = \\frac{1}{nN} \\sum_{i = 1}^N k_i\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "2  The Binomial Distribution",
    "section": "2.7 Method of Moments Estimates from Observed Data",
    "text": "2.7 Method of Moments Estimates from Observed Data\nRecall our “observed” data: \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\). This was an observation from 5 independent Bernoulli trials or only ONE Binomial experiment with \\(N=5\\) and \\(k = 2\\). We need more than \\(n = 1\\) if we want to estimate moments! If you remember the introduction, we generated this data from a Bernoulli process with \\(p = 0.35\\). Let’s generate some more samples, this time we will have \\(n = 7\\) experiments where we flipped \\(N = 5\\) coins each time, with the same probability of success \\(p = 0.35\\) as before:\n\n\nCode\n# Reset our seed\nset.seed(20150516)\n\n# Generate our sample\nobserved_int &lt;- rbinom(\n  n = 7,      # number of Binomial experiments\n  size = 5,   # number of Bernoulli Trials per experiment\n  prob = 0.35 # probability of success for each Bernoulli Trial\n)\n\n# Inspect\nobserved_int\n[1] 3 1 2 3 1 0 1\n\n\nFor these 7 Binomial trials (each with 5 flips), we observed the following number of heads: 3, 1, 2, 3, 1, 0, 1.\n\n2.7.1 Case When \\(n\\) is Known\nThis is the most common case. Recall that we need the averages of \\(k_i\\) and \\(k_i^2\\), so let’s calculate these first.\n\n\nCode\nk_df &lt;- \n  tibble(k = observed_int) %&gt;% \n  mutate(k2 = k^2)\nk_df\n# A tibble: 7 × 2\n      k    k2\n  &lt;int&gt; &lt;dbl&gt;\n1     3     9\n2     1     1\n3     2     4\n4     3     9\n5     1     1\n6     0     0\n7     1     1\n\nkBar_num &lt;- colMeans(k_df)\nkBar_num\n   k   k2 \n1.57 3.57 \n\n\nSo, \\(\\frac{1}{7} \\sum_i k_i\\) = 1.5714286 and \\(\\frac{1}{7} \\sum_i k_i^2\\) = 3.5714286. Thus, the two equations in our system are\n\n\\(np\\) = 1.571\n\\(np(np - p + 1)\\) = 3.571\n\nHowever, we already said that \\(n = 5\\) is known, so we don’t need the second equation. All we have to solve is \\(np = (5)p = 1.571 \\Rightarrow \\hat{p}_{MoM} = 0.314\\).\n\n2.7.1.1 Case When \\(n\\) is Unknown\nThis is a rare case, and usually only a theoretical exercise, though it can happen in ecological studies of species. One example could be where a park ranger goes deep into the woods on 5 different days. While on patrol, they encounter one grey wolf on the first day, none on the second, one on the third, and none on the fourth and fifth. In this case, we still have \\(|\\text{Count of observed wolves}| = |\\textbf{x}| = \\{1, 0, 1, 0, 0\\}\\). In this case, we don’t actually know how many grey wolves are in the park close enough to the ranger to even be detected. Thus, we could think about this as 5 Binomial trials with unknown \\(n\\).\nNow, we have the same system as above, but it is no longer trivial. We know that the ranger went out on \\(n = 5\\) days, and we know that \\(\\sum_i k_i = \\sum_i k_i^2 = 2\\). So, by simplifying the first equation, we have that: \\[\n\\begin{aligned}\nnp &= \\frac{1}{N}\\sum_i k_i \\\\\n\\Longrightarrow (5)p &= \\frac{1}{N}(2) \\\\\n\\Longrightarrow Np &= 0.4\\\\\n\\Longrightarrow p &= \\frac{0.4}{N} \\\\\n\\Longrightarrow np &= 5\\left( \\frac{0.4}{N} \\right) \\\\\n&= \\frac{2}{N}.\n\\end{aligned}\n\\]\nWe substitute these known quantities into the second equation: \\[\n\\begin{aligned}\nnp(np - p + 1) &= \\frac{1}{N}\\sum_i k_i^2\\\\\n\\Longrightarrow \\left( \\frac{2}{N} \\right) \\left(\\left[ \\frac{2}{N} \\right] - \\left[ \\frac{0.4}{N} \\right] + 1\\right) &= \\frac{1}{N}(2) \\\\\n\\Longrightarrow \\left(\\left[ \\frac{2}{N} \\right] - \\left[ \\frac{0.4}{N} \\right] + 1\\right) &= 1 \\\\\n\\Longrightarrow 2 - 0.4 = 0,\n\\end{aligned}\n\\] so we see that no analytic solutions exist to estimate \\(N\\) here! I recommend that students read the primer from DasGupta and Rubin (2004) at this juncture.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/binomial_20250310.html#maximum-likelihood-estimators",
    "title": "2  The Binomial Distribution",
    "section": "2.8 Maximum Likelihood Estimators",
    "text": "2.8 Maximum Likelihood Estimators\n\n2.8.1 The Likelihood Function\nLet’s continue our example of 7 Binomial trials with 5 flips each during which we observed \\(\\textbf{k}\\) = 3, 1, 2, 3, 1, 0, 1 heads. In this case, we know that \\(n = 5\\) and \\(N = 7\\), so the Likelihood of \\(p\\) given \\(\\textbf{k}\\) is \\[\n\\begin{aligned}\n\\mathcal{L}(p|\\textbf{k}, n) &= \\prod\\limits_{i = 1}^{N = 7} {n \\choose k_i} p^{k_i} (1 - p)^{n - k_i} \\\\\n&= \\left[ {5 \\choose 3} p^3 (1 - p)^{5 - 3} \\right] \\times \\left[ {5 \\choose 1} p^1 (1 - p)^{5 - 1} \\right] \\times \\left[ {5 \\choose 2} p^2 (1 - p)^{5 - 2} \\right] \\times \\left[ {5 \\choose 3} p^3 (1 - p)^{5 - 3} \\right] \\times \\\\\n&\\qquad \\left[ {5 \\choose 1} p^1 (1 - p)^{5 - 1} \\right] \\times \\left[ {5 \\choose 0} p^0 (1 - p)^{5 - 0} \\right] \\times \\left[ {5 \\choose 1} p^1 (1 - p)^{5 - 1} \\right] \\\\\n&= {5 \\choose 3}{5 \\choose 1}{5 \\choose 2}{5 \\choose 3}{5 \\choose 1}{5 \\choose 0}{5 \\choose 1} p^{11} (1 - p)^{7\\times 5 - 11}.\n\\end{aligned}\n\\]\nNote that all the Binomial Coefficient terms in the beginning are just multiplicative constants. The real “action” is happening in the \\(p^{11}(1 - p)^{35 - 11}\\) part; this is known as the kernel8 of the likelihood. How do we know this? Because \\(x\\)-value locations of the the extreme values of \\(cf(x)\\) are the same as the \\(x\\)-value locations for the extreme values of \\(f(x)\\).\nProof: Let \\(f\\) be a differentiable function with \\(M\\) extreme values given by \\(\\{(x_1, f(x_1)), (x_2, f(x_2)), \\ldots, (x_M, f(x_M))\\}\\). Therefore, for \\(i = 1, 2, \\ldots, M\\), \\(f^{\\prime}(x_i) = 0\\). Therefore, for any constant \\(c &lt; \\infty\\), \\(cf^{\\prime}(x_i) = 0\\). Hence, the extreme values of \\(cf(x)\\) are \\(\\{(x_1, cf(x_1)), (x_2, cf(x_2)), \\ldots, (x_M, cf(x_M))\\}\\).\nTherefore, it is commonplace to write the likelihood as a proportional relationship, \\[\n\\mathcal{L}(p|\\textbf{k}, n) \\propto p^{11} (1 - p)^{24},\n\\] where \\(\\propto\\) is read “is proportional to”.\nThis kernel function is of incredible importance: \\(\\mathcal{L}\\) contains almost all the information known about \\(p\\). It has all the data and it also has our best guess of the data generating process (a Binomial process in this case). However, we note that \\(\\mathcal{L}\\) is not a probability distribution of \\(p\\). If it was, then we could make probabalistic statements about the values of \\(p\\) which generated the observed data \\(\\textbf{k}\\).\n\n\n2.8.2 A Probability Function of \\(p\\)\nHow can I so sure that \\(\\mathcal{L}\\) is not a probability distribution? It’s clearly non-negative, so let’s find out what it integrates to. That is, \\[\n\\begin{aligned}\n\\int_0^1 \\mathcal{L}(p|\\textbf{k},n)dp &= \\int_0^1 {5 \\choose 3}{5 \\choose 1}{5 \\choose 2}{5 \\choose 3}{5 \\choose 1}{5 \\choose 0}{5 \\choose 1} p^{11} (1 - p)^{24}dp \\\\\n&= C(5, \\textbf{k}) \\int_0^1 p^{11} (1 - p)^{24} dp,\n\\end{aligned}\n\\] where \\(C(5, \\textbf{k})\\) is the constant product of the seven Binomial Coefficients. Further, while we have not yet derived this distribution, for \\(x \\in (0,1)\\), \\(x^A(1 - x)^B\\) is the kernel of a Beta distribution with \\(A = \\alpha - 1\\) and \\(B = \\beta - 1\\). That is \\[\nf_{\\text{Beta}}(p|\\alpha,\\beta) \\equiv \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p^{\\alpha - 1}(1 - p)^{\\beta - 1}.\n\\] Since the Beta distribution is a statistical distribution, we know that its integral over \\((0,1)\\) is equal to 1. Therefore, \\[\n\\begin{aligned}\n\\int_0^1 \\mathcal{L}(p|\\textbf{k},n)dp &= C(5, \\textbf{k}) \\int_0^1 p^{12 - 1} (1 - p)^{25 - 1} dp \\\\\n&= C(5, \\textbf{k}) \\int_0^1 \\frac{\\Gamma(12)\\Gamma(25)}{\\Gamma(12 + 25)} \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} p^{12 - 1} (1 - p)^{25 - 1} dp \\\\\n&= C(5, \\textbf{k}) \\frac{\\Gamma(12)\\Gamma(25)}{\\Gamma(12 + 25)} \\int_0^1 f_{\\text{Beta}}(p|\\alpha = 12,\\beta = 25) dp \\\\\n&= C(5, \\textbf{k}) \\frac{\\Gamma(12)\\Gamma(25)}{\\Gamma(12 + 25)},\n\\end{aligned}\n\\] which is clearly not equal to 1. But, this effort is not in vain, because it yields the multiplicative constant that makes \\(\\mathcal{L}\\) into a probability function of \\(p\\). That is, \\[\n\\begin{aligned}\nf(p|\\textbf{k}, n = 5) &= \\frac{1}{C(5, \\textbf{k})} \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} \\mathcal{L}(p|\\textbf{k},n = 5) \\\\\n&= \\frac{1}{C(5, \\textbf{k})} \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} C(5, \\textbf{k}) p^{12 - 1} (1 - p)^{25 - 1} \\\\\n&= \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} p^{12 - 1} (1 - p)^{25 - 1} \\\\\n&= f_{\\text{Beta}}(p|\\alpha = 12,\\beta = 25).\n\\end{aligned}\n\\] We can use this distribution to estimate the probability that \\(p\\) is fair. For example, a fair coin with the same total number of flips (35) would have a Beta distribution with \\(\\alpha = \\beta = (35 + 2)/2 = 18.5\\). Under such a distribution, the probability that \\(p \\in (0.4, 0,6)\\) is calculated by:\n\n\nCode\npbeta(q = 0.6, shape1 = 18.5, shape2 = 18.5) - \n  pbeta(q = 0.4, shape1 = 18.5, shape2 = 18.5)\n[1] 0.778\n\n\nThat is, if we had observed balanced data with the same sample sizes, then \\(\\mathbb{P}[0.4 &lt; p &lt; 0.6] = 0.778\\). However, what we actually observed was that\n\n\nCode\npbeta(q = 0.6, shape1 = 12, shape2 = 25) - \n  pbeta(q = 0.4, shape1 = 12, shape2 = 25)\n[1] 0.162\n\n\nThus, given the data we actually observed, \\(\\mathbb{P}[0.4 &lt; p &lt; 0.6] = 0.162\\). In terms of pure probability, this statement can be interpreted as “given the data we observed, there is a 16% chance that the coin is fair”.\n\n\n2.8.3 Estimating the Most “Likely” Value\nWhile being able to describe the probability that the coin is “fair” is valuable, we often are interested in answering the question “what is the most likely value of \\(p\\) given the data we observed?” Now we are finally discussing maximum likelihood estimation. Given the data we observed, what value of \\(p\\) makes \\(\\mathcal{L}\\) attain its maximum value? We find a candidate value as follows: \\[\n\\begin{aligned}\n\\mathcal{L}(p|\\textbf{k},n) &= C(5, \\textbf{k}) p^{11} (1 - p)^{24} \\\\\n\\Longrightarrow \\ell(p|\\textbf{k},n) &= \\log \\left[ C(5, \\textbf{k}) \\right] + 11\\log p + 24\\log(1 - p) \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial p} \\ell(p|\\textbf{k},n) &= 0 + \\frac{11}{p} + \\frac{24}{1 - p}(-1) \\\\\n&= \\frac{11}{p} - \\frac{24}{1 - p} \\\\\n\\Longrightarrow 0 &\\overset{set}{=} \\frac{11}{\\hat{p}} - \\frac{24}{1 - \\hat{p}} \\\\\n&= 11(1 - \\hat{p}) - 24\\hat{p} \\\\\n&= 11 - 35\\hat{p} \\\\\n\\Longrightarrow \\hat{p}_{MLE} &= \\frac{11}{35} \\approx 0.314.\n\\end{aligned}\n\\] So we know that \\(\\mathcal{L}\\) attains an extreme value at \\(\\hat{p}_{MLE} = 0.314\\), but is it a maximum? We check this using the second derivative test: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial p} \\ell(p|\\textbf{k},n) &= \\frac{11}{p} - \\frac{24}{1 - p} \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial p^2} \\ell(p|\\textbf{k},n) &= -\\frac{11}{p^2} - (-1)\\frac{24}{(1 - p)^2}(-1) \\\\\n&= -\\left( \\frac{11}{p^2} + \\frac{24}{(1 - p)^2} \\right) \\\\\n&&lt; 0.\n\\end{aligned}\n\\] Therefore, \\(\\hat{p}_{MLE} = 0.314\\) is the Maximum Likelihood Estimator for \\(p\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#exercises",
    "href": "chapters/binomial_20250310.html#exercises",
    "title": "2  The Binomial Distribution",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#footnotes",
    "href": "chapters/binomial_20250310.html#footnotes",
    "title": "2  The Binomial Distribution",
    "section": "",
    "text": "Read all the pages of this short lesson, as it also includes a refresher on Riemann-Stieltjes Integrals: https://www.colorado.edu/amath/sites/default/files/attached-files/definetti.pdf↩︎\nThe symbol \\(|\\cdot|\\) represents the cardinality operator: https://en.wikipedia.org/wiki/Cardinality↩︎\nhttps://en.wikipedia.org/wiki/Factorial↩︎\nhttps://en.wikipedia.org/wiki/Pascal%27s_rule↩︎\nhttps://en.wikipedia.org/wiki/Mathematical_induction↩︎\nhttps://en.wikipedia.org/wiki/Binomial_theorem↩︎\nhttps://en.wikipedia.org/wiki/Natural_number↩︎\nSee the “Bayesian Statistics” section of the article on statistical kernels: https://en.wikipedia.org/wiki/Kernel_(statistics)↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html",
    "href": "chapters/negative_binomial_20250310.html",
    "title": "3  The Negative Binomial Distribution",
    "section": "",
    "text": "3.1 Deriving the Distribution\nConsider the outcomes of \\(n\\) independent and identical Bernoulli trials, \\(k_i \\overset{iid}{\\sim} \\text{Bern}(p),\\ \\forall i \\in \\{1, 2, \\ldots, n\\}\\). We play a game where we “win” as soon as we flip enough heads. We pretend that we have a time machine, and we travel forward in time until right before the exact Bernoulli trial in which the “winning” coin flip happens. For example, imagine a game where, as soon as we’ve flipped 5 heads total, we win. We hop in our time machine and travel forward until we are just about to flip the 5th head. Let \\(Y_n = \\sum_i k_i\\) be the (cumulative) count of successes so far in the game; for example, if we win at the \\(5^{\\text{th}}\\) heads flipped, then we would have already seen four heads flipped this game. Let \\(G_m\\) be the flip number in which we will observe the \\(m^{\\text{th}}\\) success (where \\(m \\ge 1\\)). The probability of winning the game on coin flip \\(m\\) is then \\[\n\\mathbb{P}[G_m = n] = \\mathbb{P}[Y_{n - 1} = m - 1]\\times\\mathbb{P}[k_n = 1];\n\\] that is, the probability we win the game now, on flip \\(n\\), is the probability that we’ve seen \\(m - 1\\) heads in the last \\(n - 1\\) flips, times the probability that the very next flip (flip \\(n\\)) will be a heads. Recall that \\(k_i \\overset{iid}{\\sim} \\text{Bern}(p)\\), so the probability that we saw \\(m - 1\\) successes in \\(n - 1\\) trials follows the Binomial distribution, where \\[\n\\mathbb{P}[Y_{n - 1} = m - 1] = {n - 1 \\choose m - 1} p^{m - 1} (1 - p)^{n - m}.\n\\] Since, by definition, \\(\\mathbb{P}[k_n = 1] = p\\), then \\[\n\\begin{aligned}\n\\mathbb{P}[G_m = n] &= {n - 1 \\choose m - 1} p^{m - 1} (1 - p)^{n - m} \\times p \\\\\n&= {n - 1 \\choose m - 1} p^{m} (1 - p)^{n - m},\n\\end{aligned}\n\\] which is a parametrization of the Negative Binomial Distribution.\nWhile using counts of successes in total Bernoulli trials (\\(m\\) successes out of \\(n\\) trials) offers a clear derivation of this distribution, most of the time the Negative Binomial distribution is parametrized in terms counts of successes, \\(r = m\\), and failures, \\(k = n - m\\). Thus, \\(n = k + r\\) and \\(m = r\\). So, for \\(k \\in \\{\\mathbb{N} \\cup 0\\}\\) and \\(r \\ge 1\\), \\[\n\\begin{aligned}\nf_{\\text{NB}}(m, n|p) &\\equiv {n - 1 \\choose m - 1} p^{m} (1 - p)^{n - m} \\\\\n\\Longrightarrow f_{\\text{NB}}(r, k|p) &= {k + r - 1 \\choose r - 1} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{(r - 1)!([k + r - 1] - [r - 1])!} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{(r - 1)!(k + r - 1 - r + 1)!} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{k!(r - 1)!} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{k!([k + r - 1] - k)!} p^{r} (1 - p)^{k} \\\\\n&= {k + r - 1 \\choose k} p^{r} (1 - p)^{k},\n\\end{aligned}\n\\] which is the more common form of the Negative Binomial distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#example-random-samples",
    "href": "chapters/negative_binomial_20250310.html#example-random-samples",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.2 Example Random Samples",
    "text": "3.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nN &lt;- 5\n\nxSymm &lt;- rnbinom(n = 500, size = N, prob = 0.5)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n30  = xSymm[1:30],\n  n100 = xSymm[1:100],\n  n500 = xSymm\n)\nbinsSymm_int &lt;- seq.int(from = -1, to = max(xSymm) + 1, by = 1)\n\nxSkew &lt;- rnbinom(n = 500, size = N, prob = 0.2)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n30  = xSkew[1:30],\n  n100 = xSkew[1:100],\n  n500 = xSkew\n)\nbinsSkew_int &lt;- seq.int(from = -1, to = max(xSkew) + 1, by = 1)\n# we are drawing until we reach N successes, so the upper limit should be \n# N * (1 / min(prob)) + epsilon\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSymm_ls$n5, breaks = binsSymm_int)\nhist(samplesSymm_ls$n30, breaks = binsSymm_int)\nhist(samplesSymm_ls$n100, breaks = binsSymm_int)\nhist(samplesSymm_ls$n500, breaks = binsSymm_int)\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSkew_ls$n5, breaks = binsSkew_int)\nhist(samplesSkew_ls$n30, breaks = binsSkew_int)\nhist(samplesSkew_ls$n100, breaks = binsSkew_int)\nhist(samplesSkew_ls$n500, breaks = binsSkew_int)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#formal-foundations",
    "href": "chapters/negative_binomial_20250310.html#formal-foundations",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.3 Formal Foundations",
    "text": "3.3 Formal Foundations\n\n3.3.1 Taylor/MacLaurin Series\nA Taylor (MacLaurin) Series expansion is a polynomial approximation of an \\(n\\)-differentiable real-valued function \\(f\\) around a point \\(a\\) (the MacLaurin Series is a special case when \\(a = 0\\)). Let \\(f^{(n)}(a)\\) denote the \\(n^{\\text{th}}\\) derivative of the function \\(f\\) evaluated at \\(a\\). Then the \\(n^{\\text{th}}\\)-order Taylor Series approximation of \\(f\\) in a neighbourhood of \\(a\\) is given by \\[\nf(x) \\approx f(a) + \\frac{f^{\\prime}(a)}{1!}(x - a)^1 + \\frac{f^{\\prime\\prime}(a)}{2!}(x - a)^2 + \\ldots + \\frac{f^{(n)}(a)}{n!}(x - a)^n.\n\\] If \\(f\\) is infinitely-differentiable, then this series can be continued in perpetuity, and the approximation becomes exact. That is \\[\nf(x) = \\sum_{n = 0}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x - a)^n.\n\\]\n\n\n3.3.2 Infinite Geometric Series\nFor a real number \\(|r| &lt; 1\\), the Geometric Series is the infinite-term MacLaurin Series form for the ratio below: \\[\n\\frac{b}{1 - r} = \\sum_{k = 0}^{\\infty} br^k.\n\\] Proof: We presented the definition of the Taylor Series for an infinitely-differentiable function \\(f\\) above. We need the functional form of the \\(n^{\\text{th}}\\) derivative of \\((1 - r)^{-1}\\) evaluated at an arbitrary point \\(a\\), where \\(|r| &lt; 1\\). These derivatives are given as \\[\n\\begin{align}\nf^{(0)}(a) &= (1 - a)^{-1} \\\\\nf^{(1)}(a) &= (-1)(1 - a)^{-2}(-1) =&  (1 - a)^{-2}\\\\\nf^{(2)}(a) &= (-2)(1 - a)^{-3}(-1) =& 2(1 - a)^{-3}\\\\\nf^{(3)}(a) &= (-3)(2)(1 - a)^{-4}(-1) =&  3\\times2(1 - a)^{-4}\\\\\nf^{(4)}(a) &= (-4)(3)(2)(1 - a)^{-5}(-1) =&  4!(1 - a)^{-5}\\\\\n\\vdots \\\\\nf^{(n)}(a) &= n!(1 - a)^{-(n + 1)}.\n\\end{align}\n\\] We evaluate these derivatives at \\(a = 0\\), yielding \\(f^{(n)}(0) = n!(1 - 0)^{-(n + 1)} = n!\\). Therefore, evaluating the MacLaurin Series for this ratio (the Taylor Series at \\(a = 0\\)) yields \\[\n\\begin{align}\nf(r) = \\frac{1}{1 - r} &= \\sum_{n = 0}^{\\infty} \\frac{f^{(n)}(0)}{n!}(r - 0)^n \\\\\n&= \\sum_{n = 0}^{\\infty} \\frac{\\left[ n! \\right]}{n!}  r^n \\\\\n&= \\sum_{n = 0}^{\\infty} r^n.\n\\end{align}\n\\] Hence, after changing the index of summation from \\(n\\) to \\(k\\) and multiplying both sides by \\(b\\), we have \\[\n\\frac{b}{1 - r} = \\sum_{k = 0}^{\\infty} br^k.\n\\]\n\n\n3.3.3 Newton’s Binomial Theorem\nNewton’s Binomial Theorem allows us to generalize the Infinite Geometric Series for \\(|r| &lt; 1\\) from exponents other than \\(-1\\) as follows1: \\[\nb(1 + r)^{\\alpha} = \\sum_{n = 0}^{\\infty} {\\alpha \\choose n} br^n.\n\\] Proof: We will follow the same MacLaurin Series derivation for \\((1 + r)^{\\alpha}\\) here as well, where the only major difference is that we have \\(+r\\) instead of \\(-r\\). The \\(n\\) derivatives evaluated at \\(r = r_0\\) are then \\[\n\\begin{align}\nf^{(0)}(r_0) &= (1 + r_0)^{\\alpha} \\\\\nf^{(1)}(r_0) &= (\\alpha)(1 + r_0)^{\\alpha - 1} \\\\\nf^{(2)}(r_0) &= (\\alpha)(\\alpha - 1)(1 + r_0)^{\\alpha - 2} \\\\\nf^{(3)}(r_0) &= (\\alpha)(\\alpha - 1)(\\alpha - 2)(1 + r_0)^{\\alpha - 3} \\\\\n\\vdots \\\\\nf^{(n)}(r_0) &= \\left[ (\\alpha)(\\alpha - 1)(\\alpha - 2) \\ldots (\\alpha - n + 1) \\right] (1 + r_0)^{\\alpha - n} \\\\\n&= \\left[ (\\alpha)(\\alpha - 1)(\\alpha - 2) \\ldots (\\alpha - n + 1) \\right] \\frac{(\\alpha - n)!}{(\\alpha - n)!} (1 + r_0)^{\\alpha - n} \\\\\n&= \\frac{\\alpha!}{(\\alpha - n)!} (1 + r_0)^{\\alpha - n} \\\\\n\\Longrightarrow f^{(n)}(0) &= \\frac{\\alpha!}{(\\alpha - n)!} (1 + 0)^{\\alpha - n} \\\\\n&= \\frac{\\alpha!}{(\\alpha - n)!}.\n\\end{align}\n\\] Therefore, \\[\n\\begin{aligned}\nb(1 + r)^{\\alpha} &= b \\sum_{n = 0}^{\\infty} \\frac{f^{(n)}(0)}{n!} (r - 0)^n \\\\\n&= b \\sum_{n = 0}^{\\infty} \\frac{\\left[ \\frac{\\alpha!}{(\\alpha - n)!} \\right]}{n!} r^n \\\\\n&= b \\sum_{n = 0}^{\\infty} \\frac{\\alpha!}{n!(\\alpha - n)!} r^n \\\\\n&= \\sum_{n = 0}^{\\infty} {\\alpha \\choose n} br^n\n\\end{aligned}\n\\]\n\n\n3.3.4 The Gamma Function\nAs a preliminary comment, we could spend literal weeks discussing and proving the many properties of a function called the Gamma Function, and we will discuss it in much greater depth as we progress further into these lessons on various statistical distributions. However, for now, suffice it to say that the Gamma Function is a generalization of the factorial function. Visually, it “connects the dots” between the integer factorial values. To see this, we will generate factorial and Gamma values from 0 to 4.\n\n\nCode\nfactorialValues_df &lt;- data.frame(\n  n = 0:4,\n  nFact = factorial(0:4)\n)\ngammaValues_df &lt;- data.frame(\n  x = seq(from = 0, to = 4, length.out = 21),\n  xGamma = gamma(seq(from = 0, to = 4, length.out = 21) + 1)\n)\n\n\nNow let’s visualize these two sets of values.\n\n\nCode\nlibrary(ggplot2)\n\nggplot() + \n  geom_line(data = gammaValues_df, aes(x = x, y = xGamma)) + \n  geom_point(data = factorialValues_df, aes(x = n, y = nFact), color = \"red\") +\n  labs(\n    x = \"Real (black) and Integer (red) valued x\",\n    y = \"Gamma(x+1) (black) and x! (red)\"\n  )\n\n\n\n\n\n\n\n\n\nSo, we see that the Gamma Function is one (of potentially many) smooth interpolations between the values of \\(x!\\) evaluated at each non-negative integer. However, it can be extended to the negative (non-integer) numbers and even the complex plane. At its most complex (for this class anyway), the Weierstrass’s Definition of the Gamma Function for all complex values of \\(z = a + bi\\) except for the negative integers is \\[\n\\Gamma(z) \\equiv \\frac{e^{-\\gamma z}}{z} \\prod_{n = 1}^{\\infty} \\left( 1 + \\frac{z}{n} \\right)^{-1} e^{\\frac{z}{n}},\n\\] where \\(\\gamma \\approx 0.577\\) is the Euler-Mascheroni constant.\nThankfully, we don’t have to use this version, we only have to know that it exists. The version that we will use most is the representation of the Gamma Function when the Real component \\(z\\) is positive; that is, when \\(a &gt; 0\\). We represent this condition symbolically as \\(\\mathbb{R}(z) &gt; 0\\). It’s also worth noting that this includes all the positive real numbers as well, because \\(b\\) in \\(z = a + bi\\) could be \\(0\\). So, the “common form” of the Gamma Function is \\[\n\\Gamma(z) = \\int_0^{\\infty} t^{z - 1}e^{-t}dt,\\ \\mathbb{R}(z) &gt; 0.\n\\] Finally, in the simplest case, if \\(z\\) can be written as a non-negative integer \\(n\\), then we get the simplest form of all: \\[\n\\Gamma(n) \\equiv (n - 1)!.\n\\] For the next few lessons (at least until we get to the Gamma and Beta Distributions), we won’t yet need to formalize or prove any properties of this function. For now, we simply need to know that it’s possible to extend the factorial beyond the integers.\n\n\n3.3.5 “Negative” Binomial Coefficients\nThis is a specific form of the Generalized Binomial Coefficient that allows us to extend the mathematical relationship of the binomial theorem beyond its usual applications of combinations (where \\(n\\) and \\(k\\) are required to be non-negative integers). This generalization yields the following property, which we will shortly prove: \\[\n{-a \\choose b} \\equiv (-1)^b {a + b - 1 \\choose b}.\n\\]\nProof: Consider \\(a,b \\in \\mathbb{R}\\) and further recall by the above definition of the Gamma Function that the factorial operator can be extended beyond the integers. Even though we do not define how to calculate such a value, we will only need to know for this proof that such numbers could possibly exist. Thus, \\[\n\\begin{aligned}\n{-a \\choose b} &= \\frac{(-a)!}{b!(-a - b)!} \\\\\n&= \\frac{(-a)(-a - 1)(-a - 2)\\ldots(-a - b + 1)(-a - b)!}{b!(-a - b)!} \\\\\n&= \\frac{(-a)(-a - 1)(-a - 2)\\ldots(-a - b + 1)}{b!} \\\\\n&= (-1)^b\\frac{(a)(a + 1)(a + 2)\\ldots(a + b - 1)}{b!} \\\\\n&= (-1)^b\\frac{(a + b - 1)\\ldots(a + 2)(a + 1)(a)}{b!} \\times \\frac{(a - 1)!}{(a - 1)!} \\\\\n&= (-1)^b\\frac{(a + b - 1)!}{b!(a - 1)!} \\\\\n&= (-1)^b\\frac{(a + b - 1)!}{b!([a + b - 1] - b)!} \\\\\n&= (-1)^b {a + b - 1 \\choose b}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/negative_binomial_20250310.html#show-that-this-is-a-distribution",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.4 Show that this is a Distribution",
    "text": "3.4 Show that this is a Distribution\nWe first consider the parametrization with \\(m\\) successes out of \\(n\\) trials. That is, \\[\nf_{\\text{NB}}(n|m,p) \\equiv {n - 1 \\choose m - 1} p^{m} (1 - p)^{n - m}, 1 \\le m \\le n &lt; \\infty,\\ p\\in (0,1).\n\\] Note that \\(m \\ge 1\\) because we are counting the number of trials until we see at least one success. Also note that \\(n\\) has no upper bound. If the “game” is the United States Men’s Soccer team winning the FIFA World Cup, the number of World Cups necessary, \\(n\\), for this event, \\(m = 1\\), to occur \\(\\to\\infty\\).\n\n3.4.1 The Distribution is Non-negative\nAs we already know, \\(p\\in (0,1)\\). Thus \\(p^m,\\ (1 - p)^{n - m} &gt; 0\\). Further, \\(1 \\le m \\le n &lt; \\infty\\), so Binomial Coefficient will never be smaller than 1. Thus, for \\(p\\in (0,1)\\), \\(f_{\\text{NB}}(m, n|p) &gt; 0\\), and for \\(p\\) outside this defined range of probability, \\(f_{\\text{NB}}(m, n|p) \\equiv 0\\) by definition. Thus, \\(f_{\\text{NB}}(m, n|p) \\ge 0\\ \\forall p\\).\n\n\n3.4.2 The Total Probability is 1\nThis proof is considerably more involved than the proof for the Binomial Distribution; I follow this guide from Mathematics Stack Exchange. We will use proof by induction, infinite geometric series, and Pascal’s Rule of factorials. These topics are covered in the “Formal Foundations” subsections of this lesson and the previous lesson on the Binomial Distribution. Let’s begin by defining a shorthand form of the Riemman-Stieljes integral of the Negative Binomial Distribution over the support of \\(n\\); let \\[\nS_m \\equiv \\int\\limits_{\\mathcal{S}(n|m)} dF(n|m,p) = \\sum_{n = m}^{\\infty} {n - 1 \\choose m - 1} p^m (1 - p)^{n - m},\\ \\forall m\\in\\mathbb{N}.\n\\]\nThe base case is the event when \\(m = 1\\). So we must show that \\(S_1 = 1\\). First, recall that there is only 1 way to “choose” 0 events, so \\[\n\\begin{aligned}\nS_1 &= \\sum_{n = 1}^{\\infty} {n - 1 \\choose 1 - 1} p^1 (1 - p)^{n - 1} \\\\\n&= p \\sum_{n = 1}^{\\infty} {n - 1 \\choose 0} (1 - p)^{n - 1} \\\\\n&= p \\sum_{n = 1}^{\\infty} (1) (1 - p)^{n - 1} \\\\\n&= p \\sum_{k + 1 = 1}^{\\infty} (1 - p)^k,\\ \\text{for}\\ n = k + 1 \\\\\n&= p \\sum_{k = 0}^{\\infty} (1 - p)^k \\\\\n&\\qquad \\text{\\emph{Infinite Geometric Series...}} \\\\\n&= p \\left[ \\frac{1}{1 - [1 - p]} \\right],\\ |1 - p| &lt; 1 \\\\\n&= \\frac{p}{1 - 1 + p} \\\\\n&= 1.\n\\end{aligned}\n\\] The hypothesis is then that \\(S_m = 1\\). That is, we assume that \\[\nS_m = \\sum_{n = m}^{\\infty} {n - 1 \\choose m - 1} p^m (1 - p)^{n - m} = 1.\n\\] Our induction will be to assume the hypothesis is true for \\(m\\) and show that this implies that it is also true for \\(m+1\\).\nNow, using this \\(S_m\\) notation, and recalling Pascal’s Rule: \\[\n\\begin{aligned}\nS_{m + 1} &= \\sum_{n = m + 1}^{\\infty} {n - 1 \\choose m + 1 - 1} p^{m + 1} (1 - p)^{n - (m + 1)} \\\\\n&= \\sum_{n = m + 1}^{\\infty} {n - 1 \\choose m} p^{m + 1} (1 - p)^{n - m - 1} \\\\\n&\\qquad \\text{\\emph{Pascal's Rule...}} \\\\\n&= \\sum_{n = m + 1}^{\\infty} \\left[ {n - 2 \\choose m} + {n - 2 \\choose m - 1} \\right] p^{m + 1} (1 - p)^{n - m - 1} \\\\\n&= \\sum_{n = m + 1}^{\\infty} {n - 2 \\choose m} p^{m + 1} (1 - p)^{n - m - 1} + \\sum_{n = m + 1}^{\\infty} {n - 2 \\choose m - 1} p^{m + 1} (1 - p)^{n - m - 1}.\n\\end{aligned}\n\\] At this point, we’d like to pull out something that looks like \\(S_m\\), because we are assuming that equals 1. Let’s change the summation index by letting \\(j = n - 1 \\Rightarrow n = j + 1\\) and pick back up: \\[\n\\begin{aligned}\nS_{m + 1} &= \\sum_{[j + 1] = m + 1}^{\\infty} {[j + 1] - 2 \\choose m} p^{m + 1} (1 - p)^{[j + 1] - m - 1} + \\sum_{[j + 1] = m + 1}^{\\infty} {[j + 1] - 2 \\choose m - 1} p^{m + 1} (1 - p)^{[j + 1] - m - 1} \\\\\n&= \\sum_{j = m}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m} + \\sum_{j = m}^{\\infty} {j - 1 \\choose m - 1} p^{m + 1} (1 - p)^{j - m} \\\\\n&= (1 - p) \\sum_{j = m}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} + p \\sum_{j = m}^{\\infty} {j - 1 \\choose m - 1} p^{m} (1 - p)^{j - m} \\\\\n&= (1 - p) \\sum_{j = m}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} + pS_m \\\\\n&= (1 - p) \\left[ {m - 1 \\choose m} p^{m + 1} (1 - p)^{m - m - 1} + \\sum_{j = m + 1}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} \\right] + pS_m \\\\\n&= (1 - p) \\left[ 0 + \\sum_{j = m + 1}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} \\right] + pS_m.\n\\end{aligned}\n\\] The last line requires us to observe that \\({m - 1 \\choose m} = 0\\ \\forall m \\in \\mathbb{N}\\) because there are 0 ways to choose \\(m\\) objects from a set of \\(m - 1\\) objects. For our final component of the induction step, we notice that the second term in the brackets is \\(S_{m+1}\\) using an index of \\(j\\) instead of \\(n\\). Thus, \\[\n\\begin{aligned}\nS_{m + 1} &= (1 - p) \\left[\\sum_{j = m + 1}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} \\right] + pS_m \\\\\n&= (1 - p) \\left[ S_{m + 1} \\right] + pS_m \\\\\n&= S_{m + 1} - pS_{m + 1} + pS_m \\\\\n\\Longrightarrow 0 &= pS_m - pS_{m + 1} \\\\\n\\Longrightarrow S_{m + 1} &= S_m.\n\\end{aligned}\n\\] Because we assumed that \\(S_m = 1\\) at our hypothesis step, we then have that \\(S_m = 1 \\Rightarrow S_{m + 1} = 1\\), which completes our proof. Thus, \\(\\forall m \\in \\mathbb{N}\\), \\[\n\\sum_{n = m}^{\\infty} {n - 1 \\choose m - 1} p^m (1 - p)^{n - m} = 1.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/negative_binomial_20250310.html#derive-the-moment-generating-function",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.5 Derive the Moment Generating Function",
    "text": "3.5 Derive the Moment Generating Function\nIn my opinion, it’s easier to derive the MGF of the Negative Binomial when we use the \\(k,r\\) parametrization (where \\(r \\ge 1\\) is the number of successes and \\(k \\ge 0\\) is the number of failures). Thus, \\[\n\\begin{aligned}\nf_{\\text{NB}}(k,r|p) &= {k + r - 1 \\choose k} p^r (1 - p)^k \\\\\n\\Longrightarrow M_k(t) &= \\int_{\\mathcal{S}(k)} e^{tk} dF(k,r|p) \\\\\n&= \\sum_{k = 0}^{\\infty} e^{tk} {k + r - 1 \\choose k} p^r (1 - p)^k \\\\\n&= p^r \\sum_{k = 0}^{\\infty} {k + r - 1 \\choose k} \\left[ e^{t}(1 - p) \\right]^k \\\\\n&\\qquad \\text{\\emph{Generalized/Negative Binomial Coefficient...}} \\\\\n&= p^r \\sum_{k = 0}^{\\infty} \\left[ (-1)^k {-r \\choose k} \\right] \\left[ e^{t}(1 - p) \\right]^k \\\\\n&= p^r \\sum_{k = 0}^{\\infty} {-r \\choose k} \\left[ -e^{t}(1 - p) \\right]^k \\\\&\\qquad \\text{\\emph{Newton's Binomial Theorem...}} \\\\\n&= p^r \\left( 1 + \\left[ -e^{t}(1 - p) \\right] \\right)^{[-r]}.\n\\end{aligned}\n\\] To correctly invoke Newton’s Binomial Theorem in this last step, we must recall that Moment Generating Functions are defined within an \\(\\epsilon\\)-neighbourhood of 0. Therefore, \\(e^t(1 - p) \\approx (1)(1 - p)\\), which we can safely bound between \\(0\\) and \\(1\\) for arbitrarily small \\(\\epsilon\\), just as long as \\(p \\ne \\{0, 1\\}\\) (as in, as long as neither failure nor success are guaranteed). Thus, \\[\nM_k(t) = \\left[ \\frac{p}{1 - e^{t}(1 - p)} \\right]^r.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/negative_binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.6 Method of Moments Estimates from Observed Data",
    "text": "3.6 Method of Moments Estimates from Observed Data\nIf we see \\(n\\) repeated Negative Binomial experiments, then we must already know the following information:\n\nWe know that in each of the \\(n\\) experiments, by definition we observed \\(r\\) successes.\nWe know that in each experiment, the “games” or “trials” were conducted independently until all \\(r\\) successes were observed. Thus, the number of games in each experiment vary, and the probability of winning in each game, \\(p\\), does not change (but it is unknown in real life).\nBased on the first two facts, we then know that the “data” in repeated Negative Binomial experiments is the count of failures observed in each experiment until all \\(r\\) successes were observed. We denote these counts as \\(k_i,\\ i = 1, 2, \\ldots n\\).\n\nTherefore, our observed data is \\(\\textbf{k} = \\langle k_1, k_2,\\ldots,k_n\\rangle\\), the counts of the number of failures in each experiment until success number \\(r\\) was observed. Let’s generate some random data with \\(r = 5\\) and \\(p = 0.35\\) across 7 experiments:\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7\nr_int &lt;- 5L\np_num &lt;- 0.35\nNBk_int &lt;- rnbinom(n = nTrials_int, size = r_int, prob = p_num)\nNBk_int\n[1] 13 10  3  7 18  9 12\n\n\nAs we can see, in order to achieve 5 wins total in each experiment, we needed 13, 10, 3, 7, 18, 9, 12 “games” in those experiments. Now that we have the MGF and a sample of data, we can:\n\nFind \\(\\mathbb{E}[k]\\), \\(\\mathbb{E}[k^2]\\), and \\(\\text{Var}[k]\\), then\nCreate (and solve) a system of two equations by setting \\(\\mathbb{E}[k] = \\bar{k}\\) and \\(\\text{Var}[k] = s^2\\).\n\n\n3.6.1 \\(\\mathbb{E}[k]\\)\nConsider \\[\n\\begin{aligned}\nM_k(t) &= p^r \\left[ 1 - e^t(1 - p) \\right]^{-r} \\\\\n\\Longrightarrow M^{\\prime}_k(t) &= -rp^r \\left[ 1 - e^t(1 - p) \\right]^{-r - 1} \\times \\left[ - e^t(1 - p) \\right] \\\\\n&= r(1 - p)p^r \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} e^t \\\\\n\\Longrightarrow M^{\\prime}_k(0) &= r(1 - p)p^r [1] \\left[ 1 - [1](1 - p) \\right]^{-r - 1} \\\\\n&= r(1 - p) \\frac{p^r}{p^{r + 1}} \\\\\n&= r \\frac{(1 - p)}{p} \\\\\n&= \\mathbb{E}[k].\n\\end{aligned}\n\\]\n\n\n3.6.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\nTaking \\(M^{\\prime}_k(t)\\) from above, we then have that \\[\n\\begin{aligned}\nM^{\\prime\\prime}_k(t) &= r(1 - p)p^r \\frac{\\partial}{\\partial t} \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} e^t \\\\\n&= r(1 - p)p^r \\left[ \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} \\frac{\\partial}{\\partial t} e^t + e^t \\frac{\\partial}{\\partial t} \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} \\right] \\\\\n&= r(1 - p)p^r e^t \\left[ \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} - (r + 1)\\left[ 1 + e^t(p - 1) \\right]^{-r - 2} \\times e^t(p - 1) \\right].\n\\end{aligned}\n\\] Thus, \\[\n\\begin{aligned}\nM^{\\prime\\prime}_k(0) &= r(1 - p)p^r [1] \\left[ \\left[ 1 + [1](p - 1) \\right]^{-r - 1} - (r + 1)\\left[ 1 + [1](p - 1) \\right]^{-r - 2} \\times [1](p - 1) \\right] \\\\\n&= r(1 - p)p^r \\left[ p^{-(r+1)} + (r+1)(1-p)p^{-(r+2)} \\right] \\\\\n&= r(1 - p) \\left[ \\frac{p}{p^2} + (r+1)\\frac{1 - p}{p^2} \\right] \\\\\n&= \\mathbb{E}[k^2],\n\\end{aligned}\n\\] so that \\[\n\\begin{aligned}\n\\text{Var}[k] &= \\mathbb{E}[k^2] - \\left[\\mathbb{E}[k]\\right]^2 \\\\\n&= r(1 - p) \\left[ \\frac{p}{p^2} + (r+1)\\frac{1 - p}{p^2} \\right] - \\left[ r \\frac{(1 - p)}{p} \\right]^2 \\\\\n&= \\frac{ rp(1 - p) + r(r+1)(1 - p)^2 - r^2(1 - p)^2 }{p^2} \\\\\n&= r(1 - p) \\left[ \\frac{ p + (r+1)(1 - p) - r(1 - p) }{p^2} \\right] \\\\\n&= r(1 - p) \\left[ \\frac{ p + r(1 - p) + 1(1 - p) - r(1 - p) }{p^2} \\right] \\\\\n&= r(1 - p) \\left[ \\frac{ p + 1(1 - p) }{p^2} \\right] \\\\\n&= r(1 - p) \\frac{1}{p^2} \\\\\n&= \\frac{r(1 - p)}{p^2}.\n\\end{aligned}\n\\]\n\n\n3.6.3 Solving the System\nWe now have the following non-linear system of equations to solve: \\[\n\\begin{aligned}\n\\mathbb{E}[k] &: \\frac{r(1 - p)}{p} = \\bar{k} \\\\\n\\text{Var}[k] &: \\frac{r(1 - p)}{p^2} = s^2\n\\end{aligned}\n\\] We will first isolate \\(r\\) as a function of \\(s^2\\). In most real data scenarios, we know \\(r\\), but for completion we will here assume it’s unknown. Thus, \\[\n\\begin{aligned}\ns^2 &= \\frac{r(1 - p)}{p^2} \\\\\n\\Longrightarrow r &= \\frac{p^2s^2}{1 - p} \\\\\n\\Longrightarrow \\bar{k} &= \\left[ \\frac{p^2s^2}{1 - p} \\right] \\times \\frac{(1 - p)}{p} \\\\\n&= ps^2 \\\\\n\\Longrightarrow \\hat{p}_{MoM} = \\frac{\\bar{k}}{s^2}.\n\\end{aligned}\n\\] Subsequently, if we had to estimate \\(r\\) (which is unlikely), then \\[\n\\begin{aligned}\n\\bar{k} &= \\frac{r(1 - p)}{p} \\\\\n&= \\frac{r\\left( 1 - \\left[ \\frac{\\bar{k}}{s^2} \\right] \\right)}{\\left[ \\frac{\\bar{k}}{s^2} \\right]} \\\\\n&= r\\frac{s^2}{\\bar{k}} \\left[ 1 - \\frac{\\bar{k}}{s^2} \\right] \\\\\n\\Longrightarrow \\bar{k} &= r \\left[ \\frac{s^2}{\\bar{k}} - 1 \\right] \\\\\n\\Longrightarrow \\bar{k}^2 &= r (s^2 - \\bar{k}) \\\\\n\\Longrightarrow \\hat{r}_{MoM} &= \\frac{\\bar{k}^2}{s^2 - \\bar{k}}.\n\\end{aligned}\n\\] For this data, we know that \\(r\\) = 5, and we generated data for \\(n\\) = 7 trials with \\(p\\) equal to 0.35. Thus, given the observed data, we estimate \\(\\hat{p}_{MoM}\\) as\n\n\nCode\nmean(NBk_int) / var(NBk_int)\n[1] 0.456",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/negative_binomial_20250310.html#maximum-likelihood-estimators",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.7 Maximum Likelihood Estimators",
    "text": "3.7 Maximum Likelihood Estimators\nBecause we should know \\(r\\) in advance of the experiment, and because \\(\\textbf{k}\\) is the observed counts across \\(n\\) experiments, the only unknown is \\(p\\). The likelihood function is then \\[\n\\mathcal{L}(p|\\textbf{k},r) = \\prod\\limits_{i = 1}^n {k_i + r - 1 \\choose k_i} p^r (1 - p)^k_i,\\ p\\in (0,1).\n\\] We then find the extreme value of \\(\\mathcal{L}\\) by \\[\n\\begin{aligned}\n\\ell(p|\\textbf{k},r) &= \\sum\\limits_{i = 1}^n \\log\\left[ {k_i + r - 1 \\choose k_i} p^r (1 - p)^{k_i} \\right] \\\\\n&= \\sum\\limits_{i = 1}^n \\left[ \\log{k_i + r - 1 \\choose k_i} + r\\log(p) + k_i \\log(1 - p) \\right] \\\\\n&= nr\\log(p) + \\log(1 - p) \\sum\\limits_{i = 1}^n k_i + \\sum\\limits_{i = 1}^n \\log{k_i + r - 1 \\choose k_i} \\\\\n&= nr\\log(p) + n\\bar{k}\\log(1 - p) + \\sum\\limits_{i = 1}^n \\log{k_i + r - 1 \\choose k_i} \\\\\n\\Longrightarrow \\frac{\\partial\\ell(p|\\textbf{k},r)}{\\partial p} &= \\frac{nr}{p} - \\frac{n\\bar{k}}{1 - p} + 0 \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{nr}{\\hat{p}} - \\frac{n\\bar{k}}{1 - \\hat{p}} \\\\\n\\Longrightarrow 0 &= nr(1 - \\hat{p}) - n\\bar{k}\\hat{p} \\\\\n&= nr - nr\\hat{p} - n\\bar{k}\\hat{p} \\\\\n\\Longrightarrow nr &= \\hat{p}(nr + n\\bar{k}) \\\\\n\\Longrightarrow \\hat{p} &= \\frac{nr}{nr + n\\bar{k}} \\\\\n&= \\frac{r}{r + \\bar{k}}.\n\\end{aligned}\n\\] Now we need to confirm that this is indeed a maximum value, so we check the second derivative of the log-likelihood: \\[\n\\begin{aligned}\n\\frac{\\partial\\ell(p|\\textbf{k},r)}{\\partial p} &= \\frac{nr}{p} - \\frac{n\\bar{k}}{1 - p} \\\\\n&= nrp^{-1} - n\\bar{k}(1 - p)^{-1} \\\\\n\\Longrightarrow \\frac{\\partial^2\\ell(p|\\textbf{k},r)}{\\partial p^2} &= -nrp^{-2} - (-1)n\\bar{k}(1 - p)^{-2}(-1) \\\\\n&= -\\frac{nr}{p^2} - \\frac{n\\bar{k}}{(1 - p)^2} \\\\\n&&lt; 0,\n\\end{aligned}\n\\] as long as \\(\\{n,r\\} &gt;0\\) and \\(p\\in(0,1)\\). Thus, \\(\\hat{p}_{MLE} = \\frac{r}{r + \\bar{k}}\\). For our observed data, with \\(r\\) = 5, this is\n\n\nCode\nr_int / (r_int + mean(NBk_int))\n[1] 0.327\n\n\nUnlike in the Binomial Distribution case, where the two estimators were quite close, this ML estimate for \\(p\\) is much closer to the true value of \\(p\\) = 0.35 than the MoM estimate.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#exercises",
    "href": "chapters/negative_binomial_20250310.html#exercises",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.8 Exercises",
    "text": "3.8 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#footnotes",
    "href": "chapters/negative_binomial_20250310.html#footnotes",
    "title": "3  The Negative Binomial Distribution",
    "section": "",
    "text": "for the implications of “choosing” from values that aren’t necessarily integers, see the next subsection on the Gamma Function↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html",
    "href": "chapters/poisson_20250310.html",
    "title": "4  The Poisson Distribution",
    "section": "",
    "text": "4.1 Formal Foundations\nWe will begin this lesson a little differently. For the previous lessons, we were able to derive the distributions without a tremendous amount of preliminary mathematics. However, while the Poisson distribution will end up as a simple distribution to work with, deriving it requires a deep refresh of calculus in addition to some of the other Formal Foundations we have already seen.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#formal-foundations",
    "href": "chapters/poisson_20250310.html#formal-foundations",
    "title": "4  The Poisson Distribution",
    "section": "",
    "text": "4.1.1 The Limit Definition of the Derivative\nIn our introductory calculus courses, we first learned that the derivative was a sophisticated “slope” of a function. Consider some function \\(y = f(x)\\) and its first derivative, which is most commonly denoted as \\(y^{\\prime}\\), \\(f^{\\prime}(x)\\), or \\(\\frac{dy}{dx}\\). Specifically, we learned that \\(f^{\\prime}(x)\\) is the function that yields the instantaneous rate of change of the function \\(f(x)\\). That is, the function \\(f\\) at the point \\(x = x_0\\) is parallel to every straight line which has a slope given by the value of the function \\(f^{\\prime}(x)\\) evaluated at \\(x = x_0\\).\n In the above picture (from the engineers at Utah State University), the red curve is the function \\(f(x)\\), the evaluation point is the black dot near \\(\\{x = 2.25,\\ y = 1.25\\}\\), and the blue line is the tangent line1 to \\(f(x)\\) at the evaluation point. It’s the line that has a slope given by \\(f^{\\prime}\\) evaluated at the black dot.\nIn basic algebra, we know that we calculate the slope between two points, \\(\\{x,y\\}\\) and \\(\\{x_0,y_0\\}\\), as “the change in \\(y\\) divided by the change in \\(x\\)”. We use \\(\\Delta y\\) to represent the “change in \\(y\\)”, and \\(\\Delta x\\) similarly for \\(x\\). Let’s begin there, noting that \\(\\{x_0,y_0\\} = \\{x + \\Delta x,y + \\Delta y\\}\\): \\[\n\\begin{aligned}\n\\text{Slope} &= \\frac{y_0 - y}{x_0 - x} \\\\\n&= \\frac{f(x_0) - f(x)}{x_0 - x}\\\\\n&= \\frac{f([x + \\Delta x]) - f(x)}{[x + \\Delta x] - x} \\\\\n&= \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.\n\\end{aligned}\n\\] Given two fixed points, \\(\\{x,y\\}\\) and \\(\\{x_0,y_0\\}\\), these ratio above can be calculated directly. However, we said above that the derivative is called the instantaneous rate of change. That means, we want \\(\\{x,y\\}\\) and \\(\\{x_0,y_0\\}\\) to be “infinitely” close to each other. In other words, we want \\(\\Delta x \\rightarrow 0\\). This yields our well-known limit definition of the derivative2: \\[\nf^{\\prime}(x) \\equiv \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.\n\\] This limit calculation yields the first order derivative3 if we take it only once (but higher order derivatives can be found by sequentially repeating this process).\nFor example, the first order derivative of \\(y = x^2\\) via limit definition is \\[\n\\begin{aligned}\ny^{\\prime} &= \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} \\frac{\\left[ (x + \\Delta x)^2 \\right] - \\left[ x^2 \\right]}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} \\frac{x^2 + 2x\\Delta x + (\\Delta x)^2 - x^2}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} \\frac{\\Delta x(2x + \\Delta x)}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} 2x + \\Delta x \\\\\n&= 2x + 0,\n\\end{aligned}\n\\] which is the well-known first-order derivative of \\(y = x^2\\) with respect to \\(x\\).\n\n\n4.1.2 Homogeneous Functions\nA function \\(f(x)\\) is said to be homogeneous4 iff \\(f(c\\textbf{x}) = c^kf(\\textbf{x})\\) for some scalar \\(c\\) and \\(k \\in \\mathbb{N}\\). The value of \\(k\\) in the equation is known as the “degree of homogeneity” (which isn’t super important for us to know, but I digress), but it must be an integer. What’s important about homogeneous functions is that they are stretched (but aren’t “shifted”) in space: \\(f(\\textbf{x})\\) and \\(c^kf(\\textbf{x})\\) all have “zeroes” at the same values of the vector \\(\\textbf{x}\\). These functions are often sums or products of single-term polynomials.\nFor example, consider \\(f(x,y) = x^3 + y^3\\). If I pick an arbitrary constant, say 10, then \\[\nf(10x, 10y) = (10x)^3 + (10y)^3 = 10^3(x^3 + y^3) = 10^kf(x,y),\n\\] with \\(k = 3\\). Thus \\(f(x) = x^3\\) is homogeneous with degree 3. In contrast, consider the counter-example \\(f(x) = x^2 - 3\\). For that same arbitrary constant above, is \\(f(10x)\\) the same as some power of 10 times \\(f(x)\\)? Well, \\(f(10x) = 10^2x^2 + 3 = 10^2(x^2 + \\frac{3}{100}) \\ne 10^k f(x)\\). So \\(f(x) = x^2 - 3\\) is not homogeneous. As another counter-example, consider \\(f(x,y) = x^2 + y\\). We see that \\[\nf(10x, 10y) = 10^2x^2 - 10y = 10^2(x^2 - \\frac{1}{10}y) \\ne 10^kf(x,y).\n\\] You may have forgotten about homogeneous functions because of how limiting they are. However, they play a very important role in solving differential equations.\n\n\n4.1.3 First-Order, Homogeneous Differential Equations\nNow that we understand what a first order derivative and a homogeneous function are, we can find out what the build up was all about. Differential Equations are mathematical expressions that systematically equate unknown functions and their derivatives. A primer on solving ordinary5 differential equations is well beyond the scope of this material. However, we can review a very small collection of ordinary differential equations, known as homogeneous first order differential equations which have the form \\[\nM(x,y) + N(x,y)\\frac{dy}{dx} = 0,\n\\] where \\(M\\) and \\(N\\) are both homogeneous functions of the same degree \\(n\\). Because these two functions are homogenous with the same degree \\(n\\), then we can write this derivative as a function of \\(\\frac{y}{x}\\). That is, \\[\n\\begin{aligned}\n0 &= M(x,y) + N(x,y)\\frac{dy}{dx} \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -\\frac{M(x,y)}{N(x,y)} \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -f\\left(\\frac{y}{x}\\right),\n\\end{aligned}\n\\] for some function \\(f\\). Now, we can substitute \\(y = ux\\) on both sides, and distribute the derivative through the substitution with the product rule. Thus, we can separate6 this differential equation into two independent functions of \\(x\\) and \\(u\\): \\[\n\\begin{aligned}\n\\frac{dy}{dx} &= -f\\left(\\frac{y}{x}\\right) \\\\\n\\Longrightarrow \\frac{d(ux)}{dx} &= -f\\left(\\frac{ux}{x}\\right) \\\\\n\\Longrightarrow u\\frac{dx}{dx} + x\\frac{du}{dx} &= -f(u) \\\\\n\\Longrightarrow x\\frac{du}{dx} &= -f(u) - u \\\\\n\\Longrightarrow \\frac{1}{x}\\frac{dx}{du} &= \\frac{-1}{f(u) + u} \\\\\n\\Longrightarrow \\int \\frac{1}{x}dx &= \\int \\frac{-1}{f(u) + u}du,\n\\end{aligned}\n\\] which can be solved if the integral of the right hand side can be found. We note that the solution to the left hand side is \\(\\ln(x)\\).\nLet’s have an example before we move on (we’ll work something similar to this example from Newcastle University). Consider \\[\n\\begin{aligned}\n(x^2 + y^2) + y^2\\frac{dy}{dx} &= 0 \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -\\frac{x^2 + y^2}{y^2} \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -\\left(\\frac{x}{y}\\right)^2 - 1.\n\\end{aligned}\n\\] Now, we let \\(y = ux\\), so \\(\\frac{dy}{dx} = u + x\\frac{du}{dx}\\). Hence, \\[\n\\begin{aligned}\n\\frac{dy}{dx} &= -\\left(\\frac{x}{y}\\right)^2 - 1 \\\\\n\\Longrightarrow u + x\\frac{du}{dx} &= -u^2 - 1 \\\\\n\\Longrightarrow x\\frac{du}{dx} &= -u^2 -u - 1 \\\\\n\\Longrightarrow \\frac{1}{x}dx &= -\\frac{1}{u^2 + u + 1}du \\\\\n&= -\\frac{1}{\\left[u^2 + u + \\frac{1}{4}\\right] + \\left[1 - \\frac{1}{4}\\right]}du \\\\\n&= -\\frac{1}{ \\left[u + \\frac{1}{2}\\right]^2 + \\left[ \\frac{\\sqrt{3}}{2} \\right]^2 }du \\\\\n&= -\\frac{\\frac{4}{3}}{ \\left[\\frac{2}{\\sqrt{3}}\\left(u + \\frac{1}{2}\\right)\\right]^2 + \\frac{4}{3}\\left[ \\frac{\\sqrt{3}}{2} \\right]^2 }du \\\\\n&= -\\frac{4}{3} \\frac{1}{ \\left[\\frac{1}{\\sqrt{3}}\\left(2u + 1\\right)\\right]^2 + 1 }du.\n\\end{aligned}\n\\]\nWhile the last few lines may have seemed bizarre, unintuitive, and adding needless complexity, there is a method to our madness. It is known that7 \\[\n\\arctan(x) \\equiv \\int \\frac{1}{x^2 + 1}dx.\n\\] Therefore, substituting \\(a = \\frac{1}{\\sqrt{3}}(2u + 1)\\) so that \\(da = \\frac{2}{\\sqrt{3}}du\\), \\[\n\\begin{aligned}\n\\frac{1}{x}dx &= -\\frac{4}{3} \\frac{1}{ \\left[ \\frac{1}{\\sqrt{3}} (2u + 1) \\right]^2 + 1 }du \\\\\n\\Longrightarrow \\int \\frac{1}{x}dx &= -\\frac{4}{3} \\int \\frac{1}{a^2 + 1} \\left( \\frac{\\sqrt{3}}{2}da \\right) \\\\\n\\Longrightarrow \\ln(x) &= -\\left[ \\frac{4}{3}\\frac{\\sqrt{3}}{2} \\right] \\arctan\\left(\\frac{1}{\\sqrt{3}}(2u + 1)\\right) + C \\\\\n&= -\\frac{2}{\\sqrt{3}} \\arctan\\left( \\frac{2}{\\sqrt{3}}\\left[\\frac{y}{x}\\right] + \\frac{1}{\\sqrt{3}} \\right) + C,\n\\end{aligned}\n\\] where \\(C\\) is the integrating constant8, which can be solved for in cases where an initial value9 is known. We will solve for \\(C\\) below while deriving the Poisson Distribution, so we will discuss that in more detail later.\nNow, if solving this differential equation was miserable for you, take solace in knowing that we just solved the most challenging one that we will need to tackle in this course. If you had fun solving this integral, I suggest you take more electives in the mathematics department during your graduate work.\n\n\n4.1.4 Integrating Factors\nWhen we have a linear10 first order differential equation, there are various techniques and strategies that work based on the form of the differential equation. When we have a differential equation with the form \\[\n\\frac{dy}{dx} + yf(x) = g(x),\n\\] then we can multiply both sides of the equation by an integrating factor11 to make the problem easier to solve. Recall the Product Rule: \\[\n\\frac{d}{dx}\\left[f(x) \\times g(x)\\right] \\equiv f(x) \\frac{dg}{dx} + g(x) \\frac{df}{dx}\n\\] So the purpose of the integrating factor is to find something that can be multiplied by the differential equation so that the left hand can be re-written as the derivative of a product.\nFor differential equations in the form above, the well-known integrating factor is \\[\nI(x) = \\exp\\left[ \\int f(x)dx \\right].\n\\] Let’s confirm this via algebraic manipulation, starting with the product rule form of \\(y \\times I(x)\\), then invoking the chain rule on \\(I(x)\\): \\[\n\\begin{aligned}\n\\frac{d}{dx} \\left( y \\times I(x) \\right) &= \\frac{d}{dx} \\left( y \\times \\exp\\left[ \\int f(x)dx \\right] \\right) \\\\\n&= y \\times \\left( \\frac{d}{dx} \\exp\\left[ \\int f(x)dx \\right] \\right) + \\exp\\left[ \\int f(x)dx \\right] \\frac{dy}{dx} \\\\\n&= y \\left( \\exp\\left[ \\int f(x)dx \\right] \\right) \\frac{d}{dx} \\int f(x)dx + \\exp\\left[ \\int f(x)dx \\right] \\frac{dy}{dx} \\\\\n&= yf(x) \\exp\\left[ \\int f(x)dx \\right] + \\exp\\left[ \\int f(x)dx \\right] \\frac{dy}{dx} \\\\\n&= \\exp\\left[ \\int f(x)dx \\right] \\left( \\frac{dy}{dx} + yf(x) \\right).\n\\end{aligned}\n\\]\nNow, using what we know, we substitute this into the original differential equation: \\[\n\\begin{aligned}\n\\frac{dy}{dx} + yf(x) &= g(x) \\\\\n\\Longrightarrow \\exp\\left[ \\int f(x)dx \\right] \\left( \\frac{dy}{dx} + yf(x) \\right) &= g(x) \\exp\\left[ \\int f(x)dx \\right] \\\\\n\\Longrightarrow \\frac{d}{dx} \\left( y \\times \\exp\\left[ \\int f(x)dx \\right] \\right) &= g(x) \\exp\\left[ \\int f(x)dx \\right] \\\\\n\\Longrightarrow y\\exp\\left[ \\int f(x)dx \\right] &= \\int g(x) \\exp\\left[ \\int f(x)dx \\right] dx,\n\\end{aligned}\n\\] which can often be solved, or at least simplified, if \\(f(x)\\) is a “nice” function.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#deriving-the-distribution",
    "href": "chapters/poisson_20250310.html#deriving-the-distribution",
    "title": "4  The Poisson Distribution",
    "section": "4.2 Deriving the Distribution",
    "text": "4.2 Deriving the Distribution\nNow that we have recalled the basics of very simple solving ordinary differential equations, we can follow along with Prof. Cowen’s notes on deriving the Poisson distribution.12 Suppose we are counting independent events which happen over a fixed interval of time (such as patients visiting a clinic each hour). Let \\(t\\) be the time, let \\(\\{T, T + \\Delta t\\}\\) be a finite interval of time with width \\(\\Delta t\\), and let \\(1\\) indicate that the event occurs within the interval (for example, that a single patient enters the clinic within this next small window of time). Then, we can express the probability of a new event happening between “now” (time \\(T\\)) and the next \\(\\Delta t\\) few seconds as \\[\n\\mathbb{P}\\left[1 | T \\le t \\le T + \\Delta t \\right] = \\lambda \\Delta t,\n\\] where \\(\\lambda\\) is the “rate” of visits within a standard “unit” of time (like an hour). We can then see that this product \\(\\lambda \\Delta t\\) is the rate over an hour (\\(\\lambda\\)) multiplied by the amount of time in our small observation interval (\\(\\Delta t\\)). Because “now” (time \\(T\\) is arbitrary), we simplify this notation a bit and say \\[\n\\begin{aligned}\n\\mathbb{P}(1|\\Delta t) &\\equiv \\lambda \\Delta t \\\\\n\\mathbb{P}(0|\\Delta t) &\\equiv 1 - \\lambda \\Delta t.\n\\end{aligned}\n\\] Finally, let’s assume that we already know if an event occurred before “now”. That is, \\(\\mathbb{P}[0|t \\le T]\\) and \\(\\mathbb{P}[1|t \\le T]\\) are known.\n\n4.2.1 Probability that the First Event will Happen Later\nBecause events are independent, the probability that the “first” event happens after the next \\(\\Delta t\\) (that no events have happened yet AND no events will happen for the next \\(\\Delta t\\) units of time) is \\[\n\\begin{aligned}\n\\mathbb{P}(0|\\Delta t) &\\equiv \\mathbb{P}(0|t \\le T + \\Delta t) \\\\\n&= \\mathbb{P}(0|t \\le T) \\times \\mathbb{P}(0|T \\le t \\le \\Delta t) \\\\\n&= \\mathbb{P}(0|t \\le T) \\times (1 - \\lambda \\Delta t) \\\\\n&= \\mathbb{P}(0|t \\le T) - \\lambda \\mathbb{P}(0|t \\le T) \\Delta t \\\\\n\\Longrightarrow \\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T) &= - \\lambda \\mathbb{P}(0|t \\le T) \\Delta t \\\\\n\\Longrightarrow \\frac{\\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T)}{\\Delta t} &= - \\lambda \\mathbb{P}(0|t \\le T).\n\\end{aligned}\n\\]\nNotice that we are interested in the “instantaneous” probability of the next event. Hence, we want to take \\(\\Delta t \\rightarrow 0\\), which will yield a first order, linear differential equation. Thus, \\[\n\\begin{aligned}\n\\frac{\\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T)}{\\Delta t} &= - \\lambda \\mathbb{P}(0|t \\le T) \\\\\n\\Longrightarrow \\lim_{\\Delta t \\rightarrow 0} \\frac{\\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T)}{\\Delta t} &= - \\lim_{\\Delta t \\rightarrow 0} \\lambda \\mathbb{P}(0|t \\le T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\mathbb{P}(0|t \\le T) &= - \\lambda \\mathbb{P}(0|t \\le T) \\\\\n\\Longrightarrow \\frac{1}{\\mathbb{P}(0|t \\le T)} d\\mathbb{P}(0|t \\le T)  &= - \\lambda dt \\\\\n\\Longrightarrow \\int \\frac{1}{\\mathbb{P}(0|t \\le T)} d\\mathbb{P}(0|t \\le T)  &= -\\lambda \\int dt \\\\\n\\Longrightarrow \\ln\\left[ \\mathbb{P}(0|t \\le T) \\right] &= - \\lambda t + C \\\\\n\\Longrightarrow \\mathbb{P}(0|t \\le T) &= e^{-\\lambda t + C} \\\\\n&= Ae^{-\\lambda t},\n\\end{aligned}\n\\] for some constant \\(A\\).\nNow, we have the general solution, but we can incorporate the initial condition that \\(\\mathbb{P}(0|t = 0) = 1\\); that is, that no successes occurred before the experiment started. In our example of clinic visits, this means that no patients were already hiding inside the clinic before the doors opened in the morning. Therefore, we have that \\(Ae^{-\\lambda (0)} = 1\\), so \\(A = 1\\). Therefore, \\[\n\\mathbb{P}(0|t \\le T) = e^{-\\lambda t}.\n\\] This is the answer to the question: “what is the probability we haven’t seen the first event yet and won’t see the first event right now?”\n\n\n4.2.2 A General Form for the Probability of \\(n\\) Events So Far\nThe next question we must answer to derive this distribution is: “what is the probability that we will have observed \\(n\\) events right now?” Or, \\(\\mathbb{P}(n|t  \\le T + \\Delta t)\\)? We first assume that \\(\\Delta t\\) is small enough that multiple events cannot occur simultaneously; mathematically, we say \\(\\Delta t \\in (0,\\epsilon)\\) for sufficiently small \\(\\epsilon\\). This is a composite of two possibilities:\n\nAll \\(n\\) events have already happened AND we will not observe an event “now”; that is, \\(\\mathbb{P}(n|t \\le T) \\times \\mathbb{P}(0|T \\le t \\le \\Delta t)\\), which we represent in shorthand as \\(\\mathbb{P}(n|T)\\mathbb{P}(0|\\Delta t)\\).\nAll but 1 event has already happened AND we will observe an event “now”; that is, \\(\\mathbb{P}(n - 1|t \\le T) \\times \\mathbb{P}(1|T \\le t \\le \\Delta t)\\), which we represent in shorthand as \\(\\mathbb{P}(n - 1|T)\\mathbb{P}(1|\\Delta t)\\).\n\nRecall that we defined \\(\\mathbb{P}(1|\\Delta t) \\equiv \\lambda \\Delta t\\) and \\(\\mathbb{P}(0|\\Delta t) \\equiv 1 - \\lambda \\Delta t\\). Thus (using our shorthand notation to move from the first to the second line), \\[\n\\begin{aligned}\n\\mathbb{P}(n|t \\le T + \\Delta t) &= \\mathbb{P}(n|t \\le T) \\times \\mathbb{P}(0|T \\le t \\le \\Delta t) + \\mathbb{P}(n - 1|t \\le T) \\times \\mathbb{P}(1|T \\le t \\le \\Delta t) \\\\\n\\Longrightarrow \\mathbb{P}(n|T + \\Delta t) &= \\mathbb{P}(n|T) \\mathbb{P}(0|\\Delta t) + \\mathbb{P}(n - 1|T) \\mathbb{P}(1|\\Delta t) \\\\\n&= \\mathbb{P}(n|T) \\left[ 1 - \\lambda \\Delta t \\right] + \\mathbb{P}(n - 1|T) \\left[ \\lambda \\Delta t \\right] \\\\\n&= \\mathbb{P}(n|T) - \\lambda \\mathbb{P}(n|T) \\Delta t + \\lambda \\mathbb{P}(n - 1|T) \\Delta t.\n\\end{aligned}\n\\]\nNow, we will follow a similar strategy as above. We will first rearrange terms, then construct a derivative as we take \\(\\Delta t \\rightarrow 0\\), and finally identify the components of the differential equation which yield an Integrating Factor. Thus, \\[\n\\begin{aligned}\n\\mathbb{P}(n|T + \\Delta t) - \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\Delta t &= \\lambda \\mathbb{P}(n - 1|T) \\Delta t \\\\\n\\Longrightarrow \\frac{\\mathbb{P}(n|T + \\Delta t) - \\mathbb{P}(n|T)}{\\Delta t} + \\lambda \\mathbb{P}(n|T) &= \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\lim_{\\Delta t \\rightarrow 0} \\frac{\\mathbb{P}(n|T + \\Delta t) - \\mathbb{P}(n|T)}{\\Delta t} + \\lambda \\mathbb{P}(n|T) &= \\lim_{\\Delta t \\rightarrow 0} \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) &= \\lambda \\mathbb{P}(n - 1|T),\n\\end{aligned}\n\\] so for the Integrating Factor, \\(f(x) = \\lambda\\) and \\(g(x) = \\lambda \\mathbb{P}(n - 1|T)\\). Therefore, \\(I(x) = \\exp\\left[\\int\\lambda dt\\right]\\), and \\[\n\\begin{aligned}\n\\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) &= \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\exp\\left[\\int\\lambda dt\\right] \\times \\left( \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\right) &= \\exp\\left[\\int\\lambda dt\\right] \\times \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow e^{\\lambda t + C} \\times \\left( \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\right) &= e^{\\lambda t + C} \\times \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow e^{\\lambda t} \\times \\left( \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\right) &= e^{\\lambda t} \\times \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n - 1|T).\n\\end{aligned}\n\\]\nWhile this is a solution, we don’t know how to integrate \\(\\mathbb{P}(n - 1|T)\\) for any arbitrary \\(n\\).\n\n\n4.2.3 A Closed Form of the Distribution for Small \\(n\\)\nEven though the general solution we found above isn’t particularly helpful for a specific value of \\(n\\), we do have a closed form for \\(n = 0\\). We showed that \\(\\mathbb{P}(0|T) = e^{-\\lambda t}\\) in the first derivation subsection. Therefore, we will leave this solution still in the form of a differential equation and construct the equations iteratively for all \\(n\\). We start with \\(n = 1\\): \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n = 1|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n - 1 = 0|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ e^{-\\lambda t} \\right] \\\\\n&= \\lambda \\\\\n\\Longrightarrow e^{\\lambda t} \\mathbb{P}(1|T) &= \\int \\lambda dt \\\\\n&= \\lambda t + C.\n\\end{aligned}\n\\]\nWe know that \\(\\mathbb{P}(1|t = 0) = 0\\). In our clinic example, again we state that there are no patients “hiding” in the clinic before the doors open. Therefore, \\[\n\\begin{aligned}\ne^{\\lambda (0)} \\mathbb{P}(1|t = 0) &= \\lambda (0) + C \\\\\n\\Longrightarrow (1) (0) &= 0 + C \\\\\n\\Longrightarrow 0 &= C.\n\\end{aligned}\n\\] Without loss of generality, we then further state that \\(\\mathbb{P}(n|t = 0) = 0\\), which implies that \\(C = 0\\) for each solution of this differential equation. Therefore, \\[\n\\begin{aligned}\ne^{\\lambda t} \\mathbb{P}(1|T) &= \\lambda t + 0 \\\\\n\\Longrightarrow \\mathbb{P}(1|T) &= \\lambda t e^{-\\lambda t}.\n\\end{aligned}\n\\]\nNow we can substitute \\(\\mathbb{P}(1|T) = \\lambda t e^{-\\lambda t}\\) to solve for \\(\\mathbb{P}(2|T)\\): \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(2|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(1|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ \\lambda t e^{-\\lambda t} \\right] \\\\\n&= \\lambda^2 t\\\\\n\\Longrightarrow \\mathbb{P}(2|T) &= e^{-\\lambda t} \\left[ \\int \\lambda^2 t dt \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{2}(\\lambda t)^2 + C \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{2}(\\lambda t)^2 + 0 \\right] \\\\\n&= \\frac{1}{2}(\\lambda t)^2 e^{-\\lambda t}.\n\\end{aligned}\n\\]\nWe’re almost at the “ad nauseum” component of this derivation. Substituting \\(\\mathbb{P}(2|T) = \\frac{1}{2}(\\lambda t)^2 e^{-\\lambda t}\\) yields \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(3|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(2|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ \\frac{1}{2}(\\lambda t)^2 e^{-\\lambda t} \\right] \\\\\n&= \\frac{1}{2} \\lambda^3 t^2\\\\\n\\Longrightarrow \\mathbb{P}(3|T) &= e^{-\\lambda t} \\left[ \\int \\frac{1}{2} \\lambda^3 t^2 dt \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{3 \\times 2}(\\lambda t)^3 + C \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{3 \\times 2}(\\lambda t)^3 + 0 \\right] \\\\\n&= \\frac{(\\lambda t)^3}{3!} e^{-\\lambda t}.\n\\end{aligned}\n\\]\n\n\n4.2.4 Induction Proof for all \\(n\\)\nLet’s recap what we know: \\[\n\\begin{aligned}\n(1) &: \\mathbb{P}(0|T) = e^{-\\lambda t} \\\\\n(2) &: \\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n|T) \\right) = \\lambda e^{\\lambda t} \\mathbb{P}(n - 1|T)\n\\end{aligned}\n\\]\nFor mathematical induction, we need a hypothesis. The pattern of solutions we found was that \\[\n\\mathbb{P}(n|t \\le T) = \\frac{(\\lambda t)^n}{n!} e^{-\\lambda t}.\n\\] The base case is then when \\(n = 0\\), so \\[\n\\mathbb{P}(n = 0|t \\le T) = \\frac{(\\lambda t)^0}{0!} e^{-\\lambda t} = e^{-\\lambda t},\n\\] which we showed to be true above. Assuming the hypothesis is true, the induction is then to show that the following is true: \\[\n\\mathbb{P}(n + 1|t \\le T) = \\frac{(\\lambda t)^{n + 1}}{(n + 1)!} e^{-\\lambda t}.\n\\] That is, \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n + 1|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ \\frac{(\\lambda t)^n}{n!} e^{-\\lambda t} \\right] \\\\\n&= \\frac{\\lambda^{n+1}}{n!} t^n \\\\\n\\Longrightarrow \\mathbb{P}(n + 1|T) &= \\frac{\\lambda^{n+1}}{n!} e^{-\\lambda t} \\int t^n dt \\\\\n&= \\frac{\\lambda^{n+1}}{n!} e^{-\\lambda t} \\left[ \\frac{1}{n + 1} t^{n + 1} + C \\right] \\\\\n&= \\frac{\\lambda^{n+1}}{n!} e^{-\\lambda t} \\left[ \\frac{1}{n + 1} t^{n + 1} + 0 \\right] \\\\\n&= \\frac{(\\lambda t)^{n + 1}}{(n + 1)!} e^{-\\lambda t},\n\\end{aligned}\n\\] which completes the proof. Therefore, \\[\nf_{\\text{Poisson}}(k|\\lambda) \\equiv \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#example-random-samples",
    "href": "chapters/poisson_20250310.html#example-random-samples",
    "title": "4  The Poisson Distribution",
    "section": "4.3 Example Random Samples",
    "text": "4.3 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nN &lt;- 5\n\nxSymm &lt;- rpois(n = 500, lambda = 25)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n30  = xSymm[1:30],\n  n100 = xSymm[1:100],\n  n500 = xSymm\n)\nbinsSymm_int &lt;- seq.int(from = -1, to = max(xSymm) + 1, by = 1)\n\nxSkew &lt;- rpois(n = 500, lambda = 2.5)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n30  = xSkew[1:30],\n  n100 = xSkew[1:100],\n  n500 = xSkew\n)\nbinsSkew_int &lt;- seq.int(from = -1, to = max(xSkew) + 1, by = 1)\n# we are drawing until we reach N successes, so the upper limit should be \n# N * (1 / min(prob)) + epsilon\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSkew_ls$n5, breaks = binsSkew_int)\nhist(samplesSkew_ls$n30, breaks = binsSkew_int)\nhist(samplesSkew_ls$n100, breaks = binsSkew_int)\nhist(samplesSkew_ls$n500, breaks = binsSkew_int)\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSymm_ls$n5, breaks = binsSymm_int)\nhist(samplesSymm_ls$n30, breaks = binsSymm_int)\nhist(samplesSymm_ls$n100, breaks = binsSymm_int)\nhist(samplesSymm_ls$n500, breaks = binsSymm_int)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/poisson_20250310.html#show-that-this-is-a-distribution",
    "title": "4  The Poisson Distribution",
    "section": "4.4 Show that this is a Distribution",
    "text": "4.4 Show that this is a Distribution\nAfter the Herculean effort to derive this distribution, showing that it is a distribution is downright pedestrian in comparison.\n\n4.4.1 The Distribution is Non-negative\nAs we already know, \\(\\lambda &gt; 0\\), \\(t \\ge 0\\), and \\(k \\in 0 \\cup\\mathbb{N}\\). Thus \\((\\lambda t)^k \\ge 0\\). Further, the exponential and factorial functions are non-negative. Thus, \\(f_{\\text{Poisson}}(k|\\lambda t) \\ge 0\\).\n\n\n4.4.2 The Total Probability is 1\nLet’s recall the MacLaurin Series Expansion for the exponential function: \\[\ne^x \\equiv \\sum_{n = 0}^{\\infty} \\frac{x^n}{n!}.\n\\] This should give us a big hint for how were are going to integrate the Poisson distribution. Recall that the support for \\(k\\) is the set of 0 and all positive integers up to \\(\\infty\\); that is \\(\\mathcal{S}(k) = [0,\\infty) \\in \\mathbb{Z}\\). Thus, we substitute the MacLaurin Series as follows: \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(k)} dF(k|\\lambda t) &= \\sum_{k = 0}^{\\infty} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t} \\\\\n&= e^{-\\lambda t} \\sum_{k = 0}^{\\infty} \\frac{(\\lambda t)^k}{k!} \\\\\n&= e^{-\\lambda t} \\left[ e^{\\lambda t}  \\right] \\\\\n&= 1.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/poisson_20250310.html#derive-the-moment-generating-function",
    "title": "4  The Poisson Distribution",
    "section": "4.5 Derive the Moment Generating Function",
    "text": "4.5 Derive the Moment Generating Function\nThe MGF is found similarly, by (again) applying the MacLaurin Series expansion for \\(e^x\\). Note that we are using \\(s\\) as the nuisance parameter of the MGF instead of \\(t\\) because we already use \\(\\lambda t\\) as the parameter of the Poisson Distribution Thus, \\[\n\\begin{aligned}\nM_k(s) &= \\int_{\\mathcal{S}(k)} e^{sk} dF(k|\\lambda t) \\\\\n&= \\sum_{k = 0}^{\\infty} e^{sk} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t} \\\\\n&= e^{-\\lambda t} \\sum_{k = 0}^{\\infty} \\frac{(e^s \\lambda t)^k}{k!} \\\\\n&= e^{-\\lambda t} e^{e^s \\lambda t} \\\\\n&= \\exp\\left[ -\\lambda t + e^s \\lambda t \\right] \\\\\n&= \\exp\\left[ \\lambda t (e^s - 1) \\right].\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/poisson_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "4  The Poisson Distribution",
    "section": "4.6 Method of Moments Estimates from Observed Data",
    "text": "4.6 Method of Moments Estimates from Observed Data\nLet’s generate some random data across 7 experiments. We assume that these 7 experiments represent 7 identical and fixed periods of time wherein to count events, with an average of with \\(\\lambda t = 5\\) events in each interval:\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7L\nlambt_num &lt;- 5\nPoisk_int &lt;- rpois(n = nTrials_int, lambda = lambt_num)\nPoisk_int\n[1] 7 3 5 8 4 1 4\n\n\nIf these data are the counts of patient visits to a clinic in these 7 time intervals, we can see that there were 7, 3, 5, 8, 4, 1, 4 patients in each interval. Now that we have the MGF and a sample of data, we can estimate the Poisson “rate” parameter \\(\\lambda t\\).\n\n4.6.1 \\(\\mathbb{E}[k]\\)\nRecall that our MGF nuisance parameter is \\(s\\), not \\(t\\); \\(\\lambda t\\) is the Poisson parameter. Now consider \\[\n\\begin{aligned}\nM_k(s) &= \\exp[ \\lambda t (e^s - 1) ] \\\\\n\\Longrightarrow \\frac{d}{ds} M_k(s) &= \\frac{d}{ds} \\exp[ \\lambda t (e^s - 1) ] \\\\\n&= \\exp[ \\lambda t (e^s - 1) ] \\frac{d}{ds} \\lambda t (e^s - 1) \\\\\n&= \\exp[ \\lambda t (e^s - 1) ] \\lambda t e^s \\\\\n&= \\lambda t \\exp[ \\lambda t (e^s - 1) + s].\n\\end{aligned}\n\\] Thus, \\[\n\\begin{aligned}\nM_k^{\\prime}(s) &= \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\\\\n\\Longrightarrow M_k^{\\prime}(0) &= \\lambda t \\exp[ \\lambda t (e^{[0]} - 1) + [0]] \\\\\n&= \\lambda t \\exp[ \\lambda t (1 - 1) ] \\\\\n&= \\lambda t \\exp[ 0 ] \\\\\n&= \\lambda t \\\\\n&= \\mathbb{E}[k].\n\\end{aligned}\n\\]\n\n\n4.6.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\nSimilarly, \\[\n\\begin{aligned}\nM_k^{\\prime}(s) &= \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\\\\n\\Longrightarrow M_k^{\\prime\\prime}(s) &= \\frac{d}{ds} \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\\\\n&= \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\frac{d}{ds} [ \\lambda t (e^s - 1) + s] \\\\\n&= \\lambda t [ \\lambda t e^s + 1] \\exp[ \\lambda t (e^s - 1) + s].\n\\end{aligned}\n\\] Evaluating this second derivative at 0 yields \\[\n\\begin{aligned}\nM_k^{\\prime\\prime}(0) &= \\lambda t [ \\lambda t e^{[0]} + 1] \\exp[ \\lambda t (e^{[0]} - 1) + [0]] \\\\\n&= \\lambda t (\\lambda t [1] + 1) \\exp[\\lambda t (1 - 1)] \\\\\n&= \\lambda t (\\lambda t + 1) \\\\\n&= \\mathbb{E}[k^2].\n\\end{aligned}\n\\] Therefore, \\[\n\\begin{aligned}\n\\text{Var}[k] &= \\mathbb{E}[k^2] - \\left[ \\mathbb{E}[k] \\right]^2 \\\\\n&= \\lambda t (\\lambda t + 1) - [\\lambda t]^2 \\\\\n&= (\\lambda t)^2 + \\lambda t - (\\lambda t)^2 \\\\\n&= \\lambda t.\n\\end{aligned}\n\\]\n\n\n4.6.3 Solving the System\nWe now see the trivial solution to our problem: the Poisson distribution has the same estimates for mean and variance. Thus, \\(\\hat{\\lambda}_{\\text{MoM}} = \\bar{k}\\). For our example data, where the true value of \\(\\lambda t\\) was 5, we see the Method of Moments estimate is\n\n\nCode\nmean(Poisk_int)\n[1] 4.57",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/poisson_20250310.html#maximum-likelihood-estimators",
    "title": "4  The Poisson Distribution",
    "section": "4.7 Maximum Likelihood Estimators",
    "text": "4.7 Maximum Likelihood Estimators\nFor this last section, we will slightly change the parametrization of the Poisson Distribution. Let the Poisson rate be \\(r = \\lambda t\\). Consider a sample \\(\\textbf{k}_i \\overset{iid}{\\sim} \\text{Pois}(r),\\ i = 1, 2, \\ldots, n\\). The log-likelihood is then \\[\n\\begin{aligned}\nf_{\\text{Pois}}(k|r) &\\equiv \\frac{r^k}{k!}e^{-r} \\\\\n\\Longrightarrow \\mathcal{L}(r|\\textbf{k}) &= \\prod_{i = 1}^n \\frac{r^{k_i}}{k_i!}e^{-r} \\\\\n\\Longrightarrow \\ell(r|\\textbf{k}) &= \\log \\left[ \\prod_{i = 1}^n \\frac{r^{k_i}}{k_i!}e^{-r} \\right] \\\\\n&= \\sum_{i = 1}^n \\log \\left[ \\frac{r^{k_i}}{k_i!}e^{-r} \\right] \\\\\n&= \\sum_{i = 1}^n \\left[ k_i\\log(r) - \\log(k_i!) - r \\right] \\\\\n&= \\log(r) \\left[ \\sum_{i = 1}^n k_i \\right] - \\left[ \\sum_{i = 1}^n \\log(k_i!) \\right] - nr.\n\\end{aligned}\n\\]\nTherefore, we find the extreme values of this log-likelihood by \\[\n\\begin{aligned}\n\\ell(r|\\textbf{k}) &= \\log(r) \\left[ \\sum_{i = 1}^n k_i \\right] - \\left[ \\sum_{i = 1}^n \\log(k_i!) \\right] - nr \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial r} \\ell(r|\\textbf{k}) &= \\frac{\\partial}{\\partial r} \\left( \\log(r) \\left[ \\sum_{i = 1}^n k_i \\right] - \\left[ \\sum_{i = 1}^n \\log(k_i!) \\right] - nr \\right) \\\\\n&= \\frac{1}{r} \\left[ \\sum_{i = 1}^n k_i \\right] - 0 - n \\\\\n&= \\frac{1}{r} [n\\bar{k}] - n \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{n\\bar{k}}{\\hat{r}} - n \\\\\n\\Longrightarrow n\\hat{r} &= n\\bar{k} \\\\\n\\Longrightarrow \\hat{r} &= \\bar{k}.\n\\end{aligned}\n\\] We have found that \\(\\hat{r} = \\bar{k}\\) yields an extreme value of \\(\\ell(r|\\textbf{k})\\), but we need to take the second derivative to confirm that it is a maximum. Then, \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial r} \\ell(r|\\textbf{k}) &= \\frac{1}{r} [n\\bar{k}] - n \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial r^2} \\ell(r|\\textbf{k}) &= \\frac{\\partial}{\\partial r} \\left[\\frac{1}{r} [n\\bar{k}] - n \\right] \\\\\n&= -\\frac{n\\bar{k}}{r^2} \\\\\n&&lt; 0.\n\\end{aligned}\n\\] Ergo, \\(\\hat{r}_{\\text{MLE}} = \\bar{k}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#exercises",
    "href": "chapters/poisson_20250310.html#exercises",
    "title": "4  The Poisson Distribution",
    "section": "4.8 Exercises",
    "text": "4.8 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#footnotes",
    "href": "chapters/poisson_20250310.html#footnotes",
    "title": "4  The Poisson Distribution",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Tangent↩︎\nhttps://tutorial.math.lamar.edu/classes/calci/defnofderivative.aspx↩︎\nhttps://www.geeksforgeeks.org/maths/derivatives/↩︎\nhttps://en.wikipedia.org/wiki/Homogeneous_function↩︎\nMeaning derivatives with respect to only one variable; see https://web.uvic.ca/~tbazett/diffyqs/classification_section.html↩︎\nhttps://tutorial.math.lamar.edu/classes/de/separable.aspx↩︎\nSee integral No. 9 here: https://www.physics.umd.edu/hep/drew/IntegralTable.pdf↩︎\nhttps://en.wikipedia.org/wiki/Constant_of_integration↩︎\nhttps://en.wikipedia.org/wiki/Initial_value_problem↩︎\nMeaning that \\(y^{\\prime}\\) has a power of 1↩︎\nhttps://en.wikipedia.org/wiki/Integrating_factor↩︎\nGlen Cowan, 2009. Royal Holloway University of London.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html",
    "href": "chapters/exponential_20250310.html",
    "title": "5  The Exponential Distribution",
    "section": "",
    "text": "5.1 Deriving the Distribution\nLet’s consider counting events happening in an observation interval with time \\(T \\in [0,t)\\). The count of these events are generated according to a Poisson process with rate \\(\\lambda\\) and observation interval width \\(t\\), given by \\[\nf_{\\text{Pois}}(k|\\lambda t) \\equiv \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t}.\n\\] We can continue our “clinic” example from the Poisson lesson; a Poisson process could be used to describe the number of patients who visit a clinic in a one-hour period. Let’s say that we opened up the clinic in the morning, and we ask ourselves “how long do we have to wait until the first patient arrives?” Mathematically, this would be asking what the value of \\(T\\) will be when \\(k\\) increments from 0 to 1.\nThe probability that we have not yet observed an event by time \\(t\\) is given by \\[\n\\mathbb{P}(0|\\lambda, T = t) = \\frac{(\\lambda t)^0}{0!} e^{-\\lambda t} = e^{-\\lambda t}.\n\\] Notice that we can modify our question from asking about a random variable \\(k\\) to asking about a random variable \\(T\\). We then see that these two quantities are the same, but their random variables are different: \\[\n\\mathbb{P}_k(0|T = t, \\lambda) = \\mathbb{P}_T(T &gt; t|\\lambda).\n\\] In vernacular, we are saying that the probability of observing a count of zero events on or before time \\(t\\) is the same as the probability that the time of the first event is after (greater than) \\(t\\).\nBecause of the logical equivalence of these events, we can say that the probability that the first event (which happens at time \\(T\\)) hasn’t happened yet (as of time \\(t\\)) is given by \\[\n\\mathbb{P}(T &gt; t) = e^{-\\lambda t}.\n\\] This is the probability that the first event will happen after time \\(t\\). Thus, the probability that the first event will happen before the end of our observation interval (which ends at time \\(t\\)) will be the opposite of this: \\[\n\\mathbb{P}(T \\le t) = 1 - e^{-\\lambda t}.\n\\]\nNotice that we have just described the cumulative probability function1. As we all remember, the Cumulative Probability Function is the indefinite integral of the Probability Function, so to find a closed form of the Exponential distribution, we take the derivative with respect to the random variable \\(t\\). So, for \\(\\lambda,t &gt; 0\\), \\[\n\\begin{aligned}\nF_T(t|\\lambda) &= 1 - e^{-\\lambda t} \\\\\n\\Longrightarrow f_T(t|\\lambda) &= \\frac{d}{dt} \\left( 1 - e^{-\\lambda t} \\right) \\\\\n&= - e^{-\\lambda t} (-\\lambda) \\\\\n\\Longrightarrow f_{\\text{Exp}}(t|\\lambda) &= \\lambda e^{-\\lambda t}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#example-random-samples",
    "href": "chapters/exponential_20250310.html#example-random-samples",
    "title": "5  The Exponential Distribution",
    "section": "5.2 Example Random Samples",
    "text": "5.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxPeaked &lt;- rexp(n = 500, rate = 5)\nsamplesPeaked_ls &lt;- list(\n  n5   = xPeaked[1:5],\n  n50  = xPeaked[1:50],\n  n100 = xPeaked[1:100],\n  n500 = xPeaked\n)\n\nxDiffuse &lt;- rexp(n = 500, rate = 1)\nsamplesDiffuse_ls &lt;- list(\n  n5   = xDiffuse[1:5],\n  n50  = xDiffuse[1:50],\n  n100 = xDiffuse[1:100],\n  n500 = xDiffuse\n)\n\nrange_num &lt;- range(c(xPeaked, xDiffuse))\n\nrm(xPeaked, xDiffuse)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesPeaked_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPeaked_ls$n50, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPeaked_ls$n100, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPeaked_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n50, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n100, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#formal-foundations",
    "href": "chapters/exponential_20250310.html#formal-foundations",
    "title": "5  The Exponential Distribution",
    "section": "5.3 Formal Foundations",
    "text": "5.3 Formal Foundations\nAfter all the suffering through theory we’ve done in the last few lessons, the formal theory needed for this lesson is quite light.\n\n5.3.1 Improper Integrals\nThe Fundamental Theorem of Calculus states that, if \\(f\\) is a continuous function on a closed interval from \\(a\\) to \\(b\\) (inclusive) with anti-derivative \\(F\\), then \\[\n\\int_a^b f(x) dx \\equiv \\left[ F(x) \\right]_a^b \\equiv F(b) - F(a).\n\\] Notice that this definition requires that the interval include both \\(a\\) and \\(b\\). Improper integrals mean that either \\(f\\) is not continuous over the interval \\([a,b]\\), or either \\(a\\), \\(b\\), or both, are infinite. For many statistical distributions, the bounds of the support of the random variable include \\(\\infty\\) on one side or both. That means that we can’t just take the integral and substitute in \\(\\infty\\) and “call it a day”. For common statistical distributions with unbounded support, there are two cases.\nCase 1: The Interval is Open on One Side. If we have either the lower or upper bound of the integral tending to \\(\\infty\\), then we do this: \\[\n\\begin{aligned}\n\\int_a^{\\infty} f(x) dx &= \\lim_{\\psi\\to\\infty} F(\\psi) - F(a) \\\\\n\\int_{-\\infty}^b f(x) dx &= F(b) - \\lim_{\\psi\\to -\\infty} F(\\psi) \\\\\n\\end{aligned}\n\\]\nCase 2: The Interval is Open on Both Sides. If we have the lower and upper bound of the integral as the entire Real line, then we split the integral into two “one-sided” improper integrals at some value \\(x = a\\) and evaluate each separately. That is: \\[\n\\int_{-\\infty}^{\\infty} f(x) dx = \\int_{-\\infty}^a f(x) dx\\ +\\ \\int_a^{\\infty} f(x) dx.\n\\] If \\(f\\) is symmetric around the axis \\(x = a\\), then this simplifies even further: \\[\n\\int_{-\\infty}^{\\infty} f(x) dx = 2 \\times \\int_a^{\\infty} f(x) dx.\n\\] The Normal and Student’s \\(t\\) distributions are the two most famous distributions with support over the entire Real line, and they are both symmetric around their mean values (\\(\\mu\\) for the Normal and 0 for the Student’s \\(t\\) distributions).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/exponential_20250310.html#show-that-this-is-a-distribution",
    "title": "5  The Exponential Distribution",
    "section": "5.4 Show that this is a Distribution",
    "text": "5.4 Show that this is a Distribution\nWe recall that \\(\\lambda, t &gt; 0\\), so \\(f_{\\text{Exp}}(t|\\lambda) &gt; 0\\). For the total probability, we need to remember that we can reverse the limits of integration,2 and we need to be able to solve an improper integral (described above). Once you have reviewed these concepts, consider \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(t)} dF(t|\\lambda) &= \\int_0^{\\infty} \\lambda e^{-\\lambda t} dt \\\\\n&= \\lim_{\\psi \\to \\infty} \\left[ -\\frac{\\lambda}{\\lambda} e^{-\\lambda t} \\right]_{t = 0}^{\\psi} \\\\\n&= \\lim_{\\psi \\to \\infty} \\left[ -e^{-\\lambda t} (-1) \\right]_{\\psi}^{t = 0} \\\\\n&= \\lim_{\\psi \\to \\infty} \\left[ e^{-\\lambda t} \\right]_{\\psi}^{t = 0} \\\\\n&= \\left[ e^{\\lambda [0]} \\right] - \\left[ \\lim_{\\psi \\to \\infty} e^{-\\lambda \\psi} \\right] \\\\\n&= 1 - 0.\n\\end{aligned}\n\\] Therefore, \\(f_{\\text{Exp}}(t|\\lambda)\\) is a probability distribution.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/exponential_20250310.html#derive-the-moment-generating-function",
    "title": "5  The Exponential Distribution",
    "section": "5.5 Derive the Moment Generating Function",
    "text": "5.5 Derive the Moment Generating Function\nAs with the Poisson Distribution, we will call the nuisance parameter for the MGF \\(s\\) instead of \\(t\\), as \\(t\\) is the random variable of the Exponential Distribution. Recall that the MGF must be defined for \\(s\\) in an \\(\\epsilon\\)-neighbourhood of 0, for some arbitrarily small \\(\\epsilon\\). This means that, without loss of generality, we can bound \\(s\\) to be smaller than the rate parameter \\(\\lambda &gt; 0\\) (which we will need below). Thus,\n\\[\n\\begin{aligned}\nM_t(s) &= \\int_{\\mathcal{S}(t)} e^{st} dF(t|\\lambda) \\\\\n&= \\int_0^{\\infty} e^{st} \\lambda e^{-\\lambda t} dt \\\\\n&= \\lambda \\int_0^{\\infty} e^{t(s - \\lambda)} dt \\\\\n&= \\frac{\\lambda}{s - \\lambda} \\lim_{\\psi\\to\\infty} \\left[ e^{t(s - \\lambda)} \\right]_{t = 0}^{\\psi},\\ s &lt; \\lambda \\\\\n&= \\frac{\\lambda}{s - \\lambda} \\left[ \\lim_{\\psi\\to\\infty} e^{\\psi(s - \\lambda)} - e^{[0](s - \\lambda)} \\right] \\\\\n&= \\frac{\\lambda}{s - \\lambda} \\left[ \\lim_{\\psi\\to\\infty} e^{-\\psi(\\lambda - s)} - 1 \\right],\\ s &lt; \\lambda \\Rightarrow \\lambda - s &gt; 0 \\\\\n&= \\frac{\\lambda}{s - \\lambda} [0 - 1] \\\\\n&= \\frac{\\lambda}{\\lambda - s}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/exponential_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "5  The Exponential Distribution",
    "section": "5.6 Method of Moments Estimates from Observed Data",
    "text": "5.6 Method of Moments Estimates from Observed Data\nLet’s generate some random data. We continue our “clinic” example, and now we generate 7 “waiting times” until the first patient walks in. For a single experiment, that is, when we first open the clinic, how long will we have to wait for the first patient to arrive? Let’s assume the same rate of \\(\\lambda = 5\\) for one hour that we used in the previous lesson. We can generate data (in fractional hours) by\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7L\nrate_num &lt;- 5\nExpt_num &lt;- rexp(n = nTrials_int, rate = rate_num)\nExpt_num\n[1] 0.03635 0.00557 0.27411 0.00179 0.21331 0.20857 0.27598\nExpt_num * 60\n[1]  2.181  0.334 16.446  0.108 12.798 12.514 16.559\n\n\nSo, for these 7 independent trials where the waiting times \\(T\\) have an identical Exponential distribution with rate of 5 patients per hour, we wait 2.2, 0.3, 16.4, 0.1, 12.8, 12.5, 16.6 minutes to see the first patient.\n\n5.6.1 \\(\\mathbb{E}[k]\\)\nConsider \\[\n\\begin{aligned}\nM_t(s) &= \\lambda(\\lambda - s)^{-1} \\\\\n\\Longrightarrow M_t^{\\prime}(s) &= \\frac{d}{ds} \\lambda(\\lambda - s)^{-1} \\\\\n&= -\\lambda(\\lambda - s)^{-2}(-1) \\\\\n&= \\lambda(\\lambda - s)^{-2} \\\\\n\\Longrightarrow M_t^{\\prime}(0) &= \\frac{\\lambda}{(\\lambda - [0])^2} \\\\\n&= \\frac{1}{\\lambda} \\\\\n&= \\mathbb{E}[t].\n\\end{aligned}\n\\]\n\n\n5.6.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\nWe continue: \\[\n\\begin{aligned}\nM^{\\prime}_t(s) &= \\lambda(\\lambda - s)^{-2} \\\\\n\\Longrightarrow M^{\\prime\\prime}_t(s) &= \\frac{d}{ds} \\lambda(\\lambda - s)^{-2} \\\\\n&= -2\\lambda(\\lambda - s)^{-3}(-1) \\\\\n&= \\frac{2\\lambda}{(\\lambda - s)^3} \\\\\n\\Longrightarrow M^{\\prime\\prime}_t(0) &= \\frac{2\\lambda}{(\\lambda - [0])^3} \\\\\n&= \\frac{2}{\\lambda^2} \\\\\n&= \\mathbb{E}[t^2].\n\\end{aligned}\n\\]\nThen, \\[\n\\text{Var}[t] = \\mathbb{E}[t^2] - \\left[\\mathbb{E}[t]\\right]^2 = \\frac{2}{\\lambda^2} - \\left[\\frac{1}{\\lambda}\\right]^2 = \\frac{1}{\\lambda^2}.\n\\]\n\n\n5.6.3 Solving the System\nWe then have that \\(\\bar{x} = \\frac{1}{\\lambda}\\) and \\(s^2 = \\frac{1}{\\lambda^2}\\), which is an overdetermined system. For the Exponential Distribution, once we know the mean, then we should also know the variance. For our sample, generated from an Exponential with rate \\(\\lambda = 5\\), \\(\\hat{\\lambda}_{\\text{MoM}}\\) = 6.892. It’s worth noting that the Method of Moments estimate for this distribution requires a very large number of samples before it is “close” to the true value (the Maximum Likelihood estimator is the same, as we’ll see next).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/exponential_20250310.html#maximum-likelihood-estimators",
    "title": "5  The Exponential Distribution",
    "section": "5.7 Maximum Likelihood Estimators",
    "text": "5.7 Maximum Likelihood Estimators\nTo estimate a true rate, \\(\\lambda\\), using the likelihood, we collect a set of independent observed times for the first success. That is, \\(\\textbf{t} = [t_1, t_2, \\ldots, t_n] \\overset{iid}{\\sim} \\text{Exp}(\\lambda)\\). Thus, \\[\n\\begin{aligned}\nf_{\\text{Exp}}(t|\\lambda) &= \\lambda e^{-\\lambda t} \\\\\n\\Longrightarrow \\mathcal{L}(\\lambda|\\textbf{t}) &= \\prod_{i = 1}^n \\lambda e^{-\\lambda t_i} \\\\\n\\Longrightarrow \\ell(\\lambda|\\textbf{t}) &= \\log \\left[ \\prod_{i = 1}^n \\lambda e^{-\\lambda t_i} \\right] \\\\\n&= \\sum_{i = 1}^n \\log \\left[ \\lambda e^{-\\lambda t_i} \\right] \\\\\n&= \\sum_{i = 1}^n \\left[ \\log(\\lambda) - \\lambda t_i \\right] \\\\\n&= n\\log(\\lambda) - \\lambda \\sum_{i = 1}^n t_i \\\\\n&= n\\log(\\lambda) - n\\lambda\\bar{t} \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\lambda} \\ell(\\lambda|\\textbf{t}) &= \\frac{\\partial}{\\partial\\lambda} \\left( n\\log(\\lambda) - n\\lambda\\bar{t} \\right) \\\\\n&= \\frac{n}{\\lambda} - n\\bar{t} \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{n}{\\hat{\\lambda}} - n\\bar{t} \\\\\n\\Longrightarrow n\\bar{t} &= \\frac{n}{\\hat{\\lambda}} \\\\\n\\Longrightarrow \\hat{\\lambda} &= \\frac{1}{\\bar{t}}.\n\\end{aligned}\n\\] In order to confirm that this extreme value of the log-likelihood is truly a maxima, we take the second partial derivative: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\lambda} \\ell(\\lambda|\\textbf{t}) &= \\frac{n}{\\lambda} - n\\bar{t} \\\\\n&= n\\lambda^{-1} - n\\bar{t} \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial\\lambda^2} \\ell(\\lambda|\\textbf{t}) &= -n\\lambda^{-2} \\\\\n&&lt; 0.\n\\end{aligned}\n\\] Hence, \\(\\hat{\\lambda}_{MLE} = \\frac{1}{\\bar{t}}\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#exercises",
    "href": "chapters/exponential_20250310.html#exercises",
    "title": "5  The Exponential Distribution",
    "section": "5.8 Exercises",
    "text": "5.8 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#footnotes",
    "href": "chapters/exponential_20250310.html#footnotes",
    "title": "5  The Exponential Distribution",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Cumulative_distribution_function↩︎\nhttps://proofwiki.org/wiki/Reversal_of_Limits_of_Definite_Integral↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html",
    "href": "chapters/gamma_20250310.html",
    "title": "6  The Gamma Distribution",
    "section": "",
    "text": "6.1 Deriving the Distribution",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#example-random-samples",
    "href": "chapters/gamma_20250310.html#example-random-samples",
    "title": "6  The Gamma Distribution",
    "section": "6.2 Example Random Samples",
    "text": "6.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxSymm &lt;- rgamma(n = 500, shape = 10, scale = 1)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n30  = xSymm[1:30],\n  n60  = xSymm[1:60],\n  n500 = xSymm\n)\n\nxSkew &lt;- rgamma(n = 500, shape = 0.9, scale = 3)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n30  = xSkew[1:30],\n  n60  = xSkew[1:60],\n  n500 = xSkew\n)\n\nrange_num &lt;- range(c(xSymm, xSkew))\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSymm_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSkew_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/gamma_20250310.html#show-that-this-is-a-distribution",
    "title": "6  The Gamma Distribution",
    "section": "6.3 Show that this is a Distribution",
    "text": "6.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/gamma_20250310.html#derive-the-moment-generating-function",
    "title": "6  The Gamma Distribution",
    "section": "6.4 Derive the Moment Generating Function",
    "text": "6.4 Derive the Moment Generating Function",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/gamma_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "6  The Gamma Distribution",
    "section": "6.5 Method of Moments Estimates from Observed Data",
    "text": "6.5 Method of Moments Estimates from Observed Data\nLet’s generate some random data…\n\n6.5.1 \\(\\mathbb{E}[k]\\)\n\n\n6.5.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\n\n\n6.5.3 Solving the System",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/gamma_20250310.html#maximum-likelihood-estimators",
    "title": "6  The Gamma Distribution",
    "section": "6.6 Maximum Likelihood Estimators",
    "text": "6.6 Maximum Likelihood Estimators",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#exercises",
    "href": "chapters/gamma_20250310.html#exercises",
    "title": "6  The Gamma Distribution",
    "section": "6.7 Exercises",
    "text": "6.7 Exercises",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html",
    "href": "chapters/beta_20250310.html",
    "title": "7  The Beta Distribution",
    "section": "",
    "text": "7.1 Deriving the Distribution",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#example-random-samples",
    "href": "chapters/beta_20250310.html#example-random-samples",
    "title": "7  The Beta Distribution",
    "section": "7.2 Example Random Samples",
    "text": "7.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxSymm &lt;- rbeta(n = 500, shape1 = 10, shape2 = 10)\nsamplesSymm_ls &lt;- list(\n  n10  = xSymm[1:10],\n  n30  = xSymm[1:30],\n  n60  = xSymm[1:60],\n  n500 = xSymm\n)\n\nxSkew &lt;- rbeta(n = 500, shape1 = 5, shape2 = 1.5)\nsamplesSkew_ls &lt;- list(\n  n10  = xSkew[1:10],\n  n30  = xSkew[1:30],\n  n60  = xSkew[1:60],\n  n500 = xSkew\n)\n\nrange_num &lt;- c(0, 1)\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSymm_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSkew_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/beta_20250310.html#show-that-this-is-a-distribution",
    "title": "7  The Beta Distribution",
    "section": "7.3 Show that this is a Distribution",
    "text": "7.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/beta_20250310.html#derive-the-moment-generating-function",
    "title": "7  The Beta Distribution",
    "section": "7.4 Derive the Moment Generating Function",
    "text": "7.4 Derive the Moment Generating Function",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/beta_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "7  The Beta Distribution",
    "section": "7.5 Method of Moments Estimates from Observed Data",
    "text": "7.5 Method of Moments Estimates from Observed Data\nLet’s generate some random data…\n\n7.5.1 \\(\\mathbb{E}[k]\\)\n\n\n7.5.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\n\n\n7.5.3 Solving the System",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/beta_20250310.html#maximum-likelihood-estimators",
    "title": "7  The Beta Distribution",
    "section": "7.6 Maximum Likelihood Estimators",
    "text": "7.6 Maximum Likelihood Estimators",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#exercises",
    "href": "chapters/beta_20250310.html#exercises",
    "title": "7  The Beta Distribution",
    "section": "7.7 Exercises",
    "text": "7.7 Exercises",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html",
    "href": "chapters/normal_20250310.html",
    "title": "8  The Normal Distribution",
    "section": "",
    "text": "8.1 Deriving the Distribution",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#example-random-samples",
    "href": "chapters/normal_20250310.html#example-random-samples",
    "title": "8  The Normal Distribution",
    "section": "8.2 Example Random Samples",
    "text": "8.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxStandard &lt;- rnorm(n = 1000, mean = 0, sd = 1)\nsamplesStd_ls &lt;- list(\n  n5    = xStandard[1:5],\n  n30   = xStandard[1:30],\n  n60   = xStandard[1:60],\n  n1000 = xStandard\n)\n\nxShift &lt;- rnorm(n = 1000, mean = 1, sd = 2)\nsamplesShifted_ls &lt;- list(\n  n5    = xShift[1:5],\n  n30   = xShift[1:30],\n  n60   = xShift[1:60],\n  n1000 = xShift\n)\n\nrange_num &lt;- range(c(xStandard, xShift))\n\nrm(xSymm, xSkew)\nWarning in rm(xSymm, xSkew): object 'xSymm' not found\nWarning in rm(xSymm, xSkew): object 'xSkew' not found\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesStd_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesShifted_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesShifted_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesShifted_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesShifted_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/normal_20250310.html#show-that-this-is-a-distribution",
    "title": "8  The Normal Distribution",
    "section": "8.3 Show that this is a Distribution",
    "text": "8.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/normal_20250310.html#derive-the-moment-generating-function",
    "title": "8  The Normal Distribution",
    "section": "8.4 Derive the Moment Generating Function",
    "text": "8.4 Derive the Moment Generating Function",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/normal_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "8  The Normal Distribution",
    "section": "8.5 Method of Moments Estimates from Observed Data",
    "text": "8.5 Method of Moments Estimates from Observed Data\nLet’s generate some random data…\n\n8.5.1 \\(\\mathbb{E}[k]\\)\n\n\n8.5.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\n\n\n8.5.3 Solving the System",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/normal_20250310.html#maximum-likelihood-estimators",
    "title": "8  The Normal Distribution",
    "section": "8.6 Maximum Likelihood Estimators",
    "text": "8.6 Maximum Likelihood Estimators",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#exercises",
    "href": "chapters/normal_20250310.html#exercises",
    "title": "8  The Normal Distribution",
    "section": "8.7 Exercises",
    "text": "8.7 Exercises",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html",
    "href": "chapters/chi_square_20250310.html",
    "title": "9  The Central Chi Squared Distribution",
    "section": "",
    "text": "9.1 Deriving the Distribution",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html#example-random-samples",
    "href": "chapters/chi_square_20250310.html#example-random-samples",
    "title": "9  The Central Chi Squared Distribution",
    "section": "9.2 Example Random Samples",
    "text": "9.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxSymm &lt;- rchisq(n = 500, df = 40)\nsamplesSymm_ls &lt;- list(\n  n10  = xSymm[1:10],\n  n30  = xSymm[1:30],\n  n60  = xSymm[1:60],\n  n500 = xSymm\n)\n\nxSkew &lt;- rchisq(n = 500, df = 4)\nsamplesSkew_ls &lt;- list(\n  n10  = xSkew[1:10],\n  n30  = xSkew[1:30],\n  n60  = xSkew[1:60],\n  n500 = xSkew\n)\n\nrange_num &lt;- range(c(xSymm, xSkew))\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSymm_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSkew_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/chi_square_20250310.html#show-that-this-is-a-distribution",
    "title": "9  The Central Chi Squared Distribution",
    "section": "9.3 Show that this is a Distribution",
    "text": "9.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/chi_square_20250310.html#derive-the-moment-generating-function",
    "title": "9  The Central Chi Squared Distribution",
    "section": "9.4 Derive the Moment Generating Function",
    "text": "9.4 Derive the Moment Generating Function",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/chi_square_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "9  The Central Chi Squared Distribution",
    "section": "9.5 Method of Moments Estimates from Observed Data",
    "text": "9.5 Method of Moments Estimates from Observed Data\nLet’s generate some random data…\n\n9.5.1 \\(\\mathbb{E}[k]\\)\n\n\n9.5.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\n\n\n9.5.3 Solving the System",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/chi_square_20250310.html#maximum-likelihood-estimators",
    "title": "9  The Central Chi Squared Distribution",
    "section": "9.6 Maximum Likelihood Estimators",
    "text": "9.6 Maximum Likelihood Estimators",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/chi_square_20250310.html#exercises",
    "href": "chapters/chi_square_20250310.html#exercises",
    "title": "9  The Central Chi Squared Distribution",
    "section": "9.7 Exercises",
    "text": "9.7 Exercises",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Central Chi Squared Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html",
    "href": "chapters/students_t_20250310.html",
    "title": "10  The Student’s t Distribution",
    "section": "",
    "text": "10.1 Deriving the Distribution",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#example-random-samples",
    "href": "chapters/students_t_20250310.html#example-random-samples",
    "title": "10  The Student’s t Distribution",
    "section": "10.2 Example Random Samples",
    "text": "10.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxStd &lt;- rt(n = 500, df = 300)\nsamplesStd_ls &lt;- list(\n  n10  = xStd[1:10],\n  n30  = xStd[1:30],\n  n60  = xStd[1:60],\n  n500 = xStd\n)\n\nxDiffuse &lt;- rt(n = 500, df = 3)\nsamplesDiffuse_ls &lt;- list(\n  n10  = xDiffuse[1:10],\n  n30  = xDiffuse[1:30],\n  n60  = xDiffuse[1:60],\n  n500 = xDiffuse\n)\n\nrange_num &lt;- range(c(xStd, xDiffuse))\n\nrm(xStd, xDiffuse)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesStd_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/students_t_20250310.html#show-that-this-is-a-distribution",
    "title": "10  The Student’s t Distribution",
    "section": "10.3 Show that this is a Distribution",
    "text": "10.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/students_t_20250310.html#derive-the-moment-generating-function",
    "title": "10  The Student’s t Distribution",
    "section": "10.4 Derive the Moment Generating Function",
    "text": "10.4 Derive the Moment Generating Function",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/students_t_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "10  The Student’s t Distribution",
    "section": "10.5 Method of Moments Estimates from Observed Data",
    "text": "10.5 Method of Moments Estimates from Observed Data\nLet’s generate some random data…\n\n10.5.1 \\(\\mathbb{E}[k]\\)\n\n\n10.5.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\n\n\n10.5.3 Solving the System",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/students_t_20250310.html#maximum-likelihood-estimators",
    "title": "10  The Student’s t Distribution",
    "section": "10.6 Maximum Likelihood Estimators",
    "text": "10.6 Maximum Likelihood Estimators",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#exercises",
    "href": "chapters/students_t_20250310.html#exercises",
    "title": "10  The Student’s t Distribution",
    "section": "10.7 Exercises",
    "text": "10.7 Exercises",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html",
    "href": "chapters/f_20250310.html",
    "title": "11  The Central F Distribution",
    "section": "",
    "text": "11.1 Deriving the Distribution",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#example-random-samples",
    "href": "chapters/f_20250310.html#example-random-samples",
    "title": "11  The Central F Distribution",
    "section": "11.2 Example Random Samples",
    "text": "11.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\n# F for a well-posed linear model [p = 5, n = 100]\nxWP &lt;- rf(n = 1000, df1 = 4, df2 = 99)\nsamplesWP_ls &lt;- list(\n  n10   = xWP[1:10],\n  n30   = xWP[1:30],\n  n60   = xWP[1:60],\n  n1000 = xWP\n)\n\n# F for a poorly-posed linear model [p = 25, n = 100]\nxPP &lt;- rf(n = 1000, df1 = 24, df2 = 99)\nsamplesPP_ls &lt;- list(\n  n10   = xPP[1:10],\n  n30   = xPP[1:30],\n  n60   = xPP[1:60],\n  n1000 = xPP\n)\n\nrange_num &lt;- range(c(xWP, xPP))\n\nrm(xWP, xPP)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesWP_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesWP_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesWP_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesWP_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesPP_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPP_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPP_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPP_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/f_20250310.html#show-that-this-is-a-distribution",
    "title": "11  The Central F Distribution",
    "section": "11.3 Show that this is a Distribution",
    "text": "11.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/f_20250310.html#derive-the-moment-generating-function",
    "title": "11  The Central F Distribution",
    "section": "11.4 Derive the Moment Generating Function",
    "text": "11.4 Derive the Moment Generating Function",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/f_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "11  The Central F Distribution",
    "section": "11.5 Method of Moments Estimates from Observed Data",
    "text": "11.5 Method of Moments Estimates from Observed Data\nLet’s generate some random data…\n\n11.5.1 \\(\\mathbb{E}[k]\\)\n\n\n11.5.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\n\n\n11.5.3 Solving the System",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/f_20250310.html#maximum-likelihood-estimators",
    "title": "11  The Central F Distribution",
    "section": "11.6 Maximum Likelihood Estimators",
    "text": "11.6 Maximum Likelihood Estimators",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#exercises",
    "href": "chapters/f_20250310.html#exercises",
    "title": "11  The Central F Distribution",
    "section": "11.7 Exercises",
    "text": "11.7 Exercises",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  }
]