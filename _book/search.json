[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Primer on Statistical Distributions",
    "section": "",
    "text": "Preface\n\nThis is a Quarto book. To learn more about Quarto books visit https://quarto.org/docs/books.\n\nThis is a collection of notes about deriving basic properties of statistical distributions. I tried to write it so that a student who has had 2-3 semesters of undergraduate calculus can understand. It’s not deeply theoretical, but it does include theory.\nThere are probably mistakes in derivations and typos in formulas. As with anything you find on the internet, buyer beware. This is a free website, so–as the old saying goes–“you get what you pay for”.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html",
    "href": "chapters/bernoulli_20250310.html",
    "title": "1  The Bernoulli Distribution",
    "section": "",
    "text": "1.1 Deriving the Distribution\nIn the mid-1600s, mathematicians like Pascal and Fermat were obsessed with games of chance.1 The simplest such game is flipping a single coin. Let \\(P[A]\\) denote the probability of event \\(A\\) occurring. Because flipping a coin has only two outcomes (heads or tails; we ignore the microscopic possibility of a coin landing on its edge for practical gambling scenarios), we can define \\(p \\equiv P[\\text{head}]\\), which necessarily implies that \\(1 - p = P[\\text{tails}]\\). For ease of notation, we let \\(k\\in\\{0,1\\} = 1\\) when the coin hands on leads and \\(k = 0\\) for tails. Thus, we define a Bernoulli Trial as one random value drawn from the following distribution: \\[\nf_{\\text{Bern}}(k|p) = p^k(1-p)^{1-k},\\ k\\in\\{0,1\\},\\ p \\in (0,1) \\subset \\mathbb{R}.\n\\]\nNotice a few things:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#deriving-the-distribution",
    "href": "chapters/bernoulli_20250310.html#deriving-the-distribution",
    "title": "1  The Bernoulli Distribution",
    "section": "",
    "text": "The Bernoulli Probability Mass Function is denoted \\(f_{\\text{Bern}}\\); \\(f\\) is a function, and its argument \\(k\\) is discrete. The domain of \\(f\\) is 0 or 1 (\\(k\\) can only have the values in the set \\(\\mathcal{S} = \\{0,1\\}\\)).\nFor any \\(k \\in \\mathcal{S}\\), \\(f(k|p) \\ge 0\\); this is the range of \\(f\\). This means that \\(f\\) maps from the set \\(\\mathcal{S}\\) to the set of all non-negative real numbers, which is symbolically denoted as \\(f:\\mathcal{S} \\to \\mathbb{R}_{\\ge}\\).\nThe probability of a “head” (success) is the only parameter of \\(f\\), and it is fixed at some value \\(p\\), which must be a real number between 0 and 1.\n\n\n1.1.1 An Example Sample from the Bernoulli Distribution\nNow let’s use R to take \\(n = 100\\) random samples from a Bernoulli Distribution with \\(p = 0.35\\), but we will only inspect the first five (for now):\n\nset.seed(20150516)\nmyBernSample &lt;- rbinom(n = 100, size = 1, prob = 0.35)\nmyBernSample[1:5]\n[1] 1 0 0 1 0\n\nWe now pretend that we only know the results for the first five coin flips. We have flipped one coin five times, with the results \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#example-random-samples",
    "href": "chapters/bernoulli_20250310.html#example-random-samples",
    "title": "1  The Bernoulli Distribution",
    "section": "1.2 Example Random Samples",
    "text": "1.2 Example Random Samples\nWe now take some random samples from this distribution when \\(p = 0.5\\).\n\n\nCode\nset.seed(20150516)\n\nx &lt;- rbinom(n = 100, size = 1, prob = 0.5)\nsamples_ls &lt;- list(\n  n5   = x[1:5],\n  n15  = x[1:15],\n  n30  = x[1:30],\n  n100 = x\n)\n\nrm(x)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samples_ls$n5)\nhist(samples_ls$n15)\nhist(samples_ls$n30)\nhist(samples_ls$n100)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#formal-foundations",
    "href": "chapters/bernoulli_20250310.html#formal-foundations",
    "title": "1  The Bernoulli Distribution",
    "section": "1.3 Formal Foundations",
    "text": "1.3 Formal Foundations\n\n1.3.1 The Riemann-Stieltjes Integral\nLet \\(f\\) be a bounded function on the interval \\(\\mathcal{S} = [a, b] \\subset \\mathbb{R}\\), and let \\(G\\) be a monotone increasing (but not necessarily continuous) function on \\(\\mathcal{S}\\). The Riemann-Stieltjes integral of \\(f\\) with respect to \\(G\\) is denoted as \\[\n\\text{R-S}(f, G) \\equiv \\int_{x \\in \\mathcal{S}} f(x) \\text{d}G(x).\n\\] If \\(G\\) is continuous \\(\\forall x \\in \\mathcal{S}\\), then this integral simplifies to \\[\n\\int_{x \\in \\mathcal{S}} f(x) \\text{d}G(x) = \\int_{x \\in \\mathcal{S}} f(x) G^{\\prime}(x).\n\\] If, however, there exists \\(k &lt; m &lt; \\infty\\) points of discontinuity for \\(G\\) on \\(\\mathcal{S}\\), we define an \\(m\\)-partition of \\(\\mathcal{S}\\) as \\(\\{[y_0, y_1), [y_1, y_2), \\ldots, [y_{m - 2}, y_{m - 1}), [y_{m - 1}, y_m]\\}\\), where \\(\\{a = y_0, b = y_m\\}\\) and the \\(k\\) points of discontinuity are included in the sequence \\(\\{y_1, y_2, \\ldots, y_{m - 1}\\}\\). Then, this integral simplifies to \\[\n\\int_{x \\in \\mathcal{S}} f(x) \\text{d}G(x) = \\sum\\limits_{i = 1}^m f(x)\\left[ G(y_i) - G(y_{i - 1}) \\right].\n\\]\n\n\n1.3.2 Properties of Distributions\nLet \\(x\\) be an observed value \\(\\in \\mathcal{A}\\), and let \\(\\boldsymbol\\theta\\) be a vector of parameters in a parameter space \\(\\boldsymbol\\Theta \\subseteq \\mathbb{R}^q\\). Consider a function \\(f(\\textbf{x}|\\boldsymbol\\theta)\\) with anti-derivative \\(F\\), and note that \\(f\\) need not be continuous. This \\(f\\) represents a probability distribution iff2\n\n\\(\\forall x \\in \\mathcal{S}\\), \\(\\forall \\boldsymbol\\theta \\in \\boldsymbol\\Theta\\), \\(f(x|\\boldsymbol\\theta) \\ge 0\\).\n\\(\\forall \\boldsymbol\\theta \\in \\boldsymbol\\Theta\\), \\(\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) = 1\\), where \\(\\text{d}F\\) is the integrand of a Riemann-Stieltjes integral.\n\nAs long as (1) holds above, then \\(F\\) will be monotone increasing (because the anti-derivative of a non-negative function will always be flat or increasing). The probability density/mass functions for all statistical distributions share these two properties above. Because of the flexibility of the Riemann-Stieltjes integral, we don’t have to make the distinction between probability density functions and probability mass functions any longer. This is because\n\nIf \\(\\mathcal{S}\\) is a discrete set with cardinality \\(|\\mathcal{S}| = n\\), \\(f\\) is commonly referred to as a probability “mass” function. Then, because (1) holds, \\(\\exists\\) some ordering of the elements of \\(\\mathcal{S} \\ni 0 \\le F(x^{(1)}) \\le F(x^{(2)}) \\le \\cdots \\le F(x^{(n)}) \\le 1\\). We know that the total probability of all events is 1, and the total probability of no events is 0, so, by convention, we let \\(F(x^{(n)}) = 1\\) and \\(F(x^{(0)}) = 0\\). Thus, noticing the Telescoping Series3, \\[\n\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) = \\sum\\limits_{i = 1}^n F(x^{(i)}) - F(x^{(i - 1)}) = F(x^{(n)}) - F(x^{(0)}) = 1.\n\\]\nIf \\(\\mathcal{S} = [a,b]\\) is a continuous set, then \\(f\\) is a probability “density” function. For this continuous range, \\(F(a) = 0\\) and \\(F(b) = 1\\). Thus, \\[\n\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) = \\int_a^b F^{\\prime}(x) = F(b) - F(a) = 1.\n\\]\n\nThus, for the remainder of these notes, we will start all integral-based definitions with the Riemann-Stieltjes form, and then reduce this form into traditional sums or integrals, as is appropriate for the distribution at hand.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/bernoulli_20250310.html#show-that-this-is-a-distribution",
    "title": "1  The Bernoulli Distribution",
    "section": "1.4 Show that this is a Distribution",
    "text": "1.4 Show that this is a Distribution\nGiven the extensive review above, showing that \\(f_{\\text{Bern}}\\) is a probability distribution is anti-climactic.\n\n1.4.1 The Distribution is Non-negative\nClaim: The function \\(f_{\\text{Bern}}\\) must be non-negative for all values of its support given \\(p\\) in the parameter space \\((0,1)\\).\nArgument: If \\(k = 0\\), then \\(f_{\\text{Bern}}(k = 0|p) = p^0(1 - p)^1 = 1 - p \\ge 0\\). Similarly, if \\(k = 1\\), then \\(f_{\\text{Bern}}(k = 1|p) = p^1(1 - p)^0 = p \\ge 0\\).\n\n\n1.4.2 The Total Probability is 1\nClaim: The integral of the function \\(f_{\\text{Bern}}\\) over all possible values of \\(k\\) must be 1.\nArgument: Consider that \\[\n\\begin{aligned}\n\\int_{x \\in \\mathcal{S}} \\text{d}F(x|\\boldsymbol\\theta) &= \\sum\\limits_{k = 0}^1 f_{\\text{Bern}}(k|p) \\\\\n  &= \\left[ p^k(1-p)^{1-k} \\right]_{k = 0} + \\left[ p^k(1-p)^{1-k} \\right]_{k = 1} \\\\\n  &= [p^0(1-p)^1] + [p^1(1-p)^0] \\\\\n  &= (1 - p) + p \\\\\n  &= 1.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/bernoulli_20250310.html#derive-the-moment-generating-function",
    "title": "1  The Bernoulli Distribution",
    "section": "1.5 Derive the Moment Generating Function",
    "text": "1.5 Derive the Moment Generating Function\n\n1.5.1 Review: What is the MGF?\nThe Moment Generating Function4 (MGF) is, as its name implies, a function to “generate” (i.e., calculate) moments. In statistics, I have not found great intuition on what a “moment” is, other than it relates to various measures of a probability distribution:\n\nThe 0\\(^{\\text{th}}\\) moment is the total area of the probability distribution [or 1],\nThe 1\\(^{\\text{st}}\\) moment is the expected value,\nThe 2\\(^{\\text{nd}}\\) (central) moment is the variance,\nThe 3\\(^{\\text{rd}}\\) moment is the skewness, and\nThe 4\\(^{\\text{th}}\\) moment is the kurtosis.\n\nPhysics has more intuition of moments, where the 1\\(^{\\text{st}}\\) moment is the center of mass for a body (the point at which you could balance the shape on a pencil) and the 2\\(^{\\text{nd}}\\) moment is the moment of inertia (how much mass is spread out away from the axis at the center of mass, where larger values mean the mass is spread out further away from the first moment).\nGiven a Cumulative Density Function \\(F_X(x|\\boldsymbol\\theta)\\), the MGF of \\(F_X\\) with respect to some value \\(t\\) in an \\(\\epsilon\\)-neighborhood5 of 0 is defined to be \\[\nM_X(t) \\equiv \\mathbb{E}\\left[ e^{tX} \\right] = \\int\\limits_{x \\in \\mathcal{S}(X)} e^{tx} \\text{d}F_X(x|\\boldsymbol\\theta),\n\\] where \\(\\text{d}F_X\\) is the integrand of a Riemann-Stieltjes integral (as discussed above).\nIf we have a distribution with \\(j\\) parameters, the process to calculate the first \\(j\\) moments is to take the first \\(j\\) derivatives of \\(M_X\\) and evaluate these functions (if they exist) at \\(t = 0\\). Then, these theoretical moments (functions of the distribution’s parameters \\(\\boldsymbol\\theta\\)) are set equal to the first \\(j = |\\boldsymbol\\theta|\\) sample moments, yielding a system of (often non-linear) equations to solve.\n\n\n1.5.2 MGF of the Bernoulli Distribution\nGiven the definition above, we can calculate the MGF: \\[\n\\begin{aligned}\nM_K(t) &\\equiv \\mathbb{E}\\left[ e^{tK} \\right] \\\\\n  &= \\int\\limits_{k \\in \\{0,1\\}} e^{tk} \\text{d}F_K(k|p) \\\\\n  &= \\sum\\limits_{k = 0}^1 e^{tk} p^k (1 - p)^{1 - k} \\\\\n  &= \\sum\\limits_{k = 0}^1 (pe^t)^k (1 - p)^{1 - k} \\\\\n  &= \\left[ (pe^t)^0 (1 - p)^1 \\right] + \\left[ (pe^t)^1 (1 - p)^0 \\right] \\\\\n  &= 1 - p + pe^t.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#method-of-moments-estimators",
    "href": "chapters/bernoulli_20250310.html#method-of-moments-estimators",
    "title": "1  The Bernoulli Distribution",
    "section": "1.6 Method of Moments Estimators",
    "text": "1.6 Method of Moments Estimators\nNow that we have the MGF of the Bernoulli Distribution, we follow the process to calculate the theoretical moment(s) and set them equal to their corresponding sample moment(s). Because the Bernoulli Distribution only has \\(j = 1\\) parameter, our systems to solve will be somewhat trivial.\n\n1.6.1 First Moment\nGiven the MGF calculated above, we begin with \\[\n\\begin{aligned}\nM_K(t) &= 1 - p + pe^t \\\\\n\\Longrightarrow\\qquad \\frac{\\partial}{\\partial t}M_K(t) &= pe^t \\\\\n\\Longrightarrow\\qquad \\frac{\\partial}{\\partial t}M_K(0) &= p \\\\\n&= \\mathbb{E}[X].\n\\end{aligned}\n\\]\n\n\n1.6.2 The Second Moment\nThe second (non-central) moment is then \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial t}M_K(t) &= pe^t \\\\ \\\\\n\\Longrightarrow\\qquad \\frac{\\partial^2}{\\partial t^2}M_K(t) &= pe^t \\\\\n\\Longrightarrow\\qquad \\frac{\\partial^2}{\\partial t^2}M_K(0) &= p \\\\\n&= \\mathbb{E}[X^2].\n\\end{aligned}\n\\]\nBecause this is the non-central moment, we find the second central moment by exploiting the common relationship between variance and moments; that is, \\[\n\\begin{aligned}\n\\text{Var}[X] &= \\mathbb{E}[X^2] - \\mathbb{E}^2[X] \\\\\n&= p - [p]^2 \\\\\n&= p(1 - p).\n\\end{aligned}\n\\]\n\n\n1.6.3 Solving the System\n\nFor distributions with two parameters, we would now equate these two population moments, \\(\\mathbb{E}[X]\\) and \\(\\text{Var}[X]\\), the two sample moments, \\(\\bar{x}\\) and \\(s^2\\), to yield the Method of Moments estimators for the two parameters of the distribution (which we will represent generically as \\(\\hat\\theta_{MoM}\\) and \\(\\hat\\phi_{MoM}\\)).\n\nHowever, the Bernoulli has only one parameter, so our “system” of equations is just \\[\n\\begin{aligned}\n\\bar{x} &= p \\\\\n\\Longrightarrow \\hat{p}_{MoM} &= \\bar{x}.\n\\end{aligned}\n\\] For the data observed above, the coin-flip results \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\) which came from a coin with \\(P[\\text{Heads}] = 0.35\\), \\(\\hat{p}_{MoM} = \\frac{1}{5}\\sum_{i = 1}^5 x_i = 0.4\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#the-likelihood-function",
    "href": "chapters/bernoulli_20250310.html#the-likelihood-function",
    "title": "1  The Bernoulli Distribution",
    "section": "1.7 The Likelihood Function",
    "text": "1.7 The Likelihood Function\nIn standard statistical inference, we assume that the population parameter is some fixed but unknown value and that our observed data are random; we must estimate the unknown (but fixed) parameter using statistics of the observed (but random) data. Likelihood functions (and the related Bayesian school of thought) turn this question “inside out”. The likelihood instead assumes that the parameter is a random variable (still unknown), but that the data are both observed and fixed.\n\n1.7.1 Reviewing the Repeated Sampling Paradigm\nLet’s recall the observed toy data: we flipped one coin five times and observed \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\). Is the coin fair? Traditional statistics would say “\\(p\\) is unknown, but if I can collect enough data then I can estimate it with a narrow confidence interval”. In a simple coin-flip example, this is reasonable: we can hire a person to repeatedly flip that same coin for hours and hours and record the results. Eventually, we will have a sample size large enough so that we can build a confidence interval small enough to say with any requested level of “confidence” that the coin is or isn’t fair.\nRecall the \\((1-\\alpha)\\)-level confidence interval for a Bernoulli \\(p\\) is \\[\n\\text{CI}(p|n,\\alpha) =\n  \\hat{p} \\pm \\frac{z_{\\alpha/2}}{\\sqrt{n}}\\sqrt{\\hat{p}(1 - \\hat{p})},\n\\] where \\(z_{\\alpha/2}\\) is the Standard Normal \\(z\\) corresponding to the quantiles \\(1 - \\alpha/2\\) and \\(\\alpha/2\\). As we saw above, the true parameter value was \\(p = 0.35\\), which (we remark) would be impossible to know in real life.\nWe will assume that we take each coin flip one at a time. How many times will we have to flip the coin before the 95% CI no longer contains 0.5?\n\n\nCode\nzAlpha &lt;- qnorm(p = 0.975)\nresults_ls &lt;- lapply(\n  X = seq.int(from = 2, to = length(myBernSample), by = 1),\n  FUN = function(n_i) {\n    \n    x &lt;- myBernSample[1:n_i]\n    pHat &lt;- mean(x)\n    CIwidth &lt;- ( zAlpha / sqrt(n_i) ) * sqrt( pHat * (1 - pHat) )\n    \n    data.frame(\n      N = n_i,\n      pHat = pHat,\n      CIlb = pHat - CIwidth,\n      CIub = pHat + CIwidth\n    )\n  }\n)\n\nresults_df &lt;- do.call(rbind, results_ls)\n\n# add trivial CI results for first coin flip\nresults_df &lt;- rbind(\n  data.frame(\n    N = 1, pHat = myBernSample[1],\n    CIlb = myBernSample[1], CIub = myBernSample[1]\n  ),\n  results_df\n)\n\n\nLet’s plot these results:\n\n\nCode\nlibrary(ggplot2)\nggplot(data = results_df) + \n  aes(x = N) +\n  ylim(c(0, 1)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  geom_abline(slope = 0, intercept = 0.5, colour = \"red\") + \n  geom_line(aes(y = CIlb)) + \n  geom_line(aes(y = CIub))\n\n\n\n\n\n\n\n\n\nAs we can see, we need between 40-45 coin flips before we can be 95% sure that the coin is “not fair” (that the true value of \\(p\\ne 0.5\\)). Also, we see that the confidence intervals are degenerate for a few of the samples with \\(n\\le 5\\) (that the bounds of the confidence interval for \\(p\\) are outside \\([0,1]\\), which is impossible).\n\n\n1.7.2 Making the Most Use of our Data\nFor the computer, flipping additional coins to create new data is trivially inexpensive. However, in real life, collecting one additional sample may be of enormous cost to the research team. In these cases, it doesn’t help us that we would theoretically be able to reject the claim that \\(p = 0.5\\) at some point in the future (with more samples), we need to be able to make a statement about the likelihood that the coin is fair with the samples we have right now. Let the event \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\) be encoded \\(\\textbf{x} = (1,0,1,0,0)\\). Thus, we apply the multiplication rule of independent events for these five coin flips, and define the likelihood function of \\(p\\) given the observed data:\n\\[\\begin{align}\n\\mathcal{L}(p|\\textbf{x}) &=\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 1} \\times\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 0} \\times \\\\\n  &\\qquad \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 1} \\times\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 0} \\times\n  \\left[ p^k(1 - p)^{1 - k} \\right]_{k = 0} \\\\\n  \n  &= \\left[ p^1 \\right] \\times \\left[ (1 - p)^1 \\right] \\times\n  \\left[ p^1 \\right] \\times \\left[ (1 - p)^1 \\right] \\times \\left[ (1 - p)^1 \\right] \\\\\n  &= p^2(1 - p)^3 \\\\\n  &= p^2(1 - 3p + 3p^2 - p^3) \\\\\n  &= p^2 - 3p^3 + 3p^4 - p^5.\n\\end{align}\\]\n\n\n1.7.3 Integrating the Likelihood\nThis function \\(\\mathcal{L}\\) contains almost all the information we have about \\(p\\): it has all the data, and it has our best guess about the data generating process (we think it’s a Bernoulli trial). A few things to notice:6\n\n\\(\\mathcal{L}\\) is a function of the parameter, \\(p\\), not of the data.\n\\(\\mathcal{L}\\) is NOT a probability function; even though \\(\\mathcal{L} \\ge 0\\ \\forall p\\), we have that the integral over the support of \\(p\\) is\n\n\\[\\begin{align}\n\\int_0^1 \\mathcal{L}(p|\\textbf{x})dp &=\n  \\int_0^1 \\left[ p^2 - 3p^3 + 3p^4 - p^5 \\right]dp \\\\\n  &= \\frac{1}{3}p^3 - \\frac{3}{4}p^4 + \\frac{3}{5}p^5 - \\frac{1}{6}p^6 \\Big\\rvert_0^1 \\\\\n  &= \\frac{1}{3} - \\frac{3}{4} + \\frac{3}{5} - \\frac{1}{6} \\\\\n  &= \\frac{20}{60} - \\frac{45}{60} + \\frac{36}{60} - \\frac{10}{60} \\\\\n  &= \\frac{1}{60} \\\\\n  &\\ne 1\n\\end{align}\\]\nThis exercise serves two purposes: first to show that \\(\\mathcal{L}\\) is not a probability distribution, and second to show the value of the multiplicative constant which would make a distribution. That is, \\(f(p|\\textbf{x}) = 60*\\mathcal{L}(p|\\textbf{x})\\) is a probability distribution. Now we can make probabilistic statements about the value of \\(p\\).\nWe can see what the probability distribution function looks like (it should look like a Beta distribution, because it is):\n\n\nCode\np &lt;- seq(from = 0, to = 1, length.out = 101)\nf_p &lt;- 60 * p^2 * (1 - p)^3\n\nplot(x = p, y = f_p)\n\n\n\n\n\n\n\n\n\nAnd since we have calculated the indefinite integral already, we can plot the Cumulative Distribution Function:\n\n\nCode\nF_p &lt;- 60 * (p^3/3 - 3*p^4/4 + 3*p^5/5 - p^6/6)\nplot(x = p, y = F_p)\n\n\n\n\n\n\n\n\n\nFinally, we can make statements about the claim that \\(p = 0.5\\). For instance, what is \\(P[p &lt; 0.5]\\)?\n\nF_p[which(p == 0.5)]\n[1] 0.656\n\nWhat is \\(P[p &gt; 0.5]\\)?\n\n1 - F_p[which(p == 0.5)]\n[1] 0.344\n\nWhat is \\(P[0.4 &lt; p &lt; 0.6]\\)?\n\nF_p[which(p == 0.6)] - F_p[which(p == 0.4)]\n[1] 0.365\n\nWhat is an 80% credible set7 for \\(p\\)?\n\n# Lower\np[max(which(F_p &lt; 0.1))]\n[1] 0.2\n# Upper\np[min(which(F_p &gt; 0.9))]\n[1] 0.67",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#maximum-likelihood-estimators-the-most-likely-value-of-p",
    "href": "chapters/bernoulli_20250310.html#maximum-likelihood-estimators-the-most-likely-value-of-p",
    "title": "1  The Bernoulli Distribution",
    "section": "1.8 Maximum Likelihood Estimators: The “Most Likely” Value of \\(p\\)",
    "text": "1.8 Maximum Likelihood Estimators: The “Most Likely” Value of \\(p\\)\nWe have an integrated likelihood, which contains basically almost all there is to know about the data we’ve collected, but finding a closed form of the integral of \\(\\mathcal{L}\\) (necessary to find \\(f\\) and \\(F\\)) can be impossible in most real-world scenarios. Rather than trying to answer all the questions about \\(p\\), sometimes it’s still worthwhile to answer “what is the most likely value of \\(p\\) given the data we’ve observed?”\nThis is answered with maximum likelihood estimation, and we need two steps. Using (multivariable) differential calculus, we\n\nfind the value of \\(\\boldsymbol\\theta\\) which maximizes \\(\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x})\\), and\nshow that \\(\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x})\\) is concave down8 at this point.\n\nFor the first step, it is common practice to 1) disregard any multiplicative constants leading \\(\\mathcal{L}\\) (because the derivative in the next step will zero these constants out) and 2) to take the natural logarithm of the likelihood and maximize that instead. Because logarithms simply change the scale of the vertical axis, they do not affect the location of extreme values. Let’s begin (I show what happens to the multiplicative constant in square brackets):\n\\[\\begin{align}\n\\mathcal{L}(p|\\textbf{x}) &= [60\\times]\\ p^2(1 - p)^3,\\ p\\in[0,1] \\\\\n\\Longrightarrow \\qquad \\ell(p|\\textbf{x}) &= [\\log(60) +]\\ 2\\log(p) + 3\\log(1 - p),\\ p\\in(0,1) \\\\\n\\Longrightarrow \\qquad \\frac{\\partial\\ell}{\\partial p} &= [0+]\\ \\frac{2}{p} - \\frac{3}{1 - p} \\\\\n\\Longrightarrow \\qquad 0 &\\overset{\\text{set}}{=} \\frac{2}{p} - \\frac{3}{1 - p} \\\\\n\\Longrightarrow \\qquad 0 &= 2(1 - p) - 3p \\\\\n\\Longrightarrow \\qquad \\hat{p} &= 2/5\n\\end{align}\\]\nThe second step is to confirm that \\(\\hat{p} = \\frac{2}{5}\\) is a maximum of \\(\\mathcal{L}\\), by ensuring that the second derivative of \\(\\mathcal{L}\\) is negative around \\(\\hat{p}\\). For that, we return to the first derivative of the log-likelihood (I’m using negative exponents instead of fractions because the chain rule is easier to apply than the quotient rule for these fractions), and differentiate again:\n\\[\\begin{align}\n\\frac{\\partial\\ell}{\\partial p} &= 2p^{-1} - 3(1 - p)^{-1} \\\\\n\\Longrightarrow \\qquad \\frac{\\partial^2\\ell}{\\partial p^2} &= -2p^{-2} + 3(1 - p)^{-2}\\times(-1) \\\\\n&= -\\left( \\frac{2}{p^2} + \\frac{3}{(1 - p)^2} \\right) &lt;0\\ \\forall p \\in (0,1).\n\\end{align}\\]\nSo, for this trivial example, both Method of Moments and Maximum Likelihood Estimation yielded the same estimate for \\(\\hat{p}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#exercises",
    "href": "chapters/bernoulli_20250310.html#exercises",
    "title": "1  The Bernoulli Distribution",
    "section": "1.9 Exercises",
    "text": "1.9 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/bernoulli_20250310.html#footnotes",
    "href": "chapters/bernoulli_20250310.html#footnotes",
    "title": "1  The Bernoulli Distribution",
    "section": "",
    "text": "https://www.usu.edu/math/schneit/StatsStuff/Probability/probability2.html↩︎\nif and only if↩︎\n(https://en.wikipedia.org/wiki/Telescoping_series)↩︎\nhttps://en.wikipedia.org/wiki/Moment-generating_function↩︎\n\\(t \\in (-\\epsilon, \\epsilon) \\subset \\mathbb{R}\\) (where \\(\\epsilon\\) is an arbitrarily small value)↩︎\nWe could also notice that this is the kernel of a Beta distribution with \\(\\alpha = 3\\) and \\(\\beta = 4\\), with normalizing constant \\(\\frac{(3-1)!(4-1)!}{(3+4-1)!} = \\frac{2}{6*5*4} = \\frac{1}{60}\\), but that would make the next steps too easy…↩︎\nhttps://en.wikipedia.org/wiki/Credible_interval↩︎\nhttps://tutorial.math.lamar.edu/classes/calci/shapeofgraphptii.aspx↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Bernoulli Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html",
    "href": "chapters/binomial_20250310.html",
    "title": "2  The Binomial Distribution",
    "section": "",
    "text": "2.1 Deriving the Distribution\nIn the previous chapter, we explored the properties of a Bernoulli trial. We envisioned a scenario where a person flipped a coin five times, and the results were \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\). What we knew, but the hypothetical person did no know, was that this particular coin was not “fair”. In fact, these five observations were drawn from a Bernoulli process with \\(P[\\text{Heads}] = 0.35\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#deriving-the-distribution",
    "href": "chapters/binomial_20250310.html#deriving-the-distribution",
    "title": "2  The Binomial Distribution",
    "section": "",
    "text": "2.1.1 A Primer on Exchangeability\nWhat if we saw \\(\\{\\)Heads, Tails, Tails, Heads, Tails\\(\\}\\) instead? The total number of heads and tails flipped is the same, but the order is different. Does that affect our estimate of \\(p\\)? In order to generalize this experiment a bit, we need to use the principle of exchangeability.1 The general idea of exchangeability is that the order of the observed flips doesn’t matter; i.e., that the coin doesn’t remember flipping a “Head” first then a “Tail”. Recall that we encoded the observed flips as \\(\\textbf{x} = (1,0,1,0,0)\\). Therefore, if the order doesn’t matter, then all these rows will give us the same information about \\(p\\):\n\n# Thanks to ChatGPT for finding this package for me.\ncquad::sq(J = 5, s = 2)\n      [,1] [,2] [,3] [,4] [,5]\n [1,]    0    0    0    1    1\n [2,]    0    0    1    0    1\n [3,]    0    0    1    1    0\n [4,]    0    1    0    0    1\n [5,]    0    1    0    1    0\n [6,]    0    1    1    0    0\n [7,]    1    0    0    0    1\n [8,]    1    0    0    1    0\n [9,]    1    0    1    0    0\n[10,]    1    1    0    0    0\n\nWe see that there are 10 rows here, showing the 10 ways that we could flip \\(| \\textbf{x}| = 5\\) coins sequentially and only see 2 heads2. While each of these rows shows the outcomes of different events, the resulting probability functions will be the same because of the commutative property of multiplication. That is, the likelihood function for the first row: \\[\n\\prod\\limits_{k = (0, 0, 0, 1, 1)} \\left[ p^{k_i}(1 - p)^{1 - k_i} \\right] = p^{\\sum_k k_i}(1 - p)^{\\sum_k (1 - k_i)} = p^2(1 - p)^3;\n\\] yields the same polynomial as the likelihood function for the last row: \\[\n\\prod\\limits_{k = (1, 1, 0, 0, 0)} \\left[ p^{k_i}(1 - p)^{1 - k_i} \\right] = p^{\\sum_k k_i}(1 - p)^{\\sum_k (1 - k_i)} = p^2(1 - p)^3.\n\\] The likelihood functions will be the same for all 10 rows.\n\n\n2.1.2 The Binomial Coefficient\nLet’s pretend that a prophet tells us that that the next time we flip \\(n = 5\\) coins we will see \\(k = 2\\) heads. We haven’t flipped any coins yet, but we have a vision of the future. If we encode 1 for heads and 0 for tails, we know that what is about to happen when we flip these 5 coins can be described by one of the 10 rows above. But how did we get there?\nTo make this process easier to explain, let’s flip 5 coins and leave them on the table, so that we can “see” our results as they happen. The 10 rows of the matrix above are based on the logic of this process:\n\nBefore I flip any coins, there are \\(n = 5\\) coins in my hand. I haven’t flipped any coins yet, so all my options are available. There are 5 ways to flip one head.\nI flip the first coin, and after I set that coin aside, I have \\(n - 1 = 4\\) coins left for me to flip. There are still 4 ways to flip one head.\nI flip the second coin, and set it aside. I now have \\(n - 2 = 3\\) coins left to flip. There are 3 ways left to flip one head.\nI flip the third coin, and set it aside. Now things get interesting: I have \\(n = k = 2\\) coins left. If I have already flipped two heads in the first three flips, then I know the next two flips must be tails. If I haven’t flipped any heads in the first three flips, then I know the next two flips must be heads. If I’ve only flipped one head in the first three flips, then I know that one of the two next flips will be heads and the other will be tails (but I don’t know which is which).\nI flip the fourth coin and set it aside. The prophet already told me there would only be 2 heads in 5 flips, so the next flip is completely determined. If I have already flipped 2 heads with the first four coins, then this flip MUST be tails. If I’ve only flipped 1 head on the first four coins, then this flip MUST be heads. There is only one possible outcome, and it is predetermined to occur.\n\nIf we hadn’t been told by a prophet ahead of time that we would see two heads, then there would be \\(n\\) options for the first flip (I haven’t decided which coin to pick up yet, so that’s why I have 5 choices), \\(n - 1\\) for the second, all the way down to 1 way to flip at the end. That tells us there are \\(n!\\) ways these flips could have happened. There would have been \\(5\\times 4\\times 3\\times 2 = 120 = n!\\) (this \\(\\\\!\\) symbol denotes the factorial3 of an integer) possible orderings and configurations of heads and tails. However, in our process, we’ve already assumed exchangeability, so the order of the flips does not matter. Not only that, but we are further limited: the prophet informed us that we MUST see exactly \\(k = 2\\) heads and \\(n - k = 3\\) tails. Because we use multiplication to “add” new possibilities, we must use division to take away these excluded possibilities. Since we must have \\(k = 2\\) heads, we remove 2 opportunities to flip tails; since we must have \\(n - k = 3\\) tails, we remove 3 opportunities to flip heads. Therefore, the number of options will be: \\[\n\\frac{|\\text{all results}|}{|\\text{removed tails results}| \\times |\\text{removed heads results}|} = \\frac{5!}{2!\\times 3!} = \\frac{120}{2 \\times 6} = 10.\n\\]\n\nWe then define the Binomial Coefficient as \\[\n{n \\choose k} \\equiv \\frac{n!}{k!(n - k)!}.\n\\]\n\n\n2.1.3 Constructing the Distribution\nTo recap, we now have:\n\na statement about the likelihood of a single binary event, of which \\(k = 1\\) denotes one class and \\(k = 0\\) denotes its complement (the other binary class): \\(p^k(1 - p)^{1 - k}\\),\nan experiment that yields a set of \\(n\\) such independent and exchangeable binary events, and\na way to count all the ways that these events could possibly occur: \\(\\frac{n!}{k!(n - k)!}\\).\n\nLet us assume that the number of trials, \\(n\\), is known. We will now construct a probability function for the random variable \\(k = 0, 1, \\ldots, n\\). We still assume independence and exchangeability, so the probability of success, \\(p\\), is fixed. Then, this function will first have a the binomial coefficient, then the probability to observe \\(k\\) successes, and finally the probability to observe \\(n - k\\) failures. Thus, the Binomial Distribution is:\n\\[\nf(k|n,p) \\equiv {n \\choose k} p^{k}(1 - p)^{n - k}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#example-random-samples",
    "href": "chapters/binomial_20250310.html#example-random-samples",
    "title": "2  The Binomial Distribution",
    "section": "2.2 Example Random Samples",
    "text": "2.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nN &lt;- 10\nbins_int &lt;- seq.int(from = -1, to = N, by = 1)\n\nxSymm &lt;- rbinom(n = 100, size = N, prob = 0.5)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n15  = xSymm[1:15],\n  n30  = xSymm[1:30],\n  n100 = xSymm\n)\n\nxSkew &lt;- rbinom(n = 100, size = N, prob = 0.2)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n15  = xSkew[1:15],\n  n30  = xSkew[1:30],\n  n100 = xSkew\n)\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSymm_ls$n5, breaks = bins_int)\nhist(samplesSymm_ls$n15, breaks = bins_int)\nhist(samplesSymm_ls$n30, breaks = bins_int)\nhist(samplesSymm_ls$n100, breaks = bins_int)\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSkew_ls$n5, breaks = bins_int)\nhist(samplesSkew_ls$n15, breaks = bins_int)\nhist(samplesSkew_ls$n30, breaks = bins_int)\nhist(samplesSkew_ls$n100, breaks = bins_int)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#formal-foundations",
    "href": "chapters/binomial_20250310.html#formal-foundations",
    "title": "2  The Binomial Distribution",
    "section": "2.3 Formal Foundations",
    "text": "2.3 Formal Foundations\n\n2.3.1 Pascal’s Rule\nFor writing proofs involving combinations, we need the following property, known as Pascal’s Formula,4 which states that\n\\[\n{a \\choose b} = {a - 1 \\choose b} + {a - 1 \\choose b - 1}.\n\\]\nProof: For integers \\(a,b\\), we construct this identity directly via simplification: \\[\n\\begin{aligned}\n{a - 1 \\choose b} + {a - 1 \\choose b - 1} &=\n  \\frac{(a - 1)!}{b!(a - b - 1)!} + \\frac{(a - 1)!}{(b - 1)!(a - 1 - b + 1)!} \\\\\n  &= \\frac{a - b}{a - b}\\left[ \\frac{(a - 1)!}{b!(a - b - 1)!} \\right] + \\frac{b}{b} \\left[ \\frac{(a - 1)!}{(b - 1)!(a - b)!} \\right] \\\\\n  &= \\frac{a(a - 1)! - b(a - 1)!}{b!(a - b)(a - b - 1)!} + \\frac{b(a - 1)!}{b(b - 1)!(a - b)!} \\\\\n  &= \\frac{a! - b(a - 1)!}{b!(a - b)!} + \\frac{b(a - 1)!}{b!(a - b)!} \\\\\n  &= \\frac{a!}{b!(a - b)!} \\\\\n  &\\equiv {a \\choose b}.\n\\end{aligned}\n\\]\n\n\n2.3.2 Mathematical Induction\nThe next foundational proof requires a technique called “Proof by Induction”, or more generally, mathematical induction.5 This is the structure of such a proof:\n\nProof by Induction: Consider a sequence of equations indexed over the integers by \\(n\\). To show that the sequence of equations is true \\(\\forall n\\), we\n\nshow that the equation is true for \\(n = 1\\) [the “base case”],\nassume that the equation is true for \\(n = i\\) [the “hypothesis”], then\nprove that the equation is true for \\(n = i + 1\\) from the case when \\(n = i\\) [the “induction”].\n\n\nHere is a trivial example. Let’s prove \\(\\forall k \\in\\mathbb{N} \\ge 5\\) that \\(2^k &lt; \\Gamma(k + 1)\\) (the point of this proof is to show that the factorial function increases more rapidly to \\(\\infty\\) than the exponential function). Our base case is for \\(k = 5\\). We know that \\(2^5 = 32\\) and \\(\\Gamma(k + 1) = k! = 5! = 120\\). Because \\(32 &lt; 120\\), the base case is true. Our hypothesis, what we assume to be true, is that \\(2^i &lt; \\Gamma(i + 1)\\). To logically induct, we assume our hypothesis is true, and then show that our hypothesis implies that \\(2^{i + 1} &lt; \\Gamma(i + 2)\\). That is \\[\n\\begin{aligned}\n2^{i+1} &\\overset{?}{&lt;} \\Gamma(i + 2) \\\\\n\\Longrightarrow 2 \\times 2^i &\\overset{?}{&lt;} i \\times \\Gamma(i + 1) \\\\\n\\Longrightarrow \\frac{2}{i} \\times 2^i &&lt; \\Gamma(i + 1),\n\\end{aligned}\n\\] which is true for \\(i \\ge 5\\) because our hypothesis was that \\(2^i &lt; \\Gamma(i + 1)\\). Thus, \\(2^k &lt; \\Gamma(k + 1)\\ \\forall k \\in\\mathbb{N} \\ge 5\\), which completes our proof.\n\n\n2.3.3 Mathematical Induction Proof of the Binomial Theorem\nFor this section, we will also need to use the Binomial Theorem:6\n\\[\n(x +  y)^n = \\sum_{k = 0}^n {n \\choose k} x^k y^{n - k}.\n\\]\nBefore we can use this, we must prove that it is true.\n\n2.3.3.1 The Base Case\nLet \\(n = 1\\). Then\n\\[\n\\begin{aligned}\n\\sum_{k = 0}^1 {1 \\choose k} x^k y^{1 - k} &=\n  \\left[ {1 \\choose 0} x^0 y^{1 - 0} \\right] + \\left[ {1 \\choose 1} x^1 y^{1 - 1} \\right] \\\\\n  &= \\frac{1!}{0!\\times 1!} (1) y^1 + \\frac{1!}{1!\\times 0!} x^1(1) \\\\\n  &= y + x \\\\\n  &= (x + y)^1.\n\\end{aligned}\n\\]\n\n\n2.3.3.2 The Hypothesis\nWe assume that this equation is true for \\(n = i\\). That is, we assume that\n\\[\n\\sum_{k = 0}^i {i \\choose k} x^k y^{i - k} = (x + y)^i.\n\\]\n\n\n2.3.3.3 The Induction\nAssuming that the hypothesis for \\(n = i\\) is true, we will show that the equation also holds for \\(n = i + 1\\). Note that the end of the proof requires Pascal’s Rule to combine sums of combinations, and we comment that there is only one way to “choose” 0 things or all things. Thus,\n\\[\n\\begin{aligned}\n(x + y)^i &= \\sum_{k = 0}^i {i \\choose k} x^k y^{i - k} \\\\\n\\Longrightarrow (x + y)^{i + 1} &= (x + y)\\sum_{k = 0}^i {i \\choose k} x^k y^{i - k} \\\\\n  &= (x + y)\\left[ {i \\choose 0} x^0 y^{i - 0} + {i \\choose 1} x^1 y^{i - 1} + \\ldots + {i \\choose i - 1} x^{i - 1} y^1 + {i \\choose i} x^{i - 0} y^0 \\right] \\\\\n  &= x\\left[ {i \\choose 0} x^0 y^i + {i \\choose 1} x^1 y^{i - 1} + \\ldots + {i \\choose i - 1} x^{i - 1} y^1 + {i \\choose i} x^i y^0 \\right] + \\\\\n  &\\quad\\ \\  y\\left[ {i \\choose 0} x^0 y^i + {i \\choose 1} x^1 y^{i - 1} + \\ldots + {i \\choose i - 1} x^{i - 1} y^1 + {i \\choose i} x^i y^0 \\right] \\\\\n  &= \\left[ {i \\choose 0} x^1 y^i + {i \\choose 1} x^2 y^{i - 1} + \\ldots + {i \\choose i - 1} x^i y^1 + {i \\choose i} x^{i+1} y^0 \\right] + \\\\\n  &\\quad\\  \\left[ {i \\choose 0} x^0 y^{i + 1} + {i \\choose 1} x^1 y^i + \\ldots + {i \\choose i - 1} x^{i - 1} y^2 + {i \\choose i} x^i y^1 \\right] \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{Collect like terms...}} \\\\\n  &= {i \\choose 0} x^0 y^{i + 1} + \\\\\n  &\\qquad \\left[ {i \\choose 0} x^1 y^i + {i \\choose 1} x^1 y^i\\right] + \\ldots + \\left[ {i \\choose i - 1} x^i y^1 + {i \\choose i} x^i y^1 \\right] + \\\\\n  &\\qquad {i \\choose i} x^{i+1} y^0 \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{Only one way to choose all or none...}} \\\\\n  &= (1) x^0 y^{i + 1} + \\\\\n  &\\qquad \\left[ {i \\choose 0} + {i \\choose 1} \\right]x^1 y^i + \\ldots + \\left[ {i \\choose i - 1} + {i \\choose i} \\right]x^i y^1 + \\\\\n  &\\qquad (1) x^{i+1} y^0 \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{Pascal's Rule...}} \\\\\n  &= (1) x^0 y^{i + 1} + \\\\\n  &\\qquad \\left[ {i + 1 \\choose 1} \\right]x^1 y^i + \\ldots + \\left[ {i + 1 \\choose i} \\right]x^i y^1 + \\\\\n  &\\qquad (1) x^{i+1} y^0 \\\\\n  &= {i + 1 \\choose 0} x^0 y^{i + 1} + {i + 1 \\choose 1}x^1 y^i + \\ldots + {i + 1 \\choose i}x^i y^1 + {i + 1 \\choose i + 1} x^{i+1} y^0 \\\\\n  \\\\[0.1mm]\n  &\\qquad \\text{\\emph{By definition...}} \\\\\n  &= \\sum_{k = 0}^{i + 1} {i + 1 \\choose k} x^k y^{i + 1 - k}.\n\\end{aligned}\n\\]\nTherefore, \\(\\forall n \\in \\mathbb{N}\\), \\[\n\\sum_{k = 0}^n {n \\choose k} x^k y^{n - k} = (x + y)^n.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/binomial_20250310.html#show-that-this-is-a-distribution",
    "title": "2  The Binomial Distribution",
    "section": "2.4 Show that this is a Distribution",
    "text": "2.4 Show that this is a Distribution\nLet \\(\\mathcal{S} = \\mathbb{N} \\cup 0\\), where \\(\\mathbb{N}\\) denotes the set of natural numbers.7 Let \\(f(k|n,p) = {n \\choose k} p^{k}(1 - p)^{n - k}\\) represent the probability function of the Binomial Distribution. We must now show that\n\n\\(\\forall k \\in \\mathcal{S}\\), and for \\(p \\in (0,1)\\), \\(f(k|n, p) \\ge 0\\), and\nfor \\(p \\in (0,1)\\), \\(\\int_{k \\in \\mathcal{S}} \\text{d}F(k|n,p) = 1\\).\n\n\n2.4.1 The Distribution is Non-negative\nConsider \\(f\\) defined above. First, we notice that the Binomial Coefficient is defined as a ratio of factorials; the standard definition of factorials only includes the natural numbers (\\(\\mathbb{N}\\)), so they are necessarily positive. The ratio of two positive numbers is positive. Second, we have that \\(k,\\ n - k \\ge 0\\), and that \\(p &gt; 0\\). Non-negative powers of positive numbers are also positive. Setting \\(p = 0\\) yields a degenerate distribution anyway, so we don’t bother with it. Putting these together for \\(p \\in (0,1)\\), we have that \\(f = 0\\) outside the support of \\(k\\) and \\(f &gt; 0\\) for \\(k \\le n, \\ni \\{k,\\ n\\} \\in \\mathcal{S}\\).\n\n\n2.4.2 The Total Probability is 1\nRecall the Binomial Theorem we proved above, and let \\(x = p\\) and \\(y = 1 - p\\). Then, \\[\n\\begin{aligned}\n\\int_{k \\in \\mathcal{S}} \\text{d}F(k|n,p) &= \\sum_{k = 0}^n {n \\choose k} p^{k}(1 - p)^{n - k} \\\\\n  &= \\left[ p + (1 - p) \\right]^n \\\\\n  &= 1^n \\\\\n  &= 1.\n\\end{aligned}\n\\]\nTherefore, because the function \\(f(k|n,p)\\) is always non-negative and it’s Riemann-Stieljes integral is 1, the Binomial Distribution is a true distribution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/binomial_20250310.html#derive-the-moment-generating-function",
    "title": "2  The Binomial Distribution",
    "section": "2.5 Derive the Moment Generating Function",
    "text": "2.5 Derive the Moment Generating Function\nDeriving the MGF for the Binomial is a straightforward application of the definition and Binomial Theorem. That is, \\[\n\\begin{aligned}\nM_k(t) &\\equiv \\mathbb{E}\\left[ e^{tX} \\right] \\\\\n  &= \\int\\limits_{k \\in \\mathcal{S}(K)} e^{tk} \\text{d}F_K(k|n,p) \\\\\n  &= \\sum\\limits_{k = 0}^n e^{tk} {n \\choose k} p^{k}(1 - p)^{n - k} \\\\\n  &= \\sum\\limits_{k = 0}^n {n \\choose k} \\left[e^t\\right]^k p^{k}(1 - p)^{n - k} \\\\\n  &= \\sum\\limits_{k = 0}^n {n \\choose k} \\left[e^tp\\right]^k (1 - p)^{n - k} \\\\\n  &= \\left[ e^tp + (1 - p) \\right]^n.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#method-of-moments-estimators",
    "href": "chapters/binomial_20250310.html#method-of-moments-estimators",
    "title": "2  The Binomial Distribution",
    "section": "2.6 Method of Moments Estimators",
    "text": "2.6 Method of Moments Estimators\nNow that we have this MGF, we can find the Method of Moments (MoM) estimator for \\(p\\), and we will comment on such an estimator for \\(n\\) when it is unknown.\n\n2.6.1 The First Moment\nWe have that \\[\n\\begin{aligned}\nM_k(t) &= \\left[ e^tp + (1 - p) \\right]^n \\\\\n\\Longrightarrow M^{\\prime}_k(t) &= \\frac{\\partial}{\\partial t} \\left[ e^tp + (1 - p) \\right]^n \\\\\n  &= n \\left[ e^tp + (1 - p) \\right]^{n - 1} \\frac{\\partial}{\\partial t} \\left[ e^tp + (1 - p) \\right] \\\\\n  &= n \\left[ e^tp + (1 - p) \\right]^{n - 1} e^tp \\\\\n\\Longrightarrow M^{\\prime}_k(0) &= n \\left[ (1)p + (1 - p) \\right]^{n - 1} (1)p \\\\\n  &= n(1)^{n - 1}p \\\\\n  &= np.\n\\end{aligned}\n\\] Therefore, \\(\\mathbb{E}[k] = np\\).\n\n\n2.6.2 The Second Non-Central Moment\nTaking the second derivative with respect to \\(t\\), we have \\[\n\\begin{aligned}\nM^{\\prime}_k(t) &= ne^tp \\left[ e^tp + (1 - p) \\right]^{n - 1} \\\\\n\\Longrightarrow M^{\\prime\\prime}_k(t) &= ne^tp \\frac{\\partial}{\\partial t} \\left[ e^tp + (1 - p) \\right]^{n - 1} + \\left[ e^tp + (1 - p) \\right]^{n - 1} \\frac{\\partial}{\\partial t} ne^tp \\\\\n  &= ne^tp \\times (n - 1) \\left[ e^tp + (1 - p) \\right]^{n - 2} e^tp + \\left[ e^tp + (1 - p) \\right]^{n - 1} ne^tp \\\\\n\\Longrightarrow M^{\\prime\\prime}_k(0) &= n(1)p \\times (n - 1) \\left[ (1)p + (1 - p) \\right]^{n - 2} (1)p + \\left[ (1)p + (1 - p) \\right]^{n - 1} n(1)p \\\\\n  &= np^2 (n - 1) (1)^{n - 2} + np (1)^{n - 1} \\\\\n  &= np \\left[(n - 1)p + 1\\right].\n\\end{aligned}\n\\] Therefore, \\(\\mathbb{E}[k^2] = np(np - p + 1)\\).\n\n\n2.6.3 The Second Central Moment\nThus \\[\n\\begin{aligned}\n\\text{Var}[k] &= \\mathbb{E}[k^2] - \\left(\\mathbb{E}[k]\\right)^2 \\\\\n  &= np(np - p + 1) - \\left( np \\right)^2 \\\\\n  &= np \\left[ np - p + 1 - np \\right] \\\\\n  &= np (1 - p).\n\\end{aligned}\n\\]\n\nTechnically, we don’t need the second central moment for this distribution to find the Method of Moments estimators, but it is good practice.\n\n\n\n2.6.4 Solving the System of Equations\nNow that we have the first two population moments, \\(\\mathbb{E}[k]\\) and \\(\\text{Var}[k]\\), we can set them equal to the first two sample moments. That is, we solve the system \\[\n\\left\\{ \\mathbb{E}[k] = \\frac{1}{N} \\sum_{i = 1}^N k_i;\\ \\mathbb{E}[k^2] = \\frac{1}{N} \\sum_{i = 1}^N k_i^2 \\right\\},\n\\] where \\(N\\) is the number of Bernoulli trials in each Binomial experiment and \\(k_i\\) is the number of successes out of \\(N\\) attempts in Binomial experiment \\(i\\). For our example data, we were discussing the first such experiment, with observed data \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\); so we are on Binomial experiment \\(i\\), the number of coin flips was \\(N = 5\\), and we observed \\(k_i = 2\\) heads.\nGiven repeated \\(n\\) Binomial experiments of \\(N\\) Bernoulli trials each, we then solve the following system of equations: \\[\n\\left\\{ np = \\frac{1}{N} \\sum_{i = 1}^N k_i;\\ np(np - p + 1) = \\frac{1}{N} \\sum_{i = 1}^N k_i^2 \\right\\}.\n\\] Very often, \\(n\\) is known, so this simplifies to solving \\(\\hat{p}_{MoM} = \\frac{1}{nN} \\sum_{i = 1}^N k_i\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "2  The Binomial Distribution",
    "section": "2.7 Method of Moments Estimates from Observed Data",
    "text": "2.7 Method of Moments Estimates from Observed Data\nRecall our “observed” data: \\(\\{\\)Heads, Tails, Heads, Tails, Tails\\(\\}\\). This was an observation from 5 independent Bernoulli trials or only ONE Binomial experiment with \\(N=5\\) and \\(k = 2\\). We need more than \\(n = 1\\) if we want to estimate moments! If you remember the introduction, we generated this data from a Bernoulli process with \\(p = 0.35\\). Let’s generate some more samples, this time we will have \\(n = 7\\) experiments where we flipped \\(N = 5\\) coins each time, with the same probability of success \\(p = 0.35\\) as before:\n\n\nCode\n# Reset our seed\nset.seed(20150516)\n\n# Generate our sample\nobserved_int &lt;- rbinom(\n  n = 7,      # number of Binomial experiments\n  size = 5,   # number of Bernoulli Trials per experiment\n  prob = 0.35 # probability of success for each Bernoulli Trial\n)\n\n# Inspect\nobserved_int\n[1] 3 1 2 3 1 0 1\n\n\nFor these 7 Binomial trials (each with 5 flips), we observed the following number of heads: 3, 1, 2, 3, 1, 0, 1.\n\n2.7.1 Case When \\(n\\) is Known\nThis is the most common case. Recall that we need the averages of \\(k_i\\) and \\(k_i^2\\), so let’s calculate these first.\n\n\nCode\nk_df &lt;- \n  tibble(k = observed_int) %&gt;% \n  mutate(k2 = k^2)\nk_df\n# A tibble: 7 × 2\n      k    k2\n  &lt;int&gt; &lt;dbl&gt;\n1     3     9\n2     1     1\n3     2     4\n4     3     9\n5     1     1\n6     0     0\n7     1     1\n\nkBar_num &lt;- colMeans(k_df)\nkBar_num\n   k   k2 \n1.57 3.57 \n\n\nSo, \\(\\frac{1}{7} \\sum_i k_i\\) = 1.5714286 and \\(\\frac{1}{7} \\sum_i k_i^2\\) = 3.5714286. Thus, the two equations in our system are\n\n\\(np\\) = 1.571\n\\(np(np - p + 1)\\) = 3.571\n\nHowever, we already said that \\(n = 5\\) is known, so we don’t need the second equation. All we have to solve is \\(np = (5)p = 1.571 \\Rightarrow \\hat{p}_{MoM} = 0.314\\).\n\n2.7.1.1 Case When \\(n\\) is Unknown\nThis is a rare case, and usually only a theoretical exercise, though it can happen in ecological studies of species. One example could be where a park ranger goes deep into the woods on 5 different days. While on patrol, they encounter one grey wolf on the first day, none on the second, one on the third, and none on the fourth and fifth. In this case, we still have \\(|\\text{Count of observed wolves}| = |\\textbf{x}| = \\{1, 0, 1, 0, 0\\}\\). In this case, we don’t actually know how many grey wolves are in the park close enough to the ranger to even be detected. Thus, we could think about this as 5 Binomial trials with unknown \\(n\\).\nNow, we have the same system as above, but it is no longer trivial. We know that the ranger went out on \\(n = 5\\) days, and we know that \\(\\sum_i k_i = \\sum_i k_i^2 = 2\\). So, by simplifying the first equation, we have that: \\[\n\\begin{aligned}\nnp &= \\frac{1}{N}\\sum_i k_i \\\\\n\\Longrightarrow (5)p &= \\frac{1}{N}(2) \\\\\n\\Longrightarrow Np &= 0.4\\\\\n\\Longrightarrow p &= \\frac{0.4}{N} \\\\\n\\Longrightarrow np &= 5\\left( \\frac{0.4}{N} \\right) \\\\\n&= \\frac{2}{N}.\n\\end{aligned}\n\\]\nWe substitute these known quantities into the second equation: \\[\n\\begin{aligned}\nnp(np - p + 1) &= \\frac{1}{N}\\sum_i k_i^2\\\\\n\\Longrightarrow \\left( \\frac{2}{N} \\right) \\left(\\left[ \\frac{2}{N} \\right] - \\left[ \\frac{0.4}{N} \\right] + 1\\right) &= \\frac{1}{N}(2) \\\\\n\\Longrightarrow \\left(\\left[ \\frac{2}{N} \\right] - \\left[ \\frac{0.4}{N} \\right] + 1\\right) &= 1 \\\\\n\\Longrightarrow 2 - 0.4 = 0,\n\\end{aligned}\n\\] so we see that no analytic solutions exist to estimate \\(N\\) here! I recommend that students read the primer from DasGupta and Rubin (2004) at this juncture.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/binomial_20250310.html#maximum-likelihood-estimators",
    "title": "2  The Binomial Distribution",
    "section": "2.8 Maximum Likelihood Estimators",
    "text": "2.8 Maximum Likelihood Estimators\n\n2.8.1 The Likelihood Function\nLet’s continue our example of 7 Binomial trials with 5 flips each during which we observed \\(\\textbf{k}\\) = 3, 1, 2, 3, 1, 0, 1 heads. In this case, we know that \\(n = 5\\) and \\(N = 7\\), so the Likelihood of \\(p\\) given \\(\\textbf{k}\\) is \\[\n\\begin{aligned}\n\\mathcal{L}(p|\\textbf{k}, n) &= \\prod\\limits_{i = 1}^{N = 7} {n \\choose k_i} p^{k_i} (1 - p)^{n - k_i} \\\\\n&= \\left[ {5 \\choose 3} p^3 (1 - p)^{5 - 3} \\right] \\times \\left[ {5 \\choose 1} p^1 (1 - p)^{5 - 1} \\right] \\times \\left[ {5 \\choose 2} p^2 (1 - p)^{5 - 2} \\right] \\times \\left[ {5 \\choose 3} p^3 (1 - p)^{5 - 3} \\right] \\times \\\\\n&\\qquad \\left[ {5 \\choose 1} p^1 (1 - p)^{5 - 1} \\right] \\times \\left[ {5 \\choose 0} p^0 (1 - p)^{5 - 0} \\right] \\times \\left[ {5 \\choose 1} p^1 (1 - p)^{5 - 1} \\right] \\\\\n&= {5 \\choose 3}{5 \\choose 1}{5 \\choose 2}{5 \\choose 3}{5 \\choose 1}{5 \\choose 0}{5 \\choose 1} p^{11} (1 - p)^{7\\times 5 - 11}.\n\\end{aligned}\n\\]\nNote that all the Binomial Coefficient terms in the beginning are just multiplicative constants. The real “action” is happening in the \\(p^{11}(1 - p)^{35 - 11}\\) part; this is known as the kernel8 of the likelihood. How do we know this? Because \\(x\\)-value locations of the the extreme values of \\(cf(x)\\) are the same as the \\(x\\)-value locations for the extreme values of \\(f(x)\\).\nProof: Let \\(f\\) be a differentiable function with \\(M\\) extreme values given by \\(\\{(x_1, f(x_1)), (x_2, f(x_2)), \\ldots, (x_M, f(x_M))\\}\\). Therefore, for \\(i = 1, 2, \\ldots, M\\), \\(f^{\\prime}(x_i) = 0\\). Therefore, for any constant \\(c &lt; \\infty\\), \\(cf^{\\prime}(x_i) = 0\\). Hence, the extreme values of \\(cf(x)\\) are \\(\\{(x_1, cf(x_1)), (x_2, cf(x_2)), \\ldots, (x_M, cf(x_M))\\}\\).\nTherefore, it is commonplace to write the likelihood as a proportional relationship, \\[\n\\mathcal{L}(p|\\textbf{k}, n) \\propto p^{11} (1 - p)^{24},\n\\] where \\(\\propto\\) is read “is proportional to”.\nThis kernel function is of incredible importance: \\(\\mathcal{L}\\) contains almost all the information known about \\(p\\). It has all the data and it also has our best guess of the data generating process (a Binomial process in this case). However, we note that \\(\\mathcal{L}\\) is not a probability distribution of \\(p\\). If it was, then we could make probabalistic statements about the values of \\(p\\) which generated the observed data \\(\\textbf{k}\\).\n\n\n2.8.2 A Probability Function of \\(p\\)\nHow can I so sure that \\(\\mathcal{L}\\) is not a probability distribution? It’s clearly non-negative, so let’s find out what it integrates to. That is, \\[\n\\begin{aligned}\n\\int_0^1 \\mathcal{L}(p|\\textbf{k},n)dp &= \\int_0^1 {5 \\choose 3}{5 \\choose 1}{5 \\choose 2}{5 \\choose 3}{5 \\choose 1}{5 \\choose 0}{5 \\choose 1} p^{11} (1 - p)^{24}dp \\\\\n&= C(5, \\textbf{k}) \\int_0^1 p^{11} (1 - p)^{24} dp,\n\\end{aligned}\n\\] where \\(C(5, \\textbf{k})\\) is the constant product of the seven Binomial Coefficients. Further, while we have not yet derived this distribution, for \\(x \\in (0,1)\\), \\(x^A(1 - x)^B\\) is the kernel of a Beta distribution with \\(A = \\alpha - 1\\) and \\(B = \\beta - 1\\). That is \\[\nf_{\\text{Beta}}(p|\\alpha,\\beta) \\equiv \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p^{\\alpha - 1}(1 - p)^{\\beta - 1}.\n\\] Since the Beta distribution is a statistical distribution, we know that its integral over \\((0,1)\\) is equal to 1. Therefore, \\[\n\\begin{aligned}\n\\int_0^1 \\mathcal{L}(p|\\textbf{k},n)dp &= C(5, \\textbf{k}) \\int_0^1 p^{12 - 1} (1 - p)^{25 - 1} dp \\\\\n&= C(5, \\textbf{k}) \\int_0^1 \\frac{\\Gamma(12)\\Gamma(25)}{\\Gamma(12 + 25)} \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} p^{12 - 1} (1 - p)^{25 - 1} dp \\\\\n&= C(5, \\textbf{k}) \\frac{\\Gamma(12)\\Gamma(25)}{\\Gamma(12 + 25)} \\int_0^1 f_{\\text{Beta}}(p|\\alpha = 12,\\beta = 25) dp \\\\\n&= C(5, \\textbf{k}) \\frac{\\Gamma(12)\\Gamma(25)}{\\Gamma(12 + 25)},\n\\end{aligned}\n\\] which is clearly not equal to 1. But, this effort is not in vain, because it yields the multiplicative constant that makes \\(\\mathcal{L}\\) into a probability function of \\(p\\). That is, \\[\n\\begin{aligned}\nf(p|\\textbf{k}, n = 5) &= \\frac{1}{C(5, \\textbf{k})} \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} \\mathcal{L}(p|\\textbf{k},n = 5) \\\\\n&= \\frac{1}{C(5, \\textbf{k})} \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} C(5, \\textbf{k}) p^{12 - 1} (1 - p)^{25 - 1} \\\\\n&= \\frac{\\Gamma(12 + 25)}{\\Gamma(12)\\Gamma(25)} p^{12 - 1} (1 - p)^{25 - 1} \\\\\n&= f_{\\text{Beta}}(p|\\alpha = 12,\\beta = 25).\n\\end{aligned}\n\\] We can use this distribution to estimate the probability that \\(p\\) is fair. For example, a fair coin with the same total number of flips (35) would have a Beta distribution with \\(\\alpha = \\beta = (35 + 2)/2 = 18.5\\). Under such a distribution, the probability that \\(p \\in (0.4, 0,6)\\) is calculated by:\n\n\nCode\npbeta(q = 0.6, shape1 = 18.5, shape2 = 18.5) - \n  pbeta(q = 0.4, shape1 = 18.5, shape2 = 18.5)\n[1] 0.778\n\n\nThat is, if we had observed balanced data with the same sample sizes, then \\(\\mathbb{P}[0.4 &lt; p &lt; 0.6] = 0.778\\). However, what we actually observed was that\n\n\nCode\npbeta(q = 0.6, shape1 = 12, shape2 = 25) - \n  pbeta(q = 0.4, shape1 = 12, shape2 = 25)\n[1] 0.162\n\n\nThus, given the data we actually observed, \\(\\mathbb{P}[0.4 &lt; p &lt; 0.6] = 0.162\\). In terms of pure probability, this statement can be interpreted as “given the data we observed, there is a 16% chance that the coin is fair”.\n\n\n2.8.3 Estimating the Most “Likely” Value\nWhile being able to describe the probability that the coin is “fair” is valuable, we often are interested in answering the question “what is the most likely value of \\(p\\) given the data we observed?” Now we are finally discussing maximum likelihood estimation. Given the data we observed, what value of \\(p\\) makes \\(\\mathcal{L}\\) attain its maximum value? We find a candidate value as follows: \\[\n\\begin{aligned}\n\\mathcal{L}(p|\\textbf{k},n) &= C(5, \\textbf{k}) p^{11} (1 - p)^{24} \\\\\n\\Longrightarrow \\ell(p|\\textbf{k},n) &= \\log \\left[ C(5, \\textbf{k}) \\right] + 11\\log p + 24\\log(1 - p) \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial p} \\ell(p|\\textbf{k},n) &= 0 + \\frac{11}{p} + \\frac{24}{1 - p}(-1) \\\\\n&= \\frac{11}{p} - \\frac{24}{1 - p} \\\\\n\\Longrightarrow 0 &\\overset{set}{=} \\frac{11}{\\hat{p}} - \\frac{24}{1 - \\hat{p}} \\\\\n&= 11(1 - \\hat{p}) - 24\\hat{p} \\\\\n&= 11 - 35\\hat{p} \\\\\n\\Longrightarrow \\hat{p}_{MLE} &= \\frac{11}{35} \\approx 0.314.\n\\end{aligned}\n\\] So we know that \\(\\mathcal{L}\\) attains an extreme value at \\(\\hat{p}_{MLE} = 0.314\\), but is it a maximum? We check this using the second derivative test: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial p} \\ell(p|\\textbf{k},n) &= \\frac{11}{p} - \\frac{24}{1 - p} \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial p^2} \\ell(p|\\textbf{k},n) &= -\\frac{11}{p^2} - (-1)\\frac{24}{(1 - p)^2}(-1) \\\\\n&= -\\left( \\frac{11}{p^2} + \\frac{24}{(1 - p)^2} \\right) \\\\\n&&lt; 0.\n\\end{aligned}\n\\] Therefore, \\(\\hat{p}_{MLE} = 0.314\\) is the Maximum Likelihood Estimator for \\(p\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#exercises",
    "href": "chapters/binomial_20250310.html#exercises",
    "title": "2  The Binomial Distribution",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/binomial_20250310.html#footnotes",
    "href": "chapters/binomial_20250310.html#footnotes",
    "title": "2  The Binomial Distribution",
    "section": "",
    "text": "Read all the pages of this short lesson, as it also includes a refresher on Riemann-Stieltjes Integrals: https://www.colorado.edu/amath/sites/default/files/attached-files/definetti.pdf↩︎\nThe symbol \\(|\\cdot|\\) represents the cardinality operator: https://en.wikipedia.org/wiki/Cardinality↩︎\nhttps://en.wikipedia.org/wiki/Factorial↩︎\nhttps://en.wikipedia.org/wiki/Pascal%27s_rule↩︎\nhttps://en.wikipedia.org/wiki/Mathematical_induction↩︎\nhttps://en.wikipedia.org/wiki/Binomial_theorem↩︎\nhttps://en.wikipedia.org/wiki/Natural_number↩︎\nSee the “Bayesian Statistics” section of the article on statistical kernels: https://en.wikipedia.org/wiki/Kernel_(statistics)↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html",
    "href": "chapters/negative_binomial_20250310.html",
    "title": "3  The Negative Binomial Distribution",
    "section": "",
    "text": "3.1 Deriving the Distribution\nConsider the outcomes of \\(n\\) independent and identical Bernoulli trials, \\(k_i \\overset{iid}{\\sim} \\text{Bern}(p),\\ \\forall i \\in \\{1, 2, \\ldots, n\\}\\). We play a game where we “win” as soon as we flip enough heads. We pretend that we have a time machine, and we travel forward in time until right before the exact Bernoulli trial in which the “winning” coin flip happens. For example, imagine a game where, as soon as we’ve flipped 5 heads total, we win. We hop in our time machine and travel forward until we are just about to flip the 5th head. Let \\(Y_n = \\sum_i k_i\\) be the (cumulative) count of successes so far in the game; for example, if we win at the \\(5^{\\text{th}}\\) heads flipped, then we would have already seen four heads flipped this game. Let \\(G_m\\) be the flip number in which we will observe the \\(m^{\\text{th}}\\) success (where \\(m \\ge 1\\)). The probability of winning the game on coin flip \\(m\\) is then \\[\n\\mathbb{P}[G_m = n] = \\mathbb{P}[Y_{n - 1} = m - 1]\\times\\mathbb{P}[k_n = 1];\n\\] that is, the probability we win the game now, on flip \\(n\\), is the probability that we’ve seen \\(m - 1\\) heads in the last \\(n - 1\\) flips, times the probability that the very next flip (flip \\(n\\)) will be a heads. Recall that \\(k_i \\overset{iid}{\\sim} \\text{Bern}(p)\\), so the probability that we saw \\(m - 1\\) successes in \\(n - 1\\) trials follows the Binomial distribution, where \\[\n\\mathbb{P}[Y_{n - 1} = m - 1] = {n - 1 \\choose m - 1} p^{m - 1} (1 - p)^{n - m}.\n\\] Since, by definition, \\(\\mathbb{P}[k_n = 1] = p\\), then \\[\n\\begin{aligned}\n\\mathbb{P}[G_m = n] &= {n - 1 \\choose m - 1} p^{m - 1} (1 - p)^{n - m} \\times p \\\\\n&= {n - 1 \\choose m - 1} p^{m} (1 - p)^{n - m},\n\\end{aligned}\n\\] which is a parametrization of the Negative Binomial Distribution.\nWhile using counts of successes in total Bernoulli trials (\\(m\\) successes out of \\(n\\) trials) offers a clear derivation of this distribution, most of the time the Negative Binomial distribution is parametrized in terms counts of successes, \\(r = m\\), and failures, \\(k = n - m\\). Thus, \\(n = k + r\\) and \\(m = r\\). So, for \\(k \\in \\{\\mathbb{N} \\cup 0\\}\\) and \\(r \\ge 1\\), \\[\n\\begin{aligned}\nf_{\\text{NB}}(m, n|p) &\\equiv {n - 1 \\choose m - 1} p^{m} (1 - p)^{n - m} \\\\\n\\Longrightarrow f_{\\text{NB}}(r, k|p) &= {k + r - 1 \\choose r - 1} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{(r - 1)!([k + r - 1] - [r - 1])!} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{(r - 1)!(k + r - 1 - r + 1)!} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{k!(r - 1)!} p^{r} (1 - p)^{k} \\\\\n&= \\frac{(k + r - 1)!}{k!([k + r - 1] - k)!} p^{r} (1 - p)^{k} \\\\\n&= {k + r - 1 \\choose k} p^{r} (1 - p)^{k},\n\\end{aligned}\n\\] which is the more common form of the Negative Binomial distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#example-random-samples",
    "href": "chapters/negative_binomial_20250310.html#example-random-samples",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.2 Example Random Samples",
    "text": "3.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nN &lt;- 5\n\nxSymm &lt;- rnbinom(n = 500, size = N, prob = 0.5)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n30  = xSymm[1:30],\n  n100 = xSymm[1:100],\n  n500 = xSymm\n)\nbinsSymm_int &lt;- seq.int(from = -1, to = max(xSymm) + 1, by = 1)\n\nxSkew &lt;- rnbinom(n = 500, size = N, prob = 0.2)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n30  = xSkew[1:30],\n  n100 = xSkew[1:100],\n  n500 = xSkew\n)\nbinsSkew_int &lt;- seq.int(from = -1, to = max(xSkew) + 1, by = 1)\n# we are drawing until we reach N successes, so the upper limit should be \n# N * (1 / min(prob)) + epsilon\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSymm_ls$n5, breaks = binsSymm_int)\nhist(samplesSymm_ls$n30, breaks = binsSymm_int)\nhist(samplesSymm_ls$n100, breaks = binsSymm_int)\nhist(samplesSymm_ls$n500, breaks = binsSymm_int)\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSkew_ls$n5, breaks = binsSkew_int)\nhist(samplesSkew_ls$n30, breaks = binsSkew_int)\nhist(samplesSkew_ls$n100, breaks = binsSkew_int)\nhist(samplesSkew_ls$n500, breaks = binsSkew_int)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#formal-foundations",
    "href": "chapters/negative_binomial_20250310.html#formal-foundations",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.3 Formal Foundations",
    "text": "3.3 Formal Foundations\n\n3.3.1 Taylor/MacLaurin Series\nA Taylor (MacLaurin) Series expansion is a polynomial approximation of an \\(n\\)-differentiable real-valued function \\(f\\) around a point \\(a\\) (the MacLaurin Series is a special case when \\(a = 0\\)). Let \\(f^{(n)}(a)\\) denote the \\(n^{\\text{th}}\\) derivative of the function \\(f\\) evaluated at \\(a\\). Then the \\(n^{\\text{th}}\\)-order Taylor Series approximation of \\(f\\) in a neighbourhood of \\(a\\) is given by \\[\nf(x) \\approx f(a) + \\frac{f^{\\prime}(a)}{1!}(x - a)^1 + \\frac{f^{\\prime\\prime}(a)}{2!}(x - a)^2 + \\ldots + \\frac{f^{(n)}(a)}{n!}(x - a)^n.\n\\] If \\(f\\) is infinitely-differentiable, then this series can be continued in perpetuity, and the approximation becomes exact. That is \\[\nf(x) = \\sum_{n = 0}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x - a)^n.\n\\]\n\n\n3.3.2 Infinite Geometric Series\nFor a real number \\(|r| &lt; 1\\), the Geometric Series is the infinite-term MacLaurin Series form for the ratio below: \\[\n\\frac{b}{1 - r} = \\sum_{k = 0}^{\\infty} br^k.\n\\] Proof: We presented the definition of the Taylor Series for an infinitely-differentiable function \\(f\\) above. We need the functional form of the \\(n^{\\text{th}}\\) derivative of \\((1 - r)^{-1}\\) evaluated at an arbitrary point \\(a\\), where \\(|r| &lt; 1\\). These derivatives are given as \\[\n\\begin{align}\nf^{(0)}(a) &= (1 - a)^{-1} \\\\\nf^{(1)}(a) &= (-1)(1 - a)^{-2}(-1) =&  (1 - a)^{-2}\\\\\nf^{(2)}(a) &= (-2)(1 - a)^{-3}(-1) =& 2(1 - a)^{-3}\\\\\nf^{(3)}(a) &= (-3)(2)(1 - a)^{-4}(-1) =&  3\\times2(1 - a)^{-4}\\\\\nf^{(4)}(a) &= (-4)(3)(2)(1 - a)^{-5}(-1) =&  4!(1 - a)^{-5}\\\\\n\\vdots \\\\\nf^{(n)}(a) &= n!(1 - a)^{-(n + 1)}.\n\\end{align}\n\\] We evaluate these derivatives at \\(a = 0\\), yielding \\(f^{(n)}(0) = n!(1 - 0)^{-(n + 1)} = n!\\). Therefore, evaluating the MacLaurin Series for this ratio (the Taylor Series at \\(a = 0\\)) yields \\[\n\\begin{align}\nf(r) = \\frac{1}{1 - r} &= \\sum_{n = 0}^{\\infty} \\frac{f^{(n)}(0)}{n!}(r - 0)^n \\\\\n&= \\sum_{n = 0}^{\\infty} \\frac{\\left[ n! \\right]}{n!}  r^n \\\\\n&= \\sum_{n = 0}^{\\infty} r^n.\n\\end{align}\n\\] Hence, after changing the index of summation from \\(n\\) to \\(k\\) and multiplying both sides by \\(b\\), we have \\[\n\\frac{b}{1 - r} = \\sum_{k = 0}^{\\infty} br^k.\n\\]\n\n\n3.3.3 Newton’s Binomial Theorem\nNewton’s Binomial Theorem allows us to generalize the Infinite Geometric Series for \\(|r| &lt; 1\\) from exponents other than \\(-1\\) as follows1: \\[\nb(1 + r)^{\\alpha} = \\sum_{n = 0}^{\\infty} {\\alpha \\choose n} br^n.\n\\] Proof: We will follow the same MacLaurin Series derivation for \\((1 + r)^{\\alpha}\\) here as well, where the only major difference is that we have \\(+r\\) instead of \\(-r\\). The \\(n\\) derivatives evaluated at \\(r = r_0\\) are then \\[\n\\begin{align}\nf^{(0)}(r_0) &= (1 + r_0)^{\\alpha} \\\\\nf^{(1)}(r_0) &= (\\alpha)(1 + r_0)^{\\alpha - 1} \\\\\nf^{(2)}(r_0) &= (\\alpha)(\\alpha - 1)(1 + r_0)^{\\alpha - 2} \\\\\nf^{(3)}(r_0) &= (\\alpha)(\\alpha - 1)(\\alpha - 2)(1 + r_0)^{\\alpha - 3} \\\\\n\\vdots \\\\\nf^{(n)}(r_0) &= \\left[ (\\alpha)(\\alpha - 1)(\\alpha - 2) \\ldots (\\alpha - n + 1) \\right] (1 + r_0)^{\\alpha - n} \\\\\n&= \\left[ (\\alpha)(\\alpha - 1)(\\alpha - 2) \\ldots (\\alpha - n + 1) \\right] \\frac{(\\alpha - n)!}{(\\alpha - n)!} (1 + r_0)^{\\alpha - n} \\\\\n&= \\frac{\\alpha!}{(\\alpha - n)!} (1 + r_0)^{\\alpha - n} \\\\\n\\Longrightarrow f^{(n)}(0) &= \\frac{\\alpha!}{(\\alpha - n)!} (1 + 0)^{\\alpha - n} \\\\\n&= \\frac{\\alpha!}{(\\alpha - n)!}.\n\\end{align}\n\\] Therefore, \\[\n\\begin{aligned}\nb(1 + r)^{\\alpha} &= b \\sum_{n = 0}^{\\infty} \\frac{f^{(n)}(0)}{n!} (r - 0)^n \\\\\n&= b \\sum_{n = 0}^{\\infty} \\frac{\\left[ \\frac{\\alpha!}{(\\alpha - n)!} \\right]}{n!} r^n \\\\\n&= b \\sum_{n = 0}^{\\infty} \\frac{\\alpha!}{n!(\\alpha - n)!} r^n \\\\\n&= \\sum_{n = 0}^{\\infty} {\\alpha \\choose n} br^n\n\\end{aligned}\n\\]\n\n\n3.3.4 The Gamma Function\nAs a preliminary comment, we could spend literal weeks discussing and proving the many properties of a function called the Gamma Function, and we will discuss it in much greater depth as we progress further into these lessons on various statistical distributions. However, for now, suffice it to say that the Gamma Function is a generalization of the factorial function. Visually, it “connects the dots” between the integer factorial values. To see this, we will generate factorial and Gamma values from 0 to 4.\n\n\nCode\nfactorialValues_df &lt;- data.frame(\n  n = 0:4,\n  nFact = factorial(0:4)\n)\ngammaValues_df &lt;- data.frame(\n  x = seq(from = 0, to = 4, length.out = 21),\n  xGamma = gamma(seq(from = 0, to = 4, length.out = 21) + 1)\n)\n\n\nNow let’s visualize these two sets of values.\n\n\nCode\nlibrary(ggplot2)\n\nggplot() + \n  geom_line(data = gammaValues_df, aes(x = x, y = xGamma)) + \n  geom_point(data = factorialValues_df, aes(x = n, y = nFact), color = \"red\") +\n  labs(\n    x = \"Real (black) and Integer (red) valued x\",\n    y = \"Gamma(x+1) (black) and x! (red)\"\n  )\n\n\n\n\n\n\n\n\n\nSo, we see that the Gamma Function is one (of potentially many) smooth interpolations between the values of \\(x!\\) evaluated at each non-negative integer. However, it can be extended to the negative (non-integer) numbers and even the complex plane. At its most complex (for this class anyway), the Weierstrass’s Definition of the Gamma Function for all complex values of \\(z = a + bi\\) except for the negative integers is \\[\n\\Gamma(z) \\equiv \\frac{e^{-\\gamma z}}{z} \\prod_{n = 1}^{\\infty} \\left( 1 + \\frac{z}{n} \\right)^{-1} e^{\\frac{z}{n}},\n\\] where \\(\\gamma \\approx 0.577\\) is the Euler-Mascheroni constant.\nThankfully, we don’t have to use this version, we only have to know that it exists. The version that we will use most is the representation of the Gamma Function when the Real component \\(z\\) is positive; that is, when \\(a &gt; 0\\). We represent this condition symbolically as \\(\\mathbb{R}(z) &gt; 0\\). It’s also worth noting that this includes all the positive real numbers as well, because \\(b\\) in \\(z = a + bi\\) could be \\(0\\). So, the “common form” of the Gamma Function is \\[\n\\Gamma(z) = \\int_0^{\\infty} t^{z - 1}e^{-t}dt,\\ \\mathbb{R}(z) &gt; 0.\n\\] Finally, in the simplest case, if \\(z\\) can be written as a non-negative integer \\(n\\), then we get the simplest form of all: \\[\n\\Gamma(n) \\equiv (n - 1)!.\n\\] For the next few lessons (at least until we get to the Gamma and Beta Distributions), we won’t yet need to formalize or prove any properties of this function. For now, we simply need to know that it’s possible to extend the factorial beyond the integers.\n\n\n3.3.5 “Negative” Binomial Coefficients\nThis is a specific form of the Generalized Binomial Coefficient that allows us to extend the mathematical relationship of the binomial theorem beyond its usual applications of combinations (where \\(n\\) and \\(k\\) are required to be non-negative integers). This generalization yields the following property, which we will shortly prove: \\[\n{-a \\choose b} \\equiv (-1)^b {a + b - 1 \\choose b}.\n\\]\nProof: Consider \\(a,b \\in \\mathbb{R}\\) and further recall by the above definition of the Gamma Function that the factorial operator can be extended beyond the integers. Even though we do not define how to calculate such a value, we will only need to know for this proof that such numbers could possibly exist. Thus, \\[\n\\begin{aligned}\n{-a \\choose b} &= \\frac{(-a)!}{b!(-a - b)!} \\\\\n&= \\frac{(-a)(-a - 1)(-a - 2)\\ldots(-a - b + 1)(-a - b)!}{b!(-a - b)!} \\\\\n&= \\frac{(-a)(-a - 1)(-a - 2)\\ldots(-a - b + 1)}{b!} \\\\\n&= (-1)^b\\frac{(a)(a + 1)(a + 2)\\ldots(a + b - 1)}{b!} \\\\\n&= (-1)^b\\frac{(a + b - 1)\\ldots(a + 2)(a + 1)(a)}{b!} \\times \\frac{(a - 1)!}{(a - 1)!} \\\\\n&= (-1)^b\\frac{(a + b - 1)!}{b!(a - 1)!} \\\\\n&= (-1)^b\\frac{(a + b - 1)!}{b!([a + b - 1] - b)!} \\\\\n&= (-1)^b {a + b - 1 \\choose b}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/negative_binomial_20250310.html#show-that-this-is-a-distribution",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.4 Show that this is a Distribution",
    "text": "3.4 Show that this is a Distribution\nWe first consider the parametrization with \\(m\\) successes out of \\(n\\) trials. That is, \\[\nf_{\\text{NB}}(n|m,p) \\equiv {n - 1 \\choose m - 1} p^{m} (1 - p)^{n - m}, 1 \\le m \\le n &lt; \\infty,\\ p\\in (0,1).\n\\] Note that \\(m \\ge 1\\) because we are counting the number of trials until we see at least one success. Also note that \\(n\\) has no upper bound. If the “game” is the United States Men’s Soccer team winning the FIFA World Cup, the number of World Cups necessary, \\(n\\), for this event, \\(m = 1\\), to occur \\(\\to\\infty\\).\n\n3.4.1 The Distribution is Non-negative\nAs we already know, \\(p\\in (0,1)\\). Thus \\(p^m,\\ (1 - p)^{n - m} &gt; 0\\). Further, \\(1 \\le m \\le n &lt; \\infty\\), so Binomial Coefficient will never be smaller than 1. Thus, for \\(p\\in (0,1)\\), \\(f_{\\text{NB}}(m, n|p) &gt; 0\\), and for \\(p\\) outside this defined range of probability, \\(f_{\\text{NB}}(m, n|p) \\equiv 0\\) by definition. Thus, \\(f_{\\text{NB}}(m, n|p) \\ge 0\\ \\forall p\\).\n\n\n3.4.2 The Total Probability is 1\nThis proof is considerably more involved than the proof for the Binomial Distribution; I follow this guide from Mathematics Stack Exchange. We will use proof by induction, infinite geometric series, and Pascal’s Rule of factorials. These topics are covered in the “Formal Foundations” subsections of this lesson and the previous lesson on the Binomial Distribution. Let’s begin by defining a shorthand form of the Riemman-Stieljes integral of the Negative Binomial Distribution over the support of \\(n\\); let \\[\nS_m \\equiv \\int\\limits_{\\mathcal{S}(n|m)} dF(n|m,p) = \\sum_{n = m}^{\\infty} {n - 1 \\choose m - 1} p^m (1 - p)^{n - m},\\ \\forall m\\in\\mathbb{N}.\n\\]\nThe base case is the event when \\(m = 1\\). So we must show that \\(S_1 = 1\\). First, recall that there is only 1 way to “choose” 0 events, so \\[\n\\begin{aligned}\nS_1 &= \\sum_{n = 1}^{\\infty} {n - 1 \\choose 1 - 1} p^1 (1 - p)^{n - 1} \\\\\n&= p \\sum_{n = 1}^{\\infty} {n - 1 \\choose 0} (1 - p)^{n - 1} \\\\\n&= p \\sum_{n = 1}^{\\infty} (1) (1 - p)^{n - 1} \\\\\n&= p \\sum_{k + 1 = 1}^{\\infty} (1 - p)^k,\\ \\text{for}\\ n = k + 1 \\\\\n&= p \\sum_{k = 0}^{\\infty} (1 - p)^k \\\\\n&\\qquad \\text{\\emph{Infinite Geometric Series...}} \\\\\n&= p \\left[ \\frac{1}{1 - [1 - p]} \\right],\\ |1 - p| &lt; 1 \\\\\n&= \\frac{p}{1 - 1 + p} \\\\\n&= 1.\n\\end{aligned}\n\\] The hypothesis is then that \\(S_m = 1\\). That is, we assume that \\[\nS_m = \\sum_{n = m}^{\\infty} {n - 1 \\choose m - 1} p^m (1 - p)^{n - m} = 1.\n\\] Our induction will be to assume the hypothesis is true for \\(m\\) and show that this implies that it is also true for \\(m+1\\).\nNow, using this \\(S_m\\) notation, and recalling Pascal’s Rule: \\[\n\\begin{aligned}\nS_{m + 1} &= \\sum_{n = m + 1}^{\\infty} {n - 1 \\choose m + 1 - 1} p^{m + 1} (1 - p)^{n - (m + 1)} \\\\\n&= \\sum_{n = m + 1}^{\\infty} {n - 1 \\choose m} p^{m + 1} (1 - p)^{n - m - 1} \\\\\n&\\qquad \\text{\\emph{Pascal's Rule...}} \\\\\n&= \\sum_{n = m + 1}^{\\infty} \\left[ {n - 2 \\choose m} + {n - 2 \\choose m - 1} \\right] p^{m + 1} (1 - p)^{n - m - 1} \\\\\n&= \\sum_{n = m + 1}^{\\infty} {n - 2 \\choose m} p^{m + 1} (1 - p)^{n - m - 1} + \\sum_{n = m + 1}^{\\infty} {n - 2 \\choose m - 1} p^{m + 1} (1 - p)^{n - m - 1}.\n\\end{aligned}\n\\] At this point, we’d like to pull out something that looks like \\(S_m\\), because we are assuming that equals 1. Let’s change the summation index by letting \\(j = n - 1 \\Rightarrow n = j + 1\\) and pick back up: \\[\n\\begin{aligned}\nS_{m + 1} &= \\sum_{[j + 1] = m + 1}^{\\infty} {[j + 1] - 2 \\choose m} p^{m + 1} (1 - p)^{[j + 1] - m - 1} + \\sum_{[j + 1] = m + 1}^{\\infty} {[j + 1] - 2 \\choose m - 1} p^{m + 1} (1 - p)^{[j + 1] - m - 1} \\\\\n&= \\sum_{j = m}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m} + \\sum_{j = m}^{\\infty} {j - 1 \\choose m - 1} p^{m + 1} (1 - p)^{j - m} \\\\\n&= (1 - p) \\sum_{j = m}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} + p \\sum_{j = m}^{\\infty} {j - 1 \\choose m - 1} p^{m} (1 - p)^{j - m} \\\\\n&= (1 - p) \\sum_{j = m}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} + pS_m \\\\\n&= (1 - p) \\left[ {m - 1 \\choose m} p^{m + 1} (1 - p)^{m - m - 1} + \\sum_{j = m + 1}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} \\right] + pS_m \\\\\n&= (1 - p) \\left[ 0 + \\sum_{j = m + 1}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} \\right] + pS_m.\n\\end{aligned}\n\\] The last line requires us to observe that \\({m - 1 \\choose m} = 0\\ \\forall m \\in \\mathbb{N}\\) because there are 0 ways to choose \\(m\\) objects from a set of \\(m - 1\\) objects. For our final component of the induction step, we notice that the second term in the brackets is \\(S_{m+1}\\) using an index of \\(j\\) instead of \\(n\\). Thus, \\[\n\\begin{aligned}\nS_{m + 1} &= (1 - p) \\left[\\sum_{j = m + 1}^{\\infty} {j - 1 \\choose m} p^{m + 1} (1 - p)^{j - m - 1} \\right] + pS_m \\\\\n&= (1 - p) \\left[ S_{m + 1} \\right] + pS_m \\\\\n&= S_{m + 1} - pS_{m + 1} + pS_m \\\\\n\\Longrightarrow 0 &= pS_m - pS_{m + 1} \\\\\n\\Longrightarrow S_{m + 1} &= S_m.\n\\end{aligned}\n\\] Because we assumed that \\(S_m = 1\\) at our hypothesis step, we then have that \\(S_m = 1 \\Rightarrow S_{m + 1} = 1\\), which completes our proof. Thus, \\(\\forall m \\in \\mathbb{N}\\), \\[\n\\sum_{n = m}^{\\infty} {n - 1 \\choose m - 1} p^m (1 - p)^{n - m} = 1.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/negative_binomial_20250310.html#derive-the-moment-generating-function",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.5 Derive the Moment Generating Function",
    "text": "3.5 Derive the Moment Generating Function\nIn my opinion, it’s easier to derive the MGF of the Negative Binomial when we use the \\(k,r\\) parametrization (where \\(r \\ge 1\\) is the number of successes and \\(k \\ge 0\\) is the number of failures). Thus, \\[\n\\begin{aligned}\nf_{\\text{NB}}(k,r|p) &= {k + r - 1 \\choose k} p^r (1 - p)^k \\\\\n\\Longrightarrow M_k(t) &= \\int_{\\mathcal{S}(k)} e^{tk} dF(k,r|p) \\\\\n&= \\sum_{k = 0}^{\\infty} e^{tk} {k + r - 1 \\choose k} p^r (1 - p)^k \\\\\n&= p^r \\sum_{k = 0}^{\\infty} {k + r - 1 \\choose k} \\left[ e^{t}(1 - p) \\right]^k \\\\\n&\\qquad \\text{\\emph{Generalized/Negative Binomial Coefficient...}} \\\\\n&= p^r \\sum_{k = 0}^{\\infty} \\left[ (-1)^k {-r \\choose k} \\right] \\left[ e^{t}(1 - p) \\right]^k \\\\\n&= p^r \\sum_{k = 0}^{\\infty} {-r \\choose k} \\left[ -e^{t}(1 - p) \\right]^k \\\\&\\qquad \\text{\\emph{Newton's Binomial Theorem...}} \\\\\n&= p^r \\left( 1 + \\left[ -e^{t}(1 - p) \\right] \\right)^{[-r]}.\n\\end{aligned}\n\\] To correctly invoke Newton’s Binomial Theorem in this last step, we must recall that Moment Generating Functions are defined within an \\(\\epsilon\\)-neighbourhood of 0. Therefore, \\(e^t(1 - p) \\approx (1)(1 - p)\\), which we can safely bound between \\(0\\) and \\(1\\) for arbitrarily small \\(\\epsilon\\), just as long as \\(p \\ne \\{0, 1\\}\\) (as in, as long as neither failure nor success are guaranteed). Thus, \\[\nM_k(t) = \\left[ \\frac{p}{1 - e^{t}(1 - p)} \\right]^r.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/negative_binomial_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.6 Method of Moments Estimates from Observed Data",
    "text": "3.6 Method of Moments Estimates from Observed Data\nIf we see \\(n\\) repeated Negative Binomial experiments, then we must already know the following information:\n\nWe know that in each of the \\(n\\) experiments, by definition we observed \\(r\\) successes.\nWe know that in each experiment, the “games” or “trials” were conducted independently until all \\(r\\) successes were observed. Thus, the number of games in each experiment vary, and the probability of winning in each game, \\(p\\), does not change (but it is unknown in real life).\nBased on the first two facts, we then know that the “data” in repeated Negative Binomial experiments is the count of failures observed in each experiment until all \\(r\\) successes were observed. We denote these counts as \\(k_i,\\ i = 1, 2, \\ldots n\\).\n\nTherefore, our observed data is \\(\\textbf{k} = \\langle k_1, k_2,\\ldots,k_n\\rangle\\), the counts of the number of failures in each experiment until success number \\(r\\) was observed. Let’s generate some random data with \\(r = 5\\) and \\(p = 0.35\\) across 7 experiments:\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7\nr_int &lt;- 5L\np_num &lt;- 0.35\nNBk_int &lt;- rnbinom(n = nTrials_int, size = r_int, prob = p_num)\nNBk_int\n[1] 13 10  3  7 18  9 12\n\n\nAs we can see, in order to achieve 5 wins total in each experiment, we needed 13, 10, 3, 7, 18, 9, 12 “games” in those experiments. Now that we have the MGF and a sample of data, we can:\n\nFind \\(\\mathbb{E}[k]\\), \\(\\mathbb{E}[k^2]\\), and \\(\\text{Var}[k]\\), then\nCreate (and solve) a system of two equations by setting \\(\\mathbb{E}[k] = \\bar{k}\\) and \\(\\text{Var}[k] = s^2\\).\n\n\n3.6.1 \\(\\mathbb{E}[k]\\)\nConsider \\[\n\\begin{aligned}\nM_k(t) &= p^r \\left[ 1 - e^t(1 - p) \\right]^{-r} \\\\\n\\Longrightarrow M^{\\prime}_k(t) &= -rp^r \\left[ 1 - e^t(1 - p) \\right]^{-r - 1} \\times \\left[ - e^t(1 - p) \\right] \\\\\n&= r(1 - p)p^r \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} e^t \\\\\n\\Longrightarrow M^{\\prime}_k(0) &= r(1 - p)p^r [1] \\left[ 1 - [1](1 - p) \\right]^{-r - 1} \\\\\n&= r(1 - p) \\frac{p^r}{p^{r + 1}} \\\\\n&= r \\frac{(1 - p)}{p} \\\\\n&= \\mathbb{E}[k].\n\\end{aligned}\n\\]\n\n\n3.6.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\nTaking \\(M^{\\prime}_k(t)\\) from above, we then have that \\[\n\\begin{aligned}\nM^{\\prime\\prime}_k(t) &= r(1 - p)p^r \\frac{\\partial}{\\partial t} \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} e^t \\\\\n&= r(1 - p)p^r \\left[ \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} \\frac{\\partial}{\\partial t} e^t + e^t \\frac{\\partial}{\\partial t} \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} \\right] \\\\\n&= r(1 - p)p^r e^t \\left[ \\left[ 1 + e^t(p - 1) \\right]^{-r - 1} - (r + 1)\\left[ 1 + e^t(p - 1) \\right]^{-r - 2} \\times e^t(p - 1) \\right].\n\\end{aligned}\n\\] Thus, \\[\n\\begin{aligned}\nM^{\\prime\\prime}_k(0) &= r(1 - p)p^r [1] \\left[ \\left[ 1 + [1](p - 1) \\right]^{-r - 1} - (r + 1)\\left[ 1 + [1](p - 1) \\right]^{-r - 2} \\times [1](p - 1) \\right] \\\\\n&= r(1 - p)p^r \\left[ p^{-(r+1)} + (r+1)(1-p)p^{-(r+2)} \\right] \\\\\n&= r(1 - p) \\left[ \\frac{p}{p^2} + (r+1)\\frac{1 - p}{p^2} \\right] \\\\\n&= \\mathbb{E}[k^2],\n\\end{aligned}\n\\] so that \\[\n\\begin{aligned}\n\\text{Var}[k] &= \\mathbb{E}[k^2] - \\left[\\mathbb{E}[k]\\right]^2 \\\\\n&= r(1 - p) \\left[ \\frac{p}{p^2} + (r+1)\\frac{1 - p}{p^2} \\right] - \\left[ r \\frac{(1 - p)}{p} \\right]^2 \\\\\n&= \\frac{ rp(1 - p) + r(r+1)(1 - p)^2 - r^2(1 - p)^2 }{p^2} \\\\\n&= r(1 - p) \\left[ \\frac{ p + (r+1)(1 - p) - r(1 - p) }{p^2} \\right] \\\\\n&= r(1 - p) \\left[ \\frac{ p + r(1 - p) + 1(1 - p) - r(1 - p) }{p^2} \\right] \\\\\n&= r(1 - p) \\left[ \\frac{ p + 1(1 - p) }{p^2} \\right] \\\\\n&= r(1 - p) \\frac{1}{p^2} \\\\\n&= \\frac{r(1 - p)}{p^2}.\n\\end{aligned}\n\\]\n\n\n3.6.3 Solving the System\nWe now have the following non-linear system of equations to solve: \\[\n\\begin{aligned}\n\\mathbb{E}[k] &: \\frac{r(1 - p)}{p} = \\bar{k} \\\\\n\\text{Var}[k] &: \\frac{r(1 - p)}{p^2} = s^2\n\\end{aligned}\n\\] We will first isolate \\(r\\) as a function of \\(s^2\\). In most real data scenarios, we know \\(r\\), but for completion we will here assume it’s unknown. Thus, \\[\n\\begin{aligned}\ns^2 &= \\frac{r(1 - p)}{p^2} \\\\\n\\Longrightarrow r &= \\frac{p^2s^2}{1 - p} \\\\\n\\Longrightarrow \\bar{k} &= \\left[ \\frac{p^2s^2}{1 - p} \\right] \\times \\frac{(1 - p)}{p} \\\\\n&= ps^2 \\\\\n\\Longrightarrow \\hat{p}_{MoM} = \\frac{\\bar{k}}{s^2}.\n\\end{aligned}\n\\] Subsequently, if we had to estimate \\(r\\) (which is unlikely), then \\[\n\\begin{aligned}\n\\bar{k} &= \\frac{r(1 - p)}{p} \\\\\n&= \\frac{r\\left( 1 - \\left[ \\frac{\\bar{k}}{s^2} \\right] \\right)}{\\left[ \\frac{\\bar{k}}{s^2} \\right]} \\\\\n&= r\\frac{s^2}{\\bar{k}} \\left[ 1 - \\frac{\\bar{k}}{s^2} \\right] \\\\\n\\Longrightarrow \\bar{k} &= r \\left[ \\frac{s^2}{\\bar{k}} - 1 \\right] \\\\\n\\Longrightarrow \\bar{k}^2 &= r (s^2 - \\bar{k}) \\\\\n\\Longrightarrow \\hat{r}_{MoM} &= \\frac{\\bar{k}^2}{s^2 - \\bar{k}}.\n\\end{aligned}\n\\] For this data, we know that \\(r\\) = 5, and we generated data for \\(n\\) = 7 trials with \\(p\\) equal to 0.35. Thus, given the observed data, we estimate \\(\\hat{p}_{MoM}\\) as\n\n\nCode\nmean(NBk_int) / var(NBk_int)\n[1] 0.456",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/negative_binomial_20250310.html#maximum-likelihood-estimators",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.7 Maximum Likelihood Estimators",
    "text": "3.7 Maximum Likelihood Estimators\nBecause we should know \\(r\\) in advance of the experiment, and because \\(\\textbf{k}\\) is the observed counts across \\(n\\) experiments, the only unknown is \\(p\\). The likelihood function is then \\[\n\\mathcal{L}(p|\\textbf{k},r) = \\prod\\limits_{i = 1}^n {k_i + r - 1 \\choose k_i} p^r (1 - p)^k_i,\\ p\\in (0,1).\n\\] We then find the extreme value of \\(\\mathcal{L}\\) by \\[\n\\begin{aligned}\n\\ell(p|\\textbf{k},r) &= \\sum\\limits_{i = 1}^n \\log\\left[ {k_i + r - 1 \\choose k_i} p^r (1 - p)^{k_i} \\right] \\\\\n&= \\sum\\limits_{i = 1}^n \\left[ \\log{k_i + r - 1 \\choose k_i} + r\\log(p) + k_i \\log(1 - p) \\right] \\\\\n&= nr\\log(p) + \\log(1 - p) \\sum\\limits_{i = 1}^n k_i + \\sum\\limits_{i = 1}^n \\log{k_i + r - 1 \\choose k_i} \\\\\n&= nr\\log(p) + n\\bar{k}\\log(1 - p) + \\sum\\limits_{i = 1}^n \\log{k_i + r - 1 \\choose k_i} \\\\\n\\Longrightarrow \\frac{\\partial\\ell(p|\\textbf{k},r)}{\\partial p} &= \\frac{nr}{p} - \\frac{n\\bar{k}}{1 - p} + 0 \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{nr}{\\hat{p}} - \\frac{n\\bar{k}}{1 - \\hat{p}} \\\\\n\\Longrightarrow 0 &= nr(1 - \\hat{p}) - n\\bar{k}\\hat{p} \\\\\n&= nr - nr\\hat{p} - n\\bar{k}\\hat{p} \\\\\n\\Longrightarrow nr &= \\hat{p}(nr + n\\bar{k}) \\\\\n\\Longrightarrow \\hat{p} &= \\frac{nr}{nr + n\\bar{k}} \\\\\n&= \\frac{r}{r + \\bar{k}}.\n\\end{aligned}\n\\] Now we need to confirm that this is indeed a maximum value, so we check the second derivative of the log-likelihood: \\[\n\\begin{aligned}\n\\frac{\\partial\\ell(p|\\textbf{k},r)}{\\partial p} &= \\frac{nr}{p} - \\frac{n\\bar{k}}{1 - p} \\\\\n&= nrp^{-1} - n\\bar{k}(1 - p)^{-1} \\\\\n\\Longrightarrow \\frac{\\partial^2\\ell(p|\\textbf{k},r)}{\\partial p^2} &= -nrp^{-2} - (-1)n\\bar{k}(1 - p)^{-2}(-1) \\\\\n&= -\\frac{nr}{p^2} - \\frac{n\\bar{k}}{(1 - p)^2} \\\\\n&&lt; 0,\n\\end{aligned}\n\\] as long as \\(\\{n,r\\} &gt;0\\) and \\(p\\in(0,1)\\). Thus, \\(\\hat{p}_{MLE} = \\frac{r}{r + \\bar{k}}\\). For our observed data, with \\(r\\) = 5, this is\n\n\nCode\nr_int / (r_int + mean(NBk_int))\n[1] 0.327\n\n\nUnlike in the Binomial Distribution case, where the two estimators were quite close, this ML estimate for \\(p\\) is much closer to the true value of \\(p\\) = 0.35 than the MoM estimate.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#exercises",
    "href": "chapters/negative_binomial_20250310.html#exercises",
    "title": "3  The Negative Binomial Distribution",
    "section": "3.8 Exercises",
    "text": "3.8 Exercises\n\n3.8.1 The Geometric Distribution\nWhen \\(1 = m \\le n\\) (we are repeating trials until we observe the first success), the Negative Binomial Distribution reduces to the Geometric Distribution.\n\nDerive this distribution\nFind \\(\\mathbb{E}[n]\\) and \\(\\text{Var}[n]\\).\nFind the MGF of this distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/negative_binomial_20250310.html#footnotes",
    "href": "chapters/negative_binomial_20250310.html#footnotes",
    "title": "3  The Negative Binomial Distribution",
    "section": "",
    "text": "for the implications of “choosing” from values that aren’t necessarily integers, see the next subsection on the Gamma Function↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Negative Binomial Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html",
    "href": "chapters/poisson_20250310.html",
    "title": "4  The Poisson Distribution",
    "section": "",
    "text": "4.1 Formal Foundations\nWe will begin this lesson a little differently. For the previous lessons, we were able to derive the distributions without a tremendous amount of preliminary mathematics. However, while the Poisson distribution will end up as a simple distribution to work with, deriving it requires a deep refresh of calculus in addition to some of the other Formal Foundations we have already seen.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#formal-foundations",
    "href": "chapters/poisson_20250310.html#formal-foundations",
    "title": "4  The Poisson Distribution",
    "section": "",
    "text": "4.1.1 The Limit Definition of the Derivative\nIn our introductory calculus courses, we first learned that the derivative was a sophisticated “slope” of a function. Consider some function \\(y = f(x)\\) and its first derivative, which is most commonly denoted as \\(y^{\\prime}\\), \\(f^{\\prime}(x)\\), or \\(\\frac{dy}{dx}\\). Specifically, we learned that \\(f^{\\prime}(x)\\) is the function that yields the instantaneous rate of change of the function \\(f(x)\\). That is, the function \\(f\\) at the point \\(x = x_0\\) is parallel to every straight line which has a slope given by the value of the function \\(f^{\\prime}(x)\\) evaluated at \\(x = x_0\\).\n In the above picture (from the engineers at Utah State University), the red curve is the function \\(f(x)\\), the evaluation point is the black dot near \\(\\{x = 2.25,\\ y = 1.25\\}\\), and the blue line is the tangent line1 to \\(f(x)\\) at the evaluation point. It’s the line that has a slope given by \\(f^{\\prime}\\) evaluated at the black dot.\nIn basic algebra, we know that we calculate the slope between two points, \\(\\{x,y\\}\\) and \\(\\{x_0,y_0\\}\\), as “the change in \\(y\\) divided by the change in \\(x\\)”. We use \\(\\Delta y\\) to represent the “change in \\(y\\)”, and \\(\\Delta x\\) similarly for \\(x\\). Let’s begin there, noting that \\(\\{x_0,y_0\\} = \\{x + \\Delta x,y + \\Delta y\\}\\): \\[\n\\begin{aligned}\n\\text{Slope} &= \\frac{y_0 - y}{x_0 - x} \\\\\n&= \\frac{f(x_0) - f(x)}{x_0 - x}\\\\\n&= \\frac{f([x + \\Delta x]) - f(x)}{[x + \\Delta x] - x} \\\\\n&= \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.\n\\end{aligned}\n\\] Given two fixed points, \\(\\{x,y\\}\\) and \\(\\{x_0,y_0\\}\\), these ratio above can be calculated directly. However, we said above that the derivative is called the instantaneous rate of change. That means, we want \\(\\{x,y\\}\\) and \\(\\{x_0,y_0\\}\\) to be “infinitely” close to each other. In other words, we want \\(\\Delta x \\rightarrow 0\\). This yields our well-known limit definition of the derivative2: \\[\nf^{\\prime}(x) \\equiv \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.\n\\] This limit calculation yields the first order derivative3 if we take it only once (but higher order derivatives can be found by sequentially repeating this process).\nFor example, the first order derivative of \\(y = x^2\\) via limit definition is \\[\n\\begin{aligned}\ny^{\\prime} &= \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} \\frac{\\left[ (x + \\Delta x)^2 \\right] - \\left[ x^2 \\right]}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} \\frac{x^2 + 2x\\Delta x + (\\Delta x)^2 - x^2}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} \\frac{\\Delta x(2x + \\Delta x)}{\\Delta x} \\\\\n&= \\lim_{\\Delta x \\rightarrow 0} 2x + \\Delta x \\\\\n&= 2x + 0,\n\\end{aligned}\n\\] which is the well-known first-order derivative of \\(y = x^2\\) with respect to \\(x\\).\n\n\n4.1.2 Homogeneous Functions\nA function \\(f(x)\\) is said to be homogeneous4 iff \\(f(c\\textbf{x}) = c^kf(\\textbf{x})\\) for some scalar \\(c\\) and \\(k \\in \\mathbb{N}\\). The value of \\(k\\) in the equation is known as the “degree of homogeneity” (which isn’t super important for us to know, but I digress), but it must be an integer. What’s important about homogeneous functions is that they are stretched (but aren’t “shifted”) in space: \\(f(\\textbf{x})\\) and \\(c^kf(\\textbf{x})\\) all have “zeroes” at the same values of the vector \\(\\textbf{x}\\). These functions are often sums or products of single-term polynomials.\nFor example, consider \\(f(x,y) = x^3 + y^3\\). If I pick an arbitrary constant, say 10, then \\[\nf(10x, 10y) = (10x)^3 + (10y)^3 = 10^3(x^3 + y^3) = 10^kf(x,y),\n\\] with \\(k = 3\\). Thus \\(f(x) = x^3\\) is homogeneous with degree 3. In contrast, consider the counter-example \\(f(x) = x^2 - 3\\). For that same arbitrary constant above, is \\(f(10x)\\) the same as some power of 10 times \\(f(x)\\)? Well, \\(f(10x) = 10^2x^2 + 3 = 10^2(x^2 + \\frac{3}{100}) \\ne 10^k f(x)\\). So \\(f(x) = x^2 - 3\\) is not homogeneous. As another counter-example, consider \\(f(x,y) = x^2 + y\\). We see that \\[\nf(10x, 10y) = 10^2x^2 - 10y = 10^2(x^2 - \\frac{1}{10}y) \\ne 10^kf(x,y).\n\\] You may have forgotten about homogeneous functions because of how limiting they are. However, they play a very important role in solving differential equations.\n\n\n4.1.3 First-Order, Homogeneous Differential Equations\nNow that we understand what a first order derivative and a homogeneous function are, we can find out what the build up was all about. Differential Equations are mathematical expressions that systematically equate unknown functions and their derivatives. A primer on solving ordinary5 differential equations is well beyond the scope of this material. However, we can review a very small collection of ordinary differential equations, known as homogeneous first order differential equations which have the form \\[\nM(x,y) + N(x,y)\\frac{dy}{dx} = 0,\n\\] where \\(M\\) and \\(N\\) are both homogeneous functions of the same degree \\(n\\). Because these two functions are homogenous with the same degree \\(n\\), then we can write this derivative as a function of \\(\\frac{y}{x}\\). That is, \\[\n\\begin{aligned}\n0 &= M(x,y) + N(x,y)\\frac{dy}{dx} \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -\\frac{M(x,y)}{N(x,y)} \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -f\\left(\\frac{y}{x}\\right),\n\\end{aligned}\n\\] for some function \\(f\\). Now, we can substitute \\(y = ux\\) on both sides, and distribute the derivative through the substitution with the product rule. Thus, we can separate6 this differential equation into two independent functions of \\(x\\) and \\(u\\): \\[\n\\begin{aligned}\n\\frac{dy}{dx} &= -f\\left(\\frac{y}{x}\\right) \\\\\n\\Longrightarrow \\frac{d(ux)}{dx} &= -f\\left(\\frac{ux}{x}\\right) \\\\\n\\Longrightarrow u\\frac{dx}{dx} + x\\frac{du}{dx} &= -f(u) \\\\\n\\Longrightarrow x\\frac{du}{dx} &= -f(u) - u \\\\\n\\Longrightarrow \\frac{1}{x}\\frac{dx}{du} &= \\frac{-1}{f(u) + u} \\\\\n\\Longrightarrow \\int \\frac{1}{x}dx &= \\int \\frac{-1}{f(u) + u}du,\n\\end{aligned}\n\\] which can be solved if the integral of the right hand side can be found. We note that the solution to the left hand side is \\(\\ln(x)\\).\nLet’s have an example before we move on (we’ll work something similar to this example from Newcastle University). Consider \\[\n\\begin{aligned}\n(x^2 + y^2) + y^2\\frac{dy}{dx} &= 0 \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -\\frac{x^2 + y^2}{y^2} \\\\\n\\Longrightarrow \\frac{dy}{dx} &= -\\left(\\frac{x}{y}\\right)^2 - 1.\n\\end{aligned}\n\\] Now, we let \\(y = ux\\), so \\(\\frac{dy}{dx} = u + x\\frac{du}{dx}\\). Hence, \\[\n\\begin{aligned}\n\\frac{dy}{dx} &= -\\left(\\frac{x}{y}\\right)^2 - 1 \\\\\n\\Longrightarrow u + x\\frac{du}{dx} &= -u^2 - 1 \\\\\n\\Longrightarrow x\\frac{du}{dx} &= -u^2 -u - 1 \\\\\n\\Longrightarrow \\frac{1}{x}dx &= -\\frac{1}{u^2 + u + 1}du \\\\\n&= -\\frac{1}{\\left[u^2 + u + \\frac{1}{4}\\right] + \\left[1 - \\frac{1}{4}\\right]}du \\\\\n&= -\\frac{1}{ \\left[u + \\frac{1}{2}\\right]^2 + \\left[ \\frac{\\sqrt{3}}{2} \\right]^2 }du \\\\\n&= -\\frac{\\frac{4}{3}}{ \\left[\\frac{2}{\\sqrt{3}}\\left(u + \\frac{1}{2}\\right)\\right]^2 + \\frac{4}{3}\\left[ \\frac{\\sqrt{3}}{2} \\right]^2 }du \\\\\n&= -\\frac{4}{3} \\frac{1}{ \\left[\\frac{1}{\\sqrt{3}}\\left(2u + 1\\right)\\right]^2 + 1 }du.\n\\end{aligned}\n\\]\nWhile the last few lines may have seemed bizarre, unintuitive, and adding needless complexity, there is a method to our madness. It is known that7 \\[\n\\arctan(x) \\equiv \\int \\frac{1}{x^2 + 1}dx.\n\\] Therefore, substituting \\(a = \\frac{1}{\\sqrt{3}}(2u + 1)\\) so that \\(da = \\frac{2}{\\sqrt{3}}du\\), \\[\n\\begin{aligned}\n\\frac{1}{x}dx &= -\\frac{4}{3} \\frac{1}{ \\left[ \\frac{1}{\\sqrt{3}} (2u + 1) \\right]^2 + 1 }du \\\\\n\\Longrightarrow \\int \\frac{1}{x}dx &= -\\frac{4}{3} \\int \\frac{1}{a^2 + 1} \\left( \\frac{\\sqrt{3}}{2}da \\right) \\\\\n\\Longrightarrow \\ln(x) &= -\\left[ \\frac{4}{3}\\frac{\\sqrt{3}}{2} \\right] \\arctan\\left(\\frac{1}{\\sqrt{3}}(2u + 1)\\right) + C \\\\\n&= -\\frac{2}{\\sqrt{3}} \\arctan\\left( \\frac{2}{\\sqrt{3}}\\left[\\frac{y}{x}\\right] + \\frac{1}{\\sqrt{3}} \\right) + C,\n\\end{aligned}\n\\] where \\(C\\) is the integrating constant8, which can be solved for in cases where an initial value9 is known. We will solve for \\(C\\) below while deriving the Poisson Distribution, so we will discuss that in more detail later.\nNow, if solving this differential equation was miserable for you, take solace in knowing that we just solved the most challenging one that we will need to tackle in this course. If you had fun solving this integral, I suggest you take more electives in the mathematics department during your graduate work.\n\n\n4.1.4 Integrating Factors\nWhen we have a linear10 first order differential equation, there are various techniques and strategies that work based on the form of the differential equation. When we have a differential equation with the form \\[\n\\frac{dy}{dx} + yf(x) = g(x),\n\\] then we can multiply both sides of the equation by an integrating factor11 to make the problem easier to solve. Recall the Product Rule: \\[\n\\frac{d}{dx}\\left[f(x) \\times g(x)\\right] \\equiv f(x) \\frac{dg}{dx} + g(x) \\frac{df}{dx}\n\\] So the purpose of the integrating factor is to find something that can be multiplied by the differential equation so that the left hand can be re-written as the derivative of a product.\nFor differential equations in the form above, the well-known integrating factor is \\[\nI(x) = \\exp\\left[ \\int f(x)dx \\right].\n\\] Let’s confirm this via algebraic manipulation, starting with the product rule form of \\(y \\times I(x)\\), then invoking the chain rule on \\(I(x)\\): \\[\n\\begin{aligned}\n\\frac{d}{dx} \\left( y \\times I(x) \\right) &= \\frac{d}{dx} \\left( y \\times \\exp\\left[ \\int f(x)dx \\right] \\right) \\\\\n&= y \\times \\left( \\frac{d}{dx} \\exp\\left[ \\int f(x)dx \\right] \\right) + \\exp\\left[ \\int f(x)dx \\right] \\frac{dy}{dx} \\\\\n&= y \\left( \\exp\\left[ \\int f(x)dx \\right] \\right) \\frac{d}{dx} \\int f(x)dx + \\exp\\left[ \\int f(x)dx \\right] \\frac{dy}{dx} \\\\\n&= yf(x) \\exp\\left[ \\int f(x)dx \\right] + \\exp\\left[ \\int f(x)dx \\right] \\frac{dy}{dx} \\\\\n&= \\exp\\left[ \\int f(x)dx \\right] \\left( \\frac{dy}{dx} + yf(x) \\right).\n\\end{aligned}\n\\]\nNow, using what we know, we substitute this into the original differential equation: \\[\n\\begin{aligned}\n\\frac{dy}{dx} + yf(x) &= g(x) \\\\\n\\Longrightarrow \\exp\\left[ \\int f(x)dx \\right] \\left( \\frac{dy}{dx} + yf(x) \\right) &= g(x) \\exp\\left[ \\int f(x)dx \\right] \\\\\n\\Longrightarrow \\frac{d}{dx} \\left( y \\times \\exp\\left[ \\int f(x)dx \\right] \\right) &= g(x) \\exp\\left[ \\int f(x)dx \\right] \\\\\n\\Longrightarrow y\\exp\\left[ \\int f(x)dx \\right] &= \\int g(x) \\exp\\left[ \\int f(x)dx \\right] dx,\n\\end{aligned}\n\\] which can often be solved, or at least simplified, if \\(f(x)\\) is a “nice” function.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#deriving-the-distribution",
    "href": "chapters/poisson_20250310.html#deriving-the-distribution",
    "title": "4  The Poisson Distribution",
    "section": "4.2 Deriving the Distribution",
    "text": "4.2 Deriving the Distribution\nNow that we have recalled the basics of very simple solving ordinary differential equations, we can follow along with Prof. Cowen’s notes on deriving the Poisson distribution.12 Suppose we are counting independent events which happen over a fixed interval of time (such as patients visiting a clinic each hour). Let \\(t\\) be the time, let \\(\\{T, T + \\Delta t\\}\\) be a finite interval of time with width \\(\\Delta t\\), and let \\(1\\) indicate that the event occurs within the interval (for example, that a single patient enters the clinic within this next small window of time). Then, we can express the probability of a new event happening between “now” (time \\(T\\)) and the next \\(\\Delta t\\) few seconds as \\[\n\\mathbb{P}\\left[1 | T \\le t \\le T + \\Delta t \\right] = \\lambda \\Delta t,\n\\] where \\(\\lambda\\) is the “rate” of visits within a standard “unit” of time (like an hour). We can then see that this product \\(\\lambda \\Delta t\\) is the rate over an hour (\\(\\lambda\\)) multiplied by the amount of time in our small observation interval (\\(\\Delta t\\)). Because “now” (time \\(T\\) is arbitrary), we simplify this notation a bit and say \\[\n\\begin{aligned}\n\\mathbb{P}(1|\\Delta t) &\\equiv \\lambda \\Delta t \\\\\n\\mathbb{P}(0|\\Delta t) &\\equiv 1 - \\lambda \\Delta t.\n\\end{aligned}\n\\] Finally, let’s assume that we already know if an event occurred before “now”. That is, \\(\\mathbb{P}[0|t \\le T]\\) and \\(\\mathbb{P}[1|t \\le T]\\) are known.\n\n4.2.1 Probability that the First Event will Happen Later\nBecause events are independent, the probability that the “first” event happens after the next \\(\\Delta t\\) (that no events have happened yet AND no events will happen for the next \\(\\Delta t\\) units of time) is \\[\n\\begin{aligned}\n\\mathbb{P}(0|\\Delta t) &\\equiv \\mathbb{P}(0|t \\le T + \\Delta t) \\\\\n&= \\mathbb{P}(0|t \\le T) \\times \\mathbb{P}(0|T \\le t \\le \\Delta t) \\\\\n&= \\mathbb{P}(0|t \\le T) \\times (1 - \\lambda \\Delta t) \\\\\n&= \\mathbb{P}(0|t \\le T) - \\lambda \\mathbb{P}(0|t \\le T) \\Delta t \\\\\n\\Longrightarrow \\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T) &= - \\lambda \\mathbb{P}(0|t \\le T) \\Delta t \\\\\n\\Longrightarrow \\frac{\\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T)}{\\Delta t} &= - \\lambda \\mathbb{P}(0|t \\le T).\n\\end{aligned}\n\\]\nNotice that we are interested in the “instantaneous” probability of the next event. Hence, we want to take \\(\\Delta t \\rightarrow 0\\), which will yield a first order, linear differential equation. Thus, \\[\n\\begin{aligned}\n\\frac{\\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T)}{\\Delta t} &= - \\lambda \\mathbb{P}(0|t \\le T) \\\\\n\\Longrightarrow \\lim_{\\Delta t \\rightarrow 0} \\frac{\\mathbb{P}(0|t \\le T + \\Delta t) - \\mathbb{P}(0|t \\le T)}{\\Delta t} &= - \\lim_{\\Delta t \\rightarrow 0} \\lambda \\mathbb{P}(0|t \\le T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\mathbb{P}(0|t \\le T) &= - \\lambda \\mathbb{P}(0|t \\le T) \\\\\n\\Longrightarrow \\frac{1}{\\mathbb{P}(0|t \\le T)} d\\mathbb{P}(0|t \\le T)  &= - \\lambda dt \\\\\n\\Longrightarrow \\int \\frac{1}{\\mathbb{P}(0|t \\le T)} d\\mathbb{P}(0|t \\le T)  &= -\\lambda \\int dt \\\\\n\\Longrightarrow \\ln\\left[ \\mathbb{P}(0|t \\le T) \\right] &= - \\lambda t + C \\\\\n\\Longrightarrow \\mathbb{P}(0|t \\le T) &= e^{-\\lambda t + C} \\\\\n&= Ae^{-\\lambda t},\n\\end{aligned}\n\\] for some constant \\(A\\).\nNow, we have the general solution, but we can incorporate the initial condition that \\(\\mathbb{P}(0|t = 0) = 1\\); that is, that no successes occurred before the experiment started. In our example of clinic visits, this means that no patients were already hiding inside the clinic before the doors opened in the morning. Therefore, we have that \\(Ae^{-\\lambda (0)} = 1\\), so \\(A = 1\\). Therefore, \\[\n\\mathbb{P}(0|t \\le T) = e^{-\\lambda t}.\n\\] This is the answer to the question: “what is the probability we haven’t seen the first event yet and won’t see the first event right now?”\n\n\n4.2.2 A General Form for the Probability of \\(n\\) Events So Far\nThe next question we must answer to derive this distribution is: “what is the probability that we will have observed \\(n\\) events right now?” Or, \\(\\mathbb{P}(n|t  \\le T + \\Delta t)\\)? We first assume that \\(\\Delta t\\) is small enough that multiple events cannot occur simultaneously; mathematically, we say \\(\\Delta t \\in (0,\\epsilon)\\) for sufficiently small \\(\\epsilon\\). This is a composite of two possibilities:\n\nAll \\(n\\) events have already happened AND we will not observe an event “now”; that is, \\(\\mathbb{P}(n|t \\le T) \\times \\mathbb{P}(0|T \\le t \\le \\Delta t)\\), which we represent in shorthand as \\(\\mathbb{P}(n|T)\\mathbb{P}(0|\\Delta t)\\).\nAll but 1 event has already happened AND we will observe an event “now”; that is, \\(\\mathbb{P}(n - 1|t \\le T) \\times \\mathbb{P}(1|T \\le t \\le \\Delta t)\\), which we represent in shorthand as \\(\\mathbb{P}(n - 1|T)\\mathbb{P}(1|\\Delta t)\\).\n\nRecall that we defined \\(\\mathbb{P}(1|\\Delta t) \\equiv \\lambda \\Delta t\\) and \\(\\mathbb{P}(0|\\Delta t) \\equiv 1 - \\lambda \\Delta t\\). Thus (using our shorthand notation to move from the first to the second line), \\[\n\\begin{aligned}\n\\mathbb{P}(n|t \\le T + \\Delta t) &= \\mathbb{P}(n|t \\le T) \\times \\mathbb{P}(0|T \\le t \\le \\Delta t) + \\mathbb{P}(n - 1|t \\le T) \\times \\mathbb{P}(1|T \\le t \\le \\Delta t) \\\\\n\\Longrightarrow \\mathbb{P}(n|T + \\Delta t) &= \\mathbb{P}(n|T) \\mathbb{P}(0|\\Delta t) + \\mathbb{P}(n - 1|T) \\mathbb{P}(1|\\Delta t) \\\\\n&= \\mathbb{P}(n|T) \\left[ 1 - \\lambda \\Delta t \\right] + \\mathbb{P}(n - 1|T) \\left[ \\lambda \\Delta t \\right] \\\\\n&= \\mathbb{P}(n|T) - \\lambda \\mathbb{P}(n|T) \\Delta t + \\lambda \\mathbb{P}(n - 1|T) \\Delta t.\n\\end{aligned}\n\\]\nNow, we will follow a similar strategy as above. We will first rearrange terms, then construct a derivative as we take \\(\\Delta t \\rightarrow 0\\), and finally identify the components of the differential equation which yield an Integrating Factor. Thus, \\[\n\\begin{aligned}\n\\mathbb{P}(n|T + \\Delta t) - \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\Delta t &= \\lambda \\mathbb{P}(n - 1|T) \\Delta t \\\\\n\\Longrightarrow \\frac{\\mathbb{P}(n|T + \\Delta t) - \\mathbb{P}(n|T)}{\\Delta t} + \\lambda \\mathbb{P}(n|T) &= \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\lim_{\\Delta t \\rightarrow 0} \\frac{\\mathbb{P}(n|T + \\Delta t) - \\mathbb{P}(n|T)}{\\Delta t} + \\lambda \\mathbb{P}(n|T) &= \\lim_{\\Delta t \\rightarrow 0} \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) &= \\lambda \\mathbb{P}(n - 1|T),\n\\end{aligned}\n\\] so for the Integrating Factor, \\(f(x) = \\lambda\\) and \\(g(x) = \\lambda \\mathbb{P}(n - 1|T)\\). Therefore, \\(I(x) = \\exp\\left[\\int\\lambda dt\\right]\\), and \\[\n\\begin{aligned}\n\\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) &= \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\exp\\left[\\int\\lambda dt\\right] \\times \\left( \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\right) &= \\exp\\left[\\int\\lambda dt\\right] \\times \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow e^{\\lambda t + C} \\times \\left( \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\right) &= e^{\\lambda t + C} \\times \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow e^{\\lambda t} \\times \\left( \\frac{d}{dt} \\mathbb{P}(n|T) + \\lambda \\mathbb{P}(n|T) \\right) &= e^{\\lambda t} \\times \\lambda \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n - 1|T).\n\\end{aligned}\n\\]\nWhile this is a solution, we don’t know how to integrate \\(\\mathbb{P}(n - 1|T)\\) for any arbitrary \\(n\\).\n\n\n4.2.3 A Closed Form of the Distribution for Small \\(n\\)\nEven though the general solution we found above isn’t particularly helpful for a specific value of \\(n\\), we do have a closed form for \\(n = 0\\). We showed that \\(\\mathbb{P}(0|T) = e^{-\\lambda t}\\) in the first derivation subsection. Therefore, we will leave this solution still in the form of a differential equation and construct the equations iteratively for all \\(n\\). We start with \\(n = 1\\): \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n - 1|T) \\\\\n\\Longrightarrow \\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n = 1|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n - 1 = 0|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ e^{-\\lambda t} \\right] \\\\\n&= \\lambda \\\\\n\\Longrightarrow e^{\\lambda t} \\mathbb{P}(1|T) &= \\int \\lambda dt \\\\\n&= \\lambda t + C.\n\\end{aligned}\n\\]\nWe know that \\(\\mathbb{P}(1|t = 0) = 0\\). In our clinic example, again we state that there are no patients “hiding” in the clinic before the doors open. Therefore, \\[\n\\begin{aligned}\ne^{\\lambda (0)} \\mathbb{P}(1|t = 0) &= \\lambda (0) + C \\\\\n\\Longrightarrow (1) (0) &= 0 + C \\\\\n\\Longrightarrow 0 &= C.\n\\end{aligned}\n\\] Without loss of generality, we then further state that \\(\\mathbb{P}(n|t = 0) = 0\\), which implies that \\(C = 0\\) for each solution of this differential equation. Therefore, \\[\n\\begin{aligned}\ne^{\\lambda t} \\mathbb{P}(1|T) &= \\lambda t + 0 \\\\\n\\Longrightarrow \\mathbb{P}(1|T) &= \\lambda t e^{-\\lambda t}.\n\\end{aligned}\n\\]\nNow we can substitute \\(\\mathbb{P}(1|T) = \\lambda t e^{-\\lambda t}\\) to solve for \\(\\mathbb{P}(2|T)\\): \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(2|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(1|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ \\lambda t e^{-\\lambda t} \\right] \\\\\n&= \\lambda^2 t\\\\\n\\Longrightarrow \\mathbb{P}(2|T) &= e^{-\\lambda t} \\left[ \\int \\lambda^2 t dt \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{2}(\\lambda t)^2 + C \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{2}(\\lambda t)^2 + 0 \\right] \\\\\n&= \\frac{1}{2}(\\lambda t)^2 e^{-\\lambda t}.\n\\end{aligned}\n\\]\nWe’re almost at the “ad nauseum” component of this derivation. Substituting \\(\\mathbb{P}(2|T) = \\frac{1}{2}(\\lambda t)^2 e^{-\\lambda t}\\) yields \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(3|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(2|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ \\frac{1}{2}(\\lambda t)^2 e^{-\\lambda t} \\right] \\\\\n&= \\frac{1}{2} \\lambda^3 t^2\\\\\n\\Longrightarrow \\mathbb{P}(3|T) &= e^{-\\lambda t} \\left[ \\int \\frac{1}{2} \\lambda^3 t^2 dt \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{3 \\times 2}(\\lambda t)^3 + C \\right] \\\\\n&= e^{-\\lambda t} \\left[ \\frac{1}{3 \\times 2}(\\lambda t)^3 + 0 \\right] \\\\\n&= \\frac{(\\lambda t)^3}{3!} e^{-\\lambda t}.\n\\end{aligned}\n\\]\n\n\n4.2.4 Induction Proof for all \\(n\\)\nLet’s recap what we know: \\[\n\\begin{aligned}\n(1) &: \\mathbb{P}(0|T) = e^{-\\lambda t} \\\\\n(2) &: \\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n|T) \\right) = \\lambda e^{\\lambda t} \\mathbb{P}(n - 1|T)\n\\end{aligned}\n\\]\nFor mathematical induction, we need a hypothesis. The pattern of solutions we found was that \\[\n\\mathbb{P}(n|t \\le T) = \\frac{(\\lambda t)^n}{n!} e^{-\\lambda t}.\n\\] The base case is then when \\(n = 0\\), so \\[\n\\mathbb{P}(n = 0|t \\le T) = \\frac{(\\lambda t)^0}{0!} e^{-\\lambda t} = e^{-\\lambda t},\n\\] which we showed to be true above. Assuming the hypothesis is true, the induction is then to show that the following is true: \\[\n\\mathbb{P}(n + 1|t \\le T) = \\frac{(\\lambda t)^{n + 1}}{(n + 1)!} e^{-\\lambda t}.\n\\] That is, \\[\n\\begin{aligned}\n\\frac{d}{dt} \\left( e^{\\lambda t} \\mathbb{P}(n + 1|T) \\right) &= \\lambda e^{\\lambda t} \\mathbb{P}(n|T) \\\\\n&= \\lambda e^{\\lambda t} \\left[ \\frac{(\\lambda t)^n}{n!} e^{-\\lambda t} \\right] \\\\\n&= \\frac{\\lambda^{n+1}}{n!} t^n \\\\\n\\Longrightarrow \\mathbb{P}(n + 1|T) &= \\frac{\\lambda^{n+1}}{n!} e^{-\\lambda t} \\int t^n dt \\\\\n&= \\frac{\\lambda^{n+1}}{n!} e^{-\\lambda t} \\left[ \\frac{1}{n + 1} t^{n + 1} + C \\right] \\\\\n&= \\frac{\\lambda^{n+1}}{n!} e^{-\\lambda t} \\left[ \\frac{1}{n + 1} t^{n + 1} + 0 \\right] \\\\\n&= \\frac{(\\lambda t)^{n + 1}}{(n + 1)!} e^{-\\lambda t},\n\\end{aligned}\n\\] which completes the proof. Therefore, \\[\nf_{\\text{Poisson}}(k|\\lambda) \\equiv \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#example-random-samples",
    "href": "chapters/poisson_20250310.html#example-random-samples",
    "title": "4  The Poisson Distribution",
    "section": "4.3 Example Random Samples",
    "text": "4.3 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nN &lt;- 5\n\nxSymm &lt;- rpois(n = 500, lambda = 25)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n30  = xSymm[1:30],\n  n100 = xSymm[1:100],\n  n500 = xSymm\n)\nbinsSymm_int &lt;- seq.int(from = -1, to = max(xSymm) + 1, by = 1)\n\nxSkew &lt;- rpois(n = 500, lambda = 2.5)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n30  = xSkew[1:30],\n  n100 = xSkew[1:100],\n  n500 = xSkew\n)\nbinsSkew_int &lt;- seq.int(from = -1, to = max(xSkew) + 1, by = 1)\n# we are drawing until we reach N successes, so the upper limit should be \n# N * (1 / min(prob)) + epsilon\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSkew_ls$n5, breaks = binsSkew_int)\nhist(samplesSkew_ls$n30, breaks = binsSkew_int)\nhist(samplesSkew_ls$n100, breaks = binsSkew_int)\nhist(samplesSkew_ls$n500, breaks = binsSkew_int)\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nhist(samplesSymm_ls$n5, breaks = binsSymm_int)\nhist(samplesSymm_ls$n30, breaks = binsSymm_int)\nhist(samplesSymm_ls$n100, breaks = binsSymm_int)\nhist(samplesSymm_ls$n500, breaks = binsSymm_int)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/poisson_20250310.html#show-that-this-is-a-distribution",
    "title": "4  The Poisson Distribution",
    "section": "4.4 Show that this is a Distribution",
    "text": "4.4 Show that this is a Distribution\nAfter the Herculean effort to derive this distribution, showing that it is a distribution is downright pedestrian in comparison.\n\n4.4.1 The Distribution is Non-negative\nAs we already know, \\(\\lambda &gt; 0\\), \\(t \\ge 0\\), and \\(k \\in 0 \\cup\\mathbb{N}\\). Thus \\((\\lambda t)^k \\ge 0\\). Further, the exponential and factorial functions are non-negative. Thus, \\(f_{\\text{Poisson}}(k|\\lambda t) \\ge 0\\).\n\n\n4.4.2 The Total Probability is 1\nLet’s recall the MacLaurin Series Expansion for the exponential function: \\[\ne^x \\equiv \\sum_{n = 0}^{\\infty} \\frac{x^n}{n!}.\n\\] This should give us a big hint for how were are going to integrate the Poisson distribution. Recall that the support for \\(k\\) is the set of 0 and all positive integers up to \\(\\infty\\); that is \\(\\mathcal{S}(k) = [0,\\infty) \\in \\mathbb{Z}\\). Thus, we substitute the MacLaurin Series as follows: \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(k)} dF(k|\\lambda t) &= \\sum_{k = 0}^{\\infty} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t} \\\\\n&= e^{-\\lambda t} \\sum_{k = 0}^{\\infty} \\frac{(\\lambda t)^k}{k!} \\\\\n&= e^{-\\lambda t} \\left[ e^{\\lambda t}  \\right] \\\\\n&= 1.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/poisson_20250310.html#derive-the-moment-generating-function",
    "title": "4  The Poisson Distribution",
    "section": "4.5 Derive the Moment Generating Function",
    "text": "4.5 Derive the Moment Generating Function\nThe MGF is found similarly, by (again) applying the MacLaurin Series expansion for \\(e^x\\). Note that we are using \\(s\\) as the nuisance parameter of the MGF instead of \\(t\\) because we already use \\(\\lambda t\\) as the parameter of the Poisson Distribution Thus, \\[\n\\begin{aligned}\nM_k(s) &= \\int_{\\mathcal{S}(k)} e^{sk} dF(k|\\lambda t) \\\\\n&= \\sum_{k = 0}^{\\infty} e^{sk} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t} \\\\\n&= e^{-\\lambda t} \\sum_{k = 0}^{\\infty} \\frac{(e^s \\lambda t)^k}{k!} \\\\\n&= e^{-\\lambda t} e^{e^s \\lambda t} \\\\\n&= \\exp\\left[ -\\lambda t + e^s \\lambda t \\right] \\\\\n&= \\exp\\left[ \\lambda t (e^s - 1) \\right].\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/poisson_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "4  The Poisson Distribution",
    "section": "4.6 Method of Moments Estimates from Observed Data",
    "text": "4.6 Method of Moments Estimates from Observed Data\nLet’s generate some random data across 7 experiments. We assume that these 7 experiments represent 7 identical and fixed periods of time wherein to count events, with an average of with \\(\\lambda t = 5\\) events in each interval:\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7L\nlambt_num &lt;- 5\nPoisk_int &lt;- rpois(n = nTrials_int, lambda = lambt_num)\nPoisk_int\n[1] 7 3 5 8 4 1 4\n\n\nIf these data are the counts of patient visits to a clinic in these 7 time intervals, we can see that there were 7, 3, 5, 8, 4, 1, 4 patients in each interval. Now that we have the MGF and a sample of data, we can estimate the Poisson “rate” parameter \\(\\lambda t\\).\n\n4.6.1 \\(\\mathbb{E}[k]\\)\nRecall that our MGF nuisance parameter is \\(s\\), not \\(t\\); \\(\\lambda t\\) is the Poisson parameter. Now consider \\[\n\\begin{aligned}\nM_k(s) &= \\exp[ \\lambda t (e^s - 1) ] \\\\\n\\Longrightarrow \\frac{d}{ds} M_k(s) &= \\frac{d}{ds} \\exp[ \\lambda t (e^s - 1) ] \\\\\n&= \\exp[ \\lambda t (e^s - 1) ] \\frac{d}{ds} \\lambda t (e^s - 1) \\\\\n&= \\exp[ \\lambda t (e^s - 1) ] \\lambda t e^s \\\\\n&= \\lambda t \\exp[ \\lambda t (e^s - 1) + s].\n\\end{aligned}\n\\] Thus, \\[\n\\begin{aligned}\nM_k^{\\prime}(s) &= \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\\\\n\\Longrightarrow M_k^{\\prime}(0) &= \\lambda t \\exp[ \\lambda t (e^{[0]} - 1) + [0]] \\\\\n&= \\lambda t \\exp[ \\lambda t (1 - 1) ] \\\\\n&= \\lambda t \\exp[ 0 ] \\\\\n&= \\lambda t \\\\\n&= \\mathbb{E}[k].\n\\end{aligned}\n\\]\n\n\n4.6.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\nSimilarly, \\[\n\\begin{aligned}\nM_k^{\\prime}(s) &= \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\\\\n\\Longrightarrow M_k^{\\prime\\prime}(s) &= \\frac{d}{ds} \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\\\\n&= \\lambda t \\exp[ \\lambda t (e^s - 1) + s] \\frac{d}{ds} [ \\lambda t (e^s - 1) + s] \\\\\n&= \\lambda t [ \\lambda t e^s + 1] \\exp[ \\lambda t (e^s - 1) + s].\n\\end{aligned}\n\\] Evaluating this second derivative at 0 yields \\[\n\\begin{aligned}\nM_k^{\\prime\\prime}(0) &= \\lambda t [ \\lambda t e^{[0]} + 1] \\exp[ \\lambda t (e^{[0]} - 1) + [0]] \\\\\n&= \\lambda t (\\lambda t [1] + 1) \\exp[\\lambda t (1 - 1)] \\\\\n&= \\lambda t (\\lambda t + 1) \\\\\n&= \\mathbb{E}[k^2].\n\\end{aligned}\n\\] Therefore, \\[\n\\begin{aligned}\n\\text{Var}[k] &= \\mathbb{E}[k^2] - \\left[ \\mathbb{E}[k] \\right]^2 \\\\\n&= \\lambda t (\\lambda t + 1) - [\\lambda t]^2 \\\\\n&= (\\lambda t)^2 + \\lambda t - (\\lambda t)^2 \\\\\n&= \\lambda t.\n\\end{aligned}\n\\]\n\n\n4.6.3 Solving the System\nWe now see the trivial solution to our problem: the Poisson distribution has the same estimates for mean and variance. Thus, \\(\\hat{\\lambda}_{\\text{MoM}} = \\bar{k}\\). For our example data, where the true value of \\(\\lambda t\\) was 5, we see the Method of Moments estimate is\n\n\nCode\nmean(Poisk_int)\n[1] 4.57",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/poisson_20250310.html#maximum-likelihood-estimators",
    "title": "4  The Poisson Distribution",
    "section": "4.7 Maximum Likelihood Estimators",
    "text": "4.7 Maximum Likelihood Estimators\nFor this last section, we will slightly change the parametrization of the Poisson Distribution. Let the Poisson rate be \\(r = \\lambda t\\). Consider a sample \\(\\textbf{k}_i \\overset{iid}{\\sim} \\text{Pois}(r),\\ i = 1, 2, \\ldots, n\\). The log-likelihood is then \\[\n\\begin{aligned}\nf_{\\text{Pois}}(k|r) &\\equiv \\frac{r^k}{k!}e^{-r} \\\\\n\\Longrightarrow \\mathcal{L}(r|\\textbf{k}) &= \\prod_{i = 1}^n \\frac{r^{k_i}}{k_i!}e^{-r} \\\\\n\\Longrightarrow \\ell(r|\\textbf{k}) &= \\log \\left[ \\prod_{i = 1}^n \\frac{r^{k_i}}{k_i!}e^{-r} \\right] \\\\\n&= \\sum_{i = 1}^n \\log \\left[ \\frac{r^{k_i}}{k_i!}e^{-r} \\right] \\\\\n&= \\sum_{i = 1}^n \\left[ k_i\\log(r) - \\log(k_i!) - r \\right] \\\\\n&= \\log(r) \\left[ \\sum_{i = 1}^n k_i \\right] - \\left[ \\sum_{i = 1}^n \\log(k_i!) \\right] - nr.\n\\end{aligned}\n\\]\nTherefore, we find the extreme values of this log-likelihood by \\[\n\\begin{aligned}\n\\ell(r|\\textbf{k}) &= \\log(r) \\left[ \\sum_{i = 1}^n k_i \\right] - \\left[ \\sum_{i = 1}^n \\log(k_i!) \\right] - nr \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial r} \\ell(r|\\textbf{k}) &= \\frac{\\partial}{\\partial r} \\left( \\log(r) \\left[ \\sum_{i = 1}^n k_i \\right] - \\left[ \\sum_{i = 1}^n \\log(k_i!) \\right] - nr \\right) \\\\\n&= \\frac{1}{r} \\left[ \\sum_{i = 1}^n k_i \\right] - 0 - n \\\\\n&= \\frac{1}{r} [n\\bar{k}] - n \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{n\\bar{k}}{\\hat{r}} - n \\\\\n\\Longrightarrow n\\hat{r} &= n\\bar{k} \\\\\n\\Longrightarrow \\hat{r} &= \\bar{k}.\n\\end{aligned}\n\\] We have found that \\(\\hat{r} = \\bar{k}\\) yields an extreme value of \\(\\ell(r|\\textbf{k})\\), but we need to take the second derivative to confirm that it is a maximum. Then, \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial r} \\ell(r|\\textbf{k}) &= \\frac{1}{r} [n\\bar{k}] - n \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial r^2} \\ell(r|\\textbf{k}) &= \\frac{\\partial}{\\partial r} \\left[\\frac{1}{r} [n\\bar{k}] - n \\right] \\\\\n&= -\\frac{n\\bar{k}}{r^2} \\\\\n&&lt; 0.\n\\end{aligned}\n\\] Ergo, \\(\\hat{r}_{\\text{MLE}} = \\bar{k}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#exercises",
    "href": "chapters/poisson_20250310.html#exercises",
    "title": "4  The Poisson Distribution",
    "section": "4.8 Exercises",
    "text": "4.8 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/poisson_20250310.html#footnotes",
    "href": "chapters/poisson_20250310.html#footnotes",
    "title": "4  The Poisson Distribution",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Tangent↩︎\nhttps://tutorial.math.lamar.edu/classes/calci/defnofderivative.aspx↩︎\nhttps://www.geeksforgeeks.org/maths/derivatives/↩︎\nhttps://en.wikipedia.org/wiki/Homogeneous_function↩︎\nMeaning derivatives with respect to only one variable; see https://web.uvic.ca/~tbazett/diffyqs/classification_section.html↩︎\nhttps://tutorial.math.lamar.edu/classes/de/separable.aspx↩︎\nSee integral No. 9 here: https://www.physics.umd.edu/hep/drew/IntegralTable.pdf↩︎\nhttps://en.wikipedia.org/wiki/Constant_of_integration↩︎\nhttps://en.wikipedia.org/wiki/Initial_value_problem↩︎\nMeaning that \\(y^{\\prime}\\) has a power of 1↩︎\nhttps://en.wikipedia.org/wiki/Integrating_factor↩︎\nGlen Cowan, 2009. Royal Holloway University of London.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The Poisson Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html",
    "href": "chapters/exponential_20250310.html",
    "title": "5  The Exponential Distribution",
    "section": "",
    "text": "5.1 Deriving the Distribution\nLet’s consider counting events happening in an observation interval with time \\(T \\in [0,t)\\). The count of these events are generated according to a Poisson process with rate \\(\\lambda\\) and observation interval width \\(t\\), given by \\[\nf_{\\text{Pois}}(k|\\lambda t) \\equiv \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t}.\n\\] We can continue our “clinic” example from the Poisson lesson; a Poisson process could be used to describe the number of patients who visit a clinic in a one-hour period. Let’s say that we opened up the clinic in the morning, and we ask ourselves “how long do we have to wait until the first patient arrives?” Mathematically, this would be asking what the value of \\(T\\) will be when \\(k\\) increments from 0 to 1.\nThe probability that we have not yet observed an event by time \\(t\\) is given by \\[\n\\mathbb{P}(0|\\lambda, T = t) = \\frac{(\\lambda t)^0}{0!} e^{-\\lambda t} = e^{-\\lambda t}.\n\\] Notice that we can modify our question from asking about a random variable \\(k\\) to asking about a random variable \\(T\\). We then see that these two quantities are the same, but their random variables are different: \\[\n\\mathbb{P}_k(0|T = t, \\lambda) = \\mathbb{P}_T(T &gt; t|\\lambda).\n\\] In vernacular, we are saying that the probability of observing a count of zero events on or before time \\(t\\) is the same as the probability that the time of the first event is after (greater than) \\(t\\).\nBecause of the logical equivalence of these events, we can say that the probability that the first event (which happens at time \\(T\\)) hasn’t happened yet (as of time \\(t\\)) is given by \\[\n\\mathbb{P}(T &gt; t) = e^{-\\lambda t}.\n\\] This is the probability that the first event will happen after time \\(t\\). Thus, the probability that the first event will happen before the end of our observation interval (which ends at time \\(t\\)) will be the opposite of this: \\[\n\\mathbb{P}(T \\le t) = 1 - e^{-\\lambda t}.\n\\]\nNotice that we have just described the cumulative probability function1. As we all remember, the Cumulative Probability Function is the indefinite integral of the Probability Function, so to find a closed form of the Exponential distribution, we take the derivative with respect to the random variable \\(t\\). So, for \\(\\lambda,t &gt; 0\\), \\[\n\\begin{aligned}\nF_T(t|\\lambda) &= 1 - e^{-\\lambda t} \\\\\n\\Longrightarrow f_T(t|\\lambda) &= \\frac{d}{dt} \\left( 1 - e^{-\\lambda t} \\right) \\\\\n&= - e^{-\\lambda t} (-\\lambda) \\\\\n\\Longrightarrow f_{\\text{Exp}}(t|\\lambda) &= \\lambda e^{-\\lambda t}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#example-random-samples",
    "href": "chapters/exponential_20250310.html#example-random-samples",
    "title": "5  The Exponential Distribution",
    "section": "5.2 Example Random Samples",
    "text": "5.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxPeaked &lt;- rexp(n = 500, rate = 5)\nsamplesPeaked_ls &lt;- list(\n  n5   = xPeaked[1:5],\n  n50  = xPeaked[1:50],\n  n100 = xPeaked[1:100],\n  n500 = xPeaked\n)\n\nxDiffuse &lt;- rexp(n = 500, rate = 1)\nsamplesDiffuse_ls &lt;- list(\n  n5   = xDiffuse[1:5],\n  n50  = xDiffuse[1:50],\n  n100 = xDiffuse[1:100],\n  n500 = xDiffuse\n)\n\nrange_num &lt;- range(c(xPeaked, xDiffuse))\n\nrm(xPeaked, xDiffuse)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesPeaked_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPeaked_ls$n50, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPeaked_ls$n100, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPeaked_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n50, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n100, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#formal-foundations",
    "href": "chapters/exponential_20250310.html#formal-foundations",
    "title": "5  The Exponential Distribution",
    "section": "5.3 Formal Foundations",
    "text": "5.3 Formal Foundations\nAfter all the suffering through theory we’ve done in the last few lessons, the formal theory needed for this lesson is quite light.\n\n5.3.1 Improper Integrals\nThe Fundamental Theorem of Calculus states that, if \\(f\\) is a continuous function on a closed interval from \\(a\\) to \\(b\\) (inclusive) with anti-derivative \\(F\\), then \\[\n\\int_a^b f(x) dx \\equiv \\left[ F(x) \\right]_a^b \\equiv F(b) - F(a).\n\\] Notice that this definition requires that the interval include both \\(a\\) and \\(b\\). Improper integrals mean that either \\(f\\) is not continuous over the interval \\([a,b]\\), or either \\(a\\), \\(b\\), or both, are infinite. For many statistical distributions, the bounds of the support of the random variable include \\(\\infty\\) on one side or both. That means that we can’t just take the integral and substitute in \\(\\infty\\) and “call it a day”. For common statistical distributions with unbounded support, there are two cases.\nCase 1: The Interval is Open on One Side. If we have either the lower or upper bound of the integral tending to \\(\\infty\\), then we do this: \\[\n\\begin{aligned}\n\\int_a^{\\infty} f(x) dx &= \\lim_{\\psi\\to\\infty} F(\\psi) - F(a) \\\\\n\\int_{-\\infty}^b f(x) dx &= F(b) - \\lim_{\\psi\\to -\\infty} F(\\psi) \\\\\n\\end{aligned}\n\\]\nCase 2: The Interval is Open on Both Sides. If we have the lower and upper bound of the integral as the entire Real line, then we split the integral into two “one-sided” improper integrals at some value \\(x = a\\) and evaluate each separately. That is: \\[\n\\int_{-\\infty}^{\\infty} f(x) dx = \\int_{-\\infty}^a f(x) dx\\ +\\ \\int_a^{\\infty} f(x) dx.\n\\] If \\(f\\) is symmetric around the axis \\(x = a\\), then this simplifies even further: \\[\n\\int_{-\\infty}^{\\infty} f(x) dx = 2 \\times \\int_a^{\\infty} f(x) dx.\n\\] The Normal and Student’s \\(t\\) distributions are the two most famous distributions with support over the entire Real line, and they are both symmetric around their mean values (\\(\\mu\\) for the Normal and 0 for the Student’s \\(t\\) distributions).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/exponential_20250310.html#show-that-this-is-a-distribution",
    "title": "5  The Exponential Distribution",
    "section": "5.4 Show that this is a Distribution",
    "text": "5.4 Show that this is a Distribution\nWe recall that \\(\\lambda, t &gt; 0\\), so \\(f_{\\text{Exp}}(t|\\lambda) &gt; 0\\). For the total probability, we need to remember that we can reverse the limits of integration,2 and we need to be able to solve an improper integral (described above). Once you have reviewed these concepts, consider \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(t)} dF(t|\\lambda) &= \\int_0^{\\infty} \\lambda e^{-\\lambda t} dt \\\\\n&= \\lim_{\\psi \\to \\infty} \\left[ -\\frac{\\lambda}{\\lambda} e^{-\\lambda t} \\right]_{t = 0}^{\\psi} \\\\\n&= \\lim_{\\psi \\to \\infty} \\left[ -e^{-\\lambda t} (-1) \\right]_{\\psi}^{t = 0} \\\\\n&= \\lim_{\\psi \\to \\infty} \\left[ e^{-\\lambda t} \\right]_{\\psi}^{t = 0} \\\\\n&= \\left[ e^{\\lambda [0]} \\right] - \\left[ \\lim_{\\psi \\to \\infty} e^{-\\lambda \\psi} \\right] \\\\\n&= 1 - 0.\n\\end{aligned}\n\\] Therefore, \\(f_{\\text{Exp}}(t|\\lambda)\\) is a probability distribution.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/exponential_20250310.html#derive-the-moment-generating-function",
    "title": "5  The Exponential Distribution",
    "section": "5.5 Derive the Moment Generating Function",
    "text": "5.5 Derive the Moment Generating Function\nAs with the Poisson Distribution, we will call the nuisance parameter for the MGF \\(s\\) instead of \\(t\\), as \\(t\\) is the random variable of the Exponential Distribution. Recall that the MGF must be defined for \\(s\\) in an \\(\\epsilon\\)-neighbourhood of 0, for some arbitrarily small \\(\\epsilon\\). This means that, without loss of generality, we can bound \\(s\\) to be smaller than the rate parameter \\(\\lambda &gt; 0\\) (which we will need below). Thus,\n\\[\n\\begin{aligned}\nM_t(s) &= \\int_{\\mathcal{S}(t)} e^{st} dF(t|\\lambda) \\\\\n&= \\int_0^{\\infty} e^{st} \\lambda e^{-\\lambda t} dt \\\\\n&= \\lambda \\int_0^{\\infty} e^{t(s - \\lambda)} dt \\\\\n&= \\frac{\\lambda}{s - \\lambda} \\lim_{\\psi\\to\\infty} \\left[ e^{t(s - \\lambda)} \\right]_{t = 0}^{\\psi},\\ s &lt; \\lambda \\\\\n&= \\frac{\\lambda}{s - \\lambda} \\left[ \\lim_{\\psi\\to\\infty} e^{\\psi(s - \\lambda)} - e^{[0](s - \\lambda)} \\right] \\\\\n&= \\frac{\\lambda}{s - \\lambda} \\left[ \\lim_{\\psi\\to\\infty} e^{-\\psi(\\lambda - s)} - 1 \\right],\\ s &lt; \\lambda \\Rightarrow \\lambda - s &gt; 0 \\\\\n&= \\frac{\\lambda}{s - \\lambda} [0 - 1] \\\\\n&= \\frac{\\lambda}{\\lambda - s}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/exponential_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "5  The Exponential Distribution",
    "section": "5.6 Method of Moments Estimates from Observed Data",
    "text": "5.6 Method of Moments Estimates from Observed Data\nLet’s generate some random data. We continue our “clinic” example, and now we generate 7 “waiting times” until the first patient walks in. For a single experiment, that is, when we first open the clinic, how long will we have to wait for the first patient to arrive? Let’s assume the same rate of \\(\\lambda = 5\\) for one hour that we used in the previous lesson. We can generate data (in fractional hours) by\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7L\nrate_num &lt;- 5\nExpt_num &lt;- rexp(n = nTrials_int, rate = rate_num)\nExpt_num\n[1] 0.03635 0.00557 0.27411 0.00179 0.21331 0.20857 0.27598\nExpt_num * 60\n[1]  2.181  0.334 16.446  0.108 12.798 12.514 16.559\n\n\nSo, for these 7 independent trials where the waiting times \\(T\\) have an identical Exponential distribution with rate of 5 patients per hour, we wait 2.2, 0.3, 16.4, 0.1, 12.8, 12.5, 16.6 minutes to see the first patient.\n\n5.6.1 \\(\\mathbb{E}[t]\\)\nConsider \\[\n\\begin{aligned}\nM_t(s) &= \\lambda(\\lambda - s)^{-1} \\\\\n\\Longrightarrow M_t^{\\prime}(s) &= \\frac{d}{ds} \\lambda(\\lambda - s)^{-1} \\\\\n&= -\\lambda(\\lambda - s)^{-2}(-1) \\\\\n&= \\lambda(\\lambda - s)^{-2} \\\\\n\\Longrightarrow M_t^{\\prime}(0) &= \\frac{\\lambda}{(\\lambda - [0])^2} \\\\\n&= \\frac{1}{\\lambda} \\\\\n&= \\mathbb{E}[t].\n\\end{aligned}\n\\]\n\n\n5.6.2 \\(\\mathbb{E}[t^2]\\) and \\(\\text{Var}[t]\\)\nWe continue: \\[\n\\begin{aligned}\nM^{\\prime}_t(s) &= \\lambda(\\lambda - s)^{-2} \\\\\n\\Longrightarrow M^{\\prime\\prime}_t(s) &= \\frac{d}{ds} \\lambda(\\lambda - s)^{-2} \\\\\n&= -2\\lambda(\\lambda - s)^{-3}(-1) \\\\\n&= \\frac{2\\lambda}{(\\lambda - s)^3} \\\\\n\\Longrightarrow M^{\\prime\\prime}_t(0) &= \\frac{2\\lambda}{(\\lambda - [0])^3} \\\\\n&= \\frac{2}{\\lambda^2} \\\\\n&= \\mathbb{E}[t^2].\n\\end{aligned}\n\\]\nThen, \\[\n\\text{Var}[t] = \\mathbb{E}[t^2] - \\left[\\mathbb{E}[t]\\right]^2 = \\frac{2}{\\lambda^2} - \\left[\\frac{1}{\\lambda}\\right]^2 = \\frac{1}{\\lambda^2}.\n\\]\n\n\n5.6.3 Solving the System\nWe then have that \\(\\bar{x} = \\frac{1}{\\lambda}\\) and \\(s^2 = \\frac{1}{\\lambda^2}\\), which is an overdetermined system (with \\(\\hat{\\lambda}_{\\text{MoM}} = \\frac{1}{\\bar{t}}\\)). For the Exponential Distribution, once we know the mean, then we should also know the variance. For our sample, generated from an Exponential with rate \\(\\lambda = 5\\), \\(\\hat{\\lambda}_{\\text{MoM}}\\) = 6.892. It’s worth noting that the Method of Moments estimate for this distribution requires a very large number of samples before it is “close” to the true value (the Maximum Likelihood estimator is the same, as we’ll see next).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/exponential_20250310.html#maximum-likelihood-estimators",
    "title": "5  The Exponential Distribution",
    "section": "5.7 Maximum Likelihood Estimators",
    "text": "5.7 Maximum Likelihood Estimators\nTo estimate a true rate, \\(\\lambda\\), using the likelihood, we collect a set of independent observed times for the first success. That is, \\(\\textbf{t} = [t_1, t_2, \\ldots, t_n] \\overset{iid}{\\sim} \\text{Exp}(\\lambda)\\). Thus, \\[\n\\begin{aligned}\nf_{\\text{Exp}}(t|\\lambda) &= \\lambda e^{-\\lambda t} \\\\\n\\Longrightarrow \\mathcal{L}(\\lambda|\\textbf{t}) &= \\prod_{i = 1}^n \\lambda e^{-\\lambda t_i} \\\\\n\\Longrightarrow \\ell(\\lambda|\\textbf{t}) &= \\log \\left[ \\prod_{i = 1}^n \\lambda e^{-\\lambda t_i} \\right] \\\\\n&= \\sum_{i = 1}^n \\log \\left[ \\lambda e^{-\\lambda t_i} \\right] \\\\\n&= \\sum_{i = 1}^n \\left[ \\log(\\lambda) - \\lambda t_i \\right] \\\\\n&= n\\log(\\lambda) - \\lambda \\sum_{i = 1}^n t_i \\\\\n&= n\\log(\\lambda) - n\\lambda\\bar{t} \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\lambda} \\ell(\\lambda|\\textbf{t}) &= \\frac{\\partial}{\\partial\\lambda} \\left( n\\log(\\lambda) - n\\lambda\\bar{t} \\right) \\\\\n&= \\frac{n}{\\lambda} - n\\bar{t} \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{n}{\\hat{\\lambda}} - n\\bar{t} \\\\\n\\Longrightarrow n\\bar{t} &= \\frac{n}{\\hat{\\lambda}} \\\\\n\\Longrightarrow \\hat{\\lambda} &= \\frac{1}{\\bar{t}}.\n\\end{aligned}\n\\] In order to confirm that this extreme value of the log-likelihood is truly a maxima, we take the second partial derivative: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\lambda} \\ell(\\lambda|\\textbf{t}) &= \\frac{n}{\\lambda} - n\\bar{t} \\\\\n&= n\\lambda^{-1} - n\\bar{t} \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial\\lambda^2} \\ell(\\lambda|\\textbf{t}) &= -n\\lambda^{-2} \\\\\n&&lt; 0.\n\\end{aligned}\n\\] Hence, \\(\\hat{\\lambda}_{MLE} = \\frac{1}{\\bar{t}}\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#exercises",
    "href": "chapters/exponential_20250310.html#exercises",
    "title": "5  The Exponential Distribution",
    "section": "5.8 Exercises",
    "text": "5.8 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/exponential_20250310.html#footnotes",
    "href": "chapters/exponential_20250310.html#footnotes",
    "title": "5  The Exponential Distribution",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Cumulative_distribution_function↩︎\nhttps://proofwiki.org/wiki/Reversal_of_Limits_of_Definite_Integral↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Exponential Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html",
    "href": "chapters/theory_gamma_function_20250707.html",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "",
    "text": "6.1 Overview\nAs we mentioned in the Negative Binomial lesson, we could spend literal weeks discussing and proving the many properties of the Gamma Function (and its relative the Beta Function). Instead, we will try to distill the most important properties of these functions that are necessary for us to derive and prove properties of the Gamma, Beta, \\(\\chi^2\\), Student’s \\(t\\), and Central \\(F\\) distributions. As we saw previously, the Gamma Function is one (of potentially many) smooth interpolations between the values of \\(x!\\) evaluated at each non-negative integer.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#formal-foundations-of-foundations",
    "href": "chapters/theory_gamma_function_20250707.html#formal-foundations-of-foundations",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.2 Formal Foundations (of Foundations)",
    "text": "6.2 Formal Foundations (of Foundations)\nYes, I know this entire chapter is already dedicated to “math foundations”, but we have to go deeper (insert Inception joke here). We need some foundations to our foundations.\n\n6.2.1 L’Hospital’s Rule\nIf we have the limit of a ratio of functions, where the ratio of the numerator and denominator yield an indeterminant form1, then we can apply L’Hospital’s Rule to simplify the limit. Consider \\[\n\\lim_{x \\to c} \\frac{f(x)}{g(x)}.\n\\]\nWe need four conditions to hold before we can apply L’Hospital’s Rule:\n\nThe ratio must have an indeterminant form of the same value in the numerator and denominator (such as \\(0/0\\) or \\(\\infty/\\infty\\)).\nThe derivatives of \\(f\\) and \\(g\\) must exist in a neighbourhood of the point \\(c\\), but not necessarily at the point \\(c\\) itself.\nThe derivative of \\(g\\) must not equal 0 in this neighbourhood of the point \\(c\\), except potentially at the point \\(c\\) itself.\nThe ratio of the derivatives of \\(f\\) and \\(g\\) (not the derivative of the ratio) must exist at the point \\(c\\) (even if we can’t find it immediately).\n\nIF all four conditions hold, then \\[\n\\lim_{x \\to c} \\frac{f(x)}{g(x)} = \\lim_{x \\to c} \\frac{f^{\\prime}(x)}{g^{\\prime}(x)}.\n\\]\n\n\n6.2.2 The Jacobian Determinant\nIn univariate calculus, we used \\(u\\)-substitution2 as the “inverse” of the Chain Rule for derivatives. As you should recall from multivariable calculus, the multi-dimensional version of \\(u\\)-substitution involves a matrix of derivatives in all possible directions. If you need a reminder on what matrices3 are or what a determinant4 is, then I apologize that such material is beyond the scope of this text.\nConsider a function \\(f(x,y)\\) that we are integrating with respect to both \\(x\\) and \\(y\\). When we change variables from \\(x,y\\) to some other variables, say \\(u,v\\), then we use the Jacobian Determinant as the value to substitute in the place of \\(dydx\\) or \\(dxdy\\) (we assume that they can be reversed). This determinant for two dimensions (including the absolute value to ensure that the area is always positive) is then: \\[\n|\\textbf{J}| \\equiv \\det\\! \\begin{bmatrix}\n  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\\n  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}\n\\end{bmatrix} =\n  \\left| \\frac{\\partial x}{\\partial u} \\frac{\\partial y}{\\partial v} - \\frac{\\partial x}{\\partial v} \\frac{\\partial y}{\\partial u} \\right|.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#the-gamma-function",
    "href": "chapters/theory_gamma_function_20250707.html#the-gamma-function",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.3 The Gamma Function",
    "text": "6.3 The Gamma Function\nFor a complex number \\(z = a + bi\\) (except for the negative integers), the Weierstrass’s Definition of the Gamma Function is \\[\n\\Gamma(z) \\equiv \\frac{e^{-\\gamma z}}{z} \\prod_{n = 1}^{\\infty} \\left( 1 + \\frac{z}{n} \\right)^{-1} e^{\\frac{z}{n}},\n\\] where \\(\\gamma \\approx 0.577\\) is the Euler-Mascheroni constant. This is (in my experience) the most complex form of the Gamma function. In contrast, if \\(z\\) can be written as a non-negative integer \\(n\\), then we get the simplest form of all: \\[\n\\Gamma(n) \\equiv (n - 1)!.\n\\]\nHowever, we don’t need the “most” or the “least” complex versions of this function. Instead, we need a version with the flexibility to handle any \\(z \\in \\mathbb{R}^+\\), so we will dive deep into the “common form” of the Gamma Function: \\[\n\\Gamma(z) = \\int_0^{\\infty} t^{z - 1}e^{-t}dt,\\ z \\in \\mathbb{R}^+.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#integer-form-of-the-lower-incomplete-gamma-function",
    "href": "chapters/theory_gamma_function_20250707.html#integer-form-of-the-lower-incomplete-gamma-function",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.4 Integer Form of the Lower Incomplete Gamma Function",
    "text": "6.4 Integer Form of the Lower Incomplete Gamma Function\nLet \\(\\alpha, x \\in \\mathbb{R}^+\\). Then we define the lower complete Gamma Function as \\[\n\\gamma(\\alpha,x) \\equiv \\int_0^x t^{\\alpha - 1} e^{-t} dt.\n\\]\nNow, restrict \\(\\alpha \\ni \\alpha \\in 0 \\cup \\mathbb{N}\\), then we can “simplify” the above integral as \\[\n\\gamma(\\alpha,x) = (\\alpha - 1)! \\left[ 1 - e^{-x} \\sum_{k = 0}^{\\alpha - 1} \\frac{x^k}{k!} \\right].\n\\]\nThe first result has stumped me. I have not been able to figure out how to prove it. So, even though I usually tell my students to “never give up”, I’m giving up (for now) on trying to figure out how to prove this. Therefore, I am quoting the US National Institute of Standards and Technology’s Digital Library of Mathematical Functions, specifically chapter 8, section 4, equation 7. This book says that equation is true, and I’m just going to trust it.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#product-of-gamma-functions",
    "href": "chapters/theory_gamma_function_20250707.html#product-of-gamma-functions",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.5 Product of Gamma Functions",
    "text": "6.5 Product of Gamma Functions\nLet \\(a,b \\in \\mathbb{R}^+\\). We will show that \\[\n\\Gamma(a) \\times \\Gamma(b) = \\int_0^{\\infty} \\int_0^1 (uv)^{a - 1} (u - uv)^{b - 1} e^{-u} dvdu.\n\\]\nProof: First, we want to find another way to express the quantity \\(\\Gamma(a) \\times \\Gamma(b)\\), which is a product of single integrals, as a double integral. Notice that all the values with \\(t\\) are constant with respect to \\(s\\), and vice versa, so: \\[\n\\begin{aligned}\n\\Gamma(a) \\times \\Gamma(b) &\\equiv \\left[ \\int_0^{\\infty} t^{a - 1} e^{-t} dt \\right] \\times \\left[ \\int_0^{\\infty} s^{b - 1} e^{-s} ds \\right] \\\\\n&= \\int_0^{\\infty} \\int_0^{\\infty} t^{a - 1} s^{b - 1} e^{-(t + s)} dtds.\n\\end{aligned}\n\\]\nNext, we want to transform from variables in \\(\\mathbb{R}^+ \\times \\mathbb{R}^+\\) to variables in \\(\\mathbb{R}^+ \\times (0,1)\\). For our change of variables, we target the \\(\\exp[-(t+s)]\\) component first, because exponentials are more challenging to integrate than polynomials. So, let \\(u = t + s\\). We know that \\(t,s \\in \\mathbb{R}^+\\), so \\(u \\in \\mathbb{R}^+\\).\nNow, the next variable, \\(v\\), needs to have two properties: 1) \\(v \\in (0,1)\\), and 2) the product \\(uv\\) needs to be a really simple polynomial. One candidate is \\(v = t/(t + s)\\). For property (1), let’s fix \\(s\\) as any arbitrary value in \\(\\mathbb{R}^+\\). Now consider these limits (the second limit by L’Hospital’s Rule): \\[\n\\begin{aligned}\n&\\lim_{t\\to 0} \\frac{t}{t+s} = \\frac{0}{s} = 0, \\\\\n&\\lim_{t\\to\\infty} \\frac{t}{t+s} = \\lim_{t\\to\\infty} \\frac{\\frac{d}{dt} (t)}{\\frac{d}{dt} (t + s)} = \\lim_{t\\to\\infty} \\frac{1}{1+0} = 1.\n\\end{aligned}\n\\] For property (2), we note that \\(uv = [t + s][t/(t + s)] = t\\), which is a very simple polynomial.\nWe change these variables, so \\[\nv = \\frac{t}{t + s} = \\frac{t}{u} \\Rightarrow t = uv.\n\\] Moreover, \\[\nu = t + s = uv + s \\Rightarrow s = u - uv.\n\\]\nNow, we find the determinant of the Jacobian matrix: \\[\n\\begin{aligned}\n|\\textbf{J}| &\\equiv \\det\\! \\begin{bmatrix}\n  \\frac{\\partial t}{\\partial u} & \\frac{\\partial t}{\\partial v} \\\\\n  \\frac{\\partial s}{\\partial u} & \\frac{\\partial s}{\\partial v}\n\\end{bmatrix} \\\\\n&= \\det\\! \\begin{bmatrix}\n  \\frac{\\partial}{\\partial u} (uv) & \\frac{\\partial}{\\partial v} (uv) \\\\\n  \\frac{\\partial}{\\partial u} (u - uv) & \\frac{\\partial}{\\partial v} (u - uv)\n\\end{bmatrix} \\\\\n&= \\det\\! \\begin{bmatrix}\n  v & u \\\\\n  1 - v & -u\n\\end{bmatrix} \\\\\n&= \\left| (v)(-u) - (u)(1 - v) \\right| \\\\\n&= \\left| -uv - u + uv \\right| \\\\\n&= u.\n\\end{aligned}\n\\]\nTherefore, taking \\(t = uv\\), \\(s = u - uv\\), and \\(dtds = udvdu\\), we have \\[\n\\begin{aligned}\n\\Gamma(a) \\times \\Gamma(b) &= \\int_0^{\\infty} \\int_0^{\\infty} t^{a - 1} s^{b - 1} e^{-(t + s)} dtds \\\\\n&= \\int_{u = 0}^{\\infty} \\int_{v = 0}^1 [uv]^{a - 1} [u - uv]^{b - 1} e^{-[u]} [udvdu],\n\\end{aligned}\n\\] which completes our proof.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#the-complete-beta-function",
    "href": "chapters/theory_gamma_function_20250707.html#the-complete-beta-function",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.6 The Complete Beta Function",
    "text": "6.6 The Complete Beta Function\nYou may be thinking, “why did we just do all that changing of variables? We still have two integrals to deal with!” And you aren’t wrong. However, this new double integral can be simplified to yield the Complete Beta Function. Let’s pick back up where we left off, and collect all the like terms together: \\[\n\\begin{aligned}\n\\Gamma(a) \\times \\Gamma(b) &= \\int_{u = 0}^{\\infty} \\int_{v = 0}^1 (uv)^{a - 1} [u(1 - v)]^{b - 1} e^{-u} udvdu \\\\\n&= \\int_{u = 0}^{\\infty} \\int_{v = 0}^1 u^{a - 1} u^{b - 1} u^1 e^{-u} \\times v^{a - 1} (1 - v)^{b - 1} dvdu \\\\\n&= \\int_{u = 0}^{\\infty} u^{a - 1 + b - 1 + 1} e^{-u} du \\times \\int_{v = 0}^1 v^{a - 1} (1 - v)^{b - 1} dv \\\\\n&= \\int_{0}^{\\infty} u^{a + b - 1} e^{-u} du \\times \\int_{0}^1 v^{a - 1} (1 - v)^{b - 1} dv \\\\\n&= \\Gamma(a + b) \\int_{0}^1 v^{a - 1} (1 - v)^{b - 1} dv \\\\\n\\Longrightarrow \\frac{\\Gamma(a) \\times \\Gamma(b)}{\\Gamma(a + b)} &= \\int_{0}^1 v^{a - 1} (1 - v)^{b - 1} dv,\n\\end{aligned}\n\\] which is the definition of the Beta Function.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#alternate-form-of-the-beta-function-over-mathbbr",
    "href": "chapters/theory_gamma_function_20250707.html#alternate-form-of-the-beta-function-over-mathbbr",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.7 Alternate form of the Beta Function over \\(\\mathbb{R}^+\\)",
    "text": "6.7 Alternate form of the Beta Function over \\(\\mathbb{R}^+\\)\nWhile the above form of the Beta Function over \\((0,1)\\) is useful, sometimes we need a variant which we can integrate over the entire positive real line (particularly for the Central \\(F\\) Distribution). We will let \\[\nt = \\frac{1}{1 + s} \\Rightarrow \\frac{dt}{ds} = \\frac{-1}{(1 + s)^2} \\Rightarrow dt = -\\frac{1}{(1 + s)^2}ds.\n\\] Therefore, \\[\ns = \\frac{1}{t} - 1,\\ t \\in (0,1).\n\\]\nFor the bounds of integration, we have that as \\(t\\to 0^+\\), \\(s \\to +\\infty\\).5 Also, as \\(t\\to 1\\), \\(s\\to 0\\). Thus, \\[\n\\begin{aligned}\n\\frac{\\Gamma(a) \\times \\Gamma(b)}{\\Gamma(a + b)} &= \\int_{t = 0}^1 t^{a - 1} (1 - t)^{b - 1} dt \\\\\n&= \\int_{\\infty}^{s = 0} \\left[ \\frac{1}{1 + s} \\right]^{a - 1} \\left[ 1 - \\frac{1}{1 + s} \\right]^{b - 1} \\left[ -\\frac{1}{(1 + s)^2}ds \\right] \\\\\n&= (-1) \\int_{s = 0}^{\\infty} \\frac{1}{(1 + s)^{a - 1}} \\frac{1}{(1 + s)^2} \\left[ \\frac{1 + s}{1 + s} - \\frac{1}{1 + s} \\right]^{b - 1} (-1) ds \\\\\n&= \\int_{s = 0}^{\\infty} \\frac{1}{(1 + s)^{a + 1}} \\left[ \\frac{s}{1 + s} \\right]^{b - 1} ds \\\\\n&= \\int_{s = 0}^{\\infty} \\frac{1}{(1 + s)^{a + 1}} \\frac{s^{b - 1}}{(1 + s)^{b - 1}} ds \\\\\n&= \\int_{s = 0}^{\\infty} \\frac{s^{b - 1}}{(1 + s)^{a + b}} ds.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#the-gamma-continued-recurrence-equation",
    "href": "chapters/theory_gamma_function_20250707.html#the-gamma-continued-recurrence-equation",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "6.8 The Gamma Continued Recurrence Equation",
    "text": "6.8 The Gamma Continued Recurrence Equation\nIf we have the Gamma function of a sum, where one summand is an integer, then we can factor the Gamma function into a product of the integer part and the Gamma function of the non-integer part. This is an extension of the Gamma recurrence relationship (which we will prove below) that \\(\\Gamma(z + 1) = z\\Gamma(z)\\). That is, for \\(a\\in\\mathbb{R}^+\\) and \\(k\\in\\mathbb{N}\\) \\[\n\\Gamma(a + k) = \\Gamma(a)\\prod_{j = 0}^{k - 1} (a + j).\n\\]\nProof: If \\(a\\) is an integer, then the result follows directly from the definition of the factorial. \\[\n\\begin{aligned}\n\\Gamma(a+k) &\\equiv (a+k-1)! \\\\\n&= (a+k-1)(a+k-2)\\ldots(a+k-[k-1])(a+k-k)(a-1)! \\\\\n&= \\left\\{ (a+[k - 1])(a+[k - 2])\\ldots(a+[1])(a+[0]) \\right\\} \\times (a - 1)! \\\\\n&= \\left\\{ \\prod_{j = 0}^{k - 1} (a+j) \\right\\} \\times (a - 1)! \\\\\n&= \\Gamma(a) \\left\\{ \\prod_{j = 0}^{k - 1} (a+j) \\right\\}.\n\\end{aligned}\n\\] If \\(a\\in\\mathbb{R}^+\\) but not an integer, then the factorial operator is not defined. But, we assumed that \\(k\\in\\mathbb{N}\\), so we can assume that \\(k\\) is fixed at some arbitrary positive integer and use a general “Proof by Induction” strategy.\nFor the base case, let’s set up integration by parts and let \\(k = 1\\). Recall that integration by parts decomposes the integral of a product as \\(\\int udv = uv - \\int vdu\\). For the integral below, let \\(u = t^{a} \\Rightarrow du = (a)t^{a - 1}dt\\). We have the remaining portion as \\(e^{-t}dt = dv\\Rightarrow v = -e^{-t}\\). Thus, \\[\n\\begin{aligned}\n\\Gamma(a+1) &= \\int_0^{\\infty} t^{(a+1)-1}e^{-t}dt \\\\\n&= \\lim_{\\psi\\to\\infty} \\left[ t^a \\right] \\left[ -e^{-t} \\right]_0^{\\psi} - \\int_0^{\\infty} \\left[ -e^{-t} \\right] \\left[ at^{a - 1}dt \\right] \\\\\n&= \\left[ \\lim_{\\psi\\to\\infty} \\left(-[\\psi]^a e^{-[\\psi]}\\right) - \\left(-[0]^a e^{-[0]}\\right) \\right] + a \\int_0^{\\infty} t^{a - 1}e^{-t}dt \\\\\n&= \\left[ \\lim_{\\psi\\to\\infty} -\\frac{\\psi^a}{e^{\\psi}}  - 0 \\right] + a\\Gamma(a) \\\\\n&= a\\Gamma(a) - \\lim_{\\psi\\to\\infty} \\frac{\\psi^a}{e^{\\psi}}.\n\\end{aligned}\n\\] Now, recall L’Hospital’s Rule. We see that we are very close to showing the result for \\(k = 1\\). We see that \\(\\psi^a/e^{\\psi}\\) is an indeterminant form; even more interesting, the first derivative of the top divided by the first derivative of the bottom also yields an indeterminant form: \\((a\\psi^{a-1})/e^{\\psi}\\). In fact, this ratio will be in indeterminant form for the first \\(a\\) derivatives of \\(\\psi^a\\). However, taking repeated derivatives of this polynomial will eventially yield a constant. On the other hand, taking repeated derivatives of \\(e^{\\psi}\\) yields \\(e^{\\psi}\\). We see that \\[\n\\begin{aligned}\n\\Gamma(a+1) &= a\\Gamma(a) - \\lim_{\\psi\\to\\infty} \\frac{\\psi^a}{e^{\\psi}} \\\\\n&= a\\Gamma(a) - \\lim_{\\psi\\to\\infty} \\frac{ \\frac{d^a}{d\\psi^a} \\psi^a }{ \\frac{d^a}{d\\psi^a} e^{\\psi} } \\\\\n&= a\\Gamma(a) - \\lim_{\\psi\\to\\infty} \\frac{ a! }{ e^{\\psi} } \\\\\n&= a\\Gamma(a) - \\frac{ a! }{ \\lim_{\\psi\\to\\infty} e^{\\psi} } \\\\\n&= a\\Gamma(a) - 0.\n\\end{aligned}\n\\] Therefore, this limit converges to 0. So, for the base case that \\(k = 1\\), \\(\\Gamma(a+1) = (a+1-1)\\Gamma(a+1-1) = a\\Gamma(a)\\). Thus, we have shown the Gamma Recurrence relationship (as we promised).\nThe hypothesis is that \\(\\Gamma(a+k) = (a+k-1)\\Gamma(a+k-1)\\). Now we move to the induction. Similar to before, we let \\(u = t^{a+k} \\Rightarrow du = (a+k)t^{a + k - 1}dt\\). We have the remaining portion as \\(e^{-t}dt = dv\\Rightarrow v = -e^{-t}\\). Thus, \\[\n\\begin{aligned}\n\\Gamma(a+k+1) &= \\int_0^{\\infty} t^{(a+k+1)-1}e^{-t}dt \\\\\n&= \\lim_{\\psi\\to\\infty} \\left[ t^{a+k} \\right] \\left[ -e^{-t} \\right]_0^{\\psi} - \\int_0^{\\infty} \\left[ -e^{-t} \\right] \\left[ (a+k)t^{a + k - 1}dt \\right] \\\\\n&= \\left[ \\lim_{\\psi\\to\\infty} \\left(-[\\psi]^{a+k} e^{-[\\psi]}\\right) - \\left(-[0]^{a+k} e^{-[0]}\\right) \\right] + (a+k) \\int_0^{\\infty} t^{a + k - 1}e^{-t}dt \\\\\n&= \\left[ \\lim_{\\psi\\to\\infty} -\\frac{\\psi^{a+k}}{e^{\\psi}}  - 0 \\right] + (a+k) \\Gamma(a+k) \\\\\n&= (a+k) \\Gamma(a+k) - \\lim_{\\psi\\to\\infty} \\frac{\\psi^{a+k}}{e^{\\psi}} \\\\\n&= (a+k) \\Gamma(a+k),\n\\end{aligned}\n\\] which completes the induction step. Now, we recursively apply the hypothesis and induction until we reach the base case: \\[\n\\begin{aligned}\n\\Gamma(a+k) &= (a+k-1) \\Gamma(a+k-1) \\\\\n&= (a+k-1)(a+k-2)\\Gamma(a+k-2) \\\\\n&\\ \\ \\vdots \\\\\n&= \\left\\{ (a+[k - 1])(a+[k - 2])\\ldots(a+[1])(a+[0]) \\right\\} \\Gamma(a) \\\\\n&= \\left\\{ \\prod_{j = 0}^{k - 1} (a+j) \\right\\} \\Gamma(a) \\\\\n&= \\Gamma(a) \\left\\{ \\prod_{j = 0}^{k - 1} (a+j) \\right\\},\n\\end{aligned}\n\\] which completes our proof.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/theory_gamma_function_20250707.html#footnotes",
    "href": "chapters/theory_gamma_function_20250707.html#footnotes",
    "title": "6  Formal Foundations: The Gamma and Beta Functions",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Indeterminate_form↩︎\nhttps://www.math.ucdavis.edu/~kouba/CalcTwoDIRECTORY/usubdirectory/USubstitution.html↩︎\nhttps://en.wikipedia.org/wiki/Matrix_(mathematics)↩︎\nhttps://en.wikipedia.org/wiki/Determinant↩︎\n\\(t\\to 0^+\\) means “as \\(t\\) approaches 0 from the right” (the positive side)↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formal Foundations: The Gamma and Beta Functions</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html",
    "href": "chapters/gamma_20250310.html",
    "title": "7  The Gamma Distribution",
    "section": "",
    "text": "7.1 Overview\nWhen we derived the Exponential Distribution, we started with a Poisson process with rate \\(\\lambda\\) and time interval length \\(t\\), and we asked “how long will we have to wait until we see the first patient?” The Erlang Distribution1 extends this to the total waiting time until patient number \\(\\alpha\\in\\mathbb{N}\\) arrives, and the Gamma Distribution2 generalizes this to any \\(\\alpha\\in\\mathbb{R}\\), removing the restriction that \\(\\alpha\\) need be an integer. For this lesson, I’m following Clay Ford’s process3 to derive these distributions, but I’m deviating a bit where I think I can add some clarity. We will derive the Erlang Distribution first (because it follows a similar process to deriving the Exponential Distribution), then we will extend our derivation to the Gamma Distribution.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#formal-foundations",
    "href": "chapters/gamma_20250310.html#formal-foundations",
    "title": "7  The Gamma Distribution",
    "section": "7.2 Formal Foundations",
    "text": "7.2 Formal Foundations\n\n7.2.1 Leibniz’ Integral Rule\nLet \\(F(x)\\) be a differentiable function over an interval \\(x\\in[a,b] \\subset \\mathbb{R}\\) and let \\(f(x)\\) denote this derivative of \\(F\\). We know the First and Second Fundamental Theorems of Calculus4 state that \\[\n\\begin{aligned}\n(1)\\qquad &\\frac{d}{dx} \\int f(x)dx = \\frac{d}{dx} F(x) = f(x) \\\\\n(2)\\qquad &\\int_a^b f(x)dx = F(b) - F(a).\n\\end{aligned}\n\\] Leibniz’ Integral Rule5 extends these theorems to allow more flexible bounds of integration and combines these results with the Chain Rule. Let \\(a(x)\\) and \\(b(x)\\) be finite-valued, differentiable functions. Then, for a differentiable function \\(F(t)\\) with derivative \\(f(t)\\), \\[\n\\frac{d}{dx} \\left[ \\int_{a(x)}^{b(x)} f(t)dt \\right] = f(b(x))\\frac{d}{dx}b(x) - f(a(x))\\frac{d}{dx}a(x).\n\\]\nProof: We assume that \\(F\\), \\(f\\), \\(a\\), and \\(b\\) are all nice functions that have the properties described above. Then, this result is shown by a straightforward application of the First and Second Fundamental Theorems and then the Chain Rule: \\[\n\\begin{aligned}\n\\frac{d}{dx} \\left[ \\int_{a(x)}^{b(x)} f(t)dt \\right] &= \\frac{d}{dx} \\Biggl [ F(b(x)) - F(a(x)) \\Biggr ] \\\\\n&= f(b(x))\\frac{d}{dx}b(x) - f(a(x))\\frac{d}{dx}a(x),\n\\end{aligned}\n\\] which completes our proof.\n\n\n7.2.2 Integrating like a Statistician\nTo be honest, this “formal foundations” subsection is my favourite of all that I’ve included in this book. The idea is really simple: when you are integrating/summing a function over a fixed boundary (a definite integral6) or over a region that extends towards infinity (an improper unbounded integral7), then be on the lookout for the kernel8 of a statistical distribution. Because you know that distributions must integrate/sum to 1 over their entire support, you can often cancel out very complicated integral pieces if you can use algebra to turn them into the kernel of a distribution.\nLet’s have an example. Consider this integral: \\[\n\\int_{-\\infty}^0 e^{3x-2}dx.\n\\] We could integrate this with the traditional \\(u\\)-substitution and improper limits procedures, or we could “look for the hidden distribution”. First, we want to flip the bounds of integration, replacing all \\(x\\) with \\(-x\\), so \\[\n\\int_{-\\infty}^0 e^{3x-2}dx = \\int_0^{\\infty} e^{3[-x]-2}dx = \\int_0^{\\infty} e^{-3x-2}dx.\n\\] Now this integral has the same support (\\(\\mathbb{R}^+\\)) as quite a few statistical distributions, including the Weibull, Gamma, Rayleigh, Exponential, and \\(\\chi^2\\) distributions. The integrand \\(e^{-3x-2}\\) looks similar to the probability function of the Exponential Distribution, so let’s try to use algebra to turn it into something that looks like \\(\\lambda e^{-\\lambda t}\\). We need to get rid of the \\(-2\\) in the exponent first: \\[\n\\int_0^{\\infty} e^{-3x-2}dx = \\int_0^{\\infty} e^{-3x}e^{-2}dx = \\frac{1}{e^2} \\int_0^{\\infty} e^{-3x}dx.\n\\] This looks like the kernel of an Exponential Distribution with parameter \\(\\lambda = 3\\). That’s good news, so \\[\n\\frac{1}{e^2} \\int_0^{\\infty} e^{-3x}dx = \\frac{3}{3e^2} \\int_0^{\\infty} e^{-3x}dx = \\frac{1}{3e^2} \\int_0^{\\infty} 3e^{-3x}dx.\n\\] Finally, we remember that the integral of a probability function over its entire support is equal to 1, so \\[\n\\frac{1}{3e^2} \\int_0^{\\infty} 3e^{-3x}dx = \\frac{1}{3e^2} (1) = \\frac{1}{3e^2}.\n\\] Therefore, \\[\n\\int_{-\\infty}^0 e^{3x-2}dx = \\frac{1}{3e^2}.\n\\]\nNow, for this example, you might say “that seemed like a really complex way to solve a simple problem.” And you’d be right. However, many integrals we encounter are far more challenging than this one, and learning to be on the lookout for kernels to appear in integrals is a prudent thing to do. For more examples, see this online homework page.9",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#deriving-the-distribution-the-erlang-distribution",
    "href": "chapters/gamma_20250310.html#deriving-the-distribution-the-erlang-distribution",
    "title": "7  The Gamma Distribution",
    "section": "7.3 Deriving the Distribution: The Erlang Distribution",
    "text": "7.3 Deriving the Distribution: The Erlang Distribution\nAs we mentioned above, we have a Poisson process with rate \\(\\lambda\\) and time interval length \\(t\\), such as the number of patients visiting a clinic each hour. Now, assume that we have already observed \\(\\alpha - 1\\) independent events (visits in this case). What would be the waiting time between event \\(\\alpha - 1\\) and event \\(\\alpha\\)? Let \\(T\\) be the time that event number \\(\\alpha\\) takes place, and let \\(t\\) be the random variable. Then, because we’ve already observed \\(\\alpha - 1\\) events so far, the probability that we observe \\(\\alpha\\) total events before time \\(t\\) is the compliment to the probability that we observe event number \\(\\alpha\\) after time \\(t\\), which is the same as 1 minus the probability that we observed all \\(\\alpha - 1\\) events before time \\(t\\) in this Poisson process.\nI know that’s a lot, but let’s walk through these statements symbolically: \\[\n\\begin{aligned}\nF(t) &= \\mathbb{P}[T \\le t] \\\\\n&= 1 - \\mathbb{P}[T &gt; t] &(1)\\ \\\\\n&= 1 - F_{\\text{Pois}}(k = \\alpha - 1|\\lambda, t) &(2),\n\\end{aligned}\n\\] where \\(F_{\\text{Pois}}\\) is the cumulative probability function of the Poisson Distribution with rate \\(\\lambda\\) and time interval \\(t\\). We move from equation (1) to (2) because the probability that the time of event number \\(\\alpha\\) (that is, \\(T\\)) happens later (after \\(t\\)), is the same as the probability that all but one of the events have already happened (the count of events \\(k\\) so far, up to and including \\(t\\), equals \\(\\alpha - 1\\)).\nThen, as long as we can write down what \\(F_{\\text{Pois}}\\) is, we get the Gamma (technically Erlang) Distribution, right? Easy enough… \\[\n\\begin{aligned}\nF(t|\\alpha, \\lambda) &= 1 - F_{\\text{Pois}}(k = \\alpha - 1|\\lambda, t) \\\\\n&= 1 - \\int_{\\mathcal{S}(k)} dF_{\\text{Pois}}(k = \\alpha - 1|\\lambda, t) \\\\\n&= 1 - \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t} \\\\\n\\Longrightarrow f(t|\\alpha, \\lambda) &= \\frac{\\partial}{\\partial t} \\left[ 1 - \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t} \\right] \\\\\n&= -\\frac{\\partial}{\\partial t} \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} e^{-\\lambda t},\n\\end{aligned}\n\\] which looks exactly like the Gamma Distribution we know and love! Just kidding, this looks awful.\nWe have the probability function as the derivative of a summation, but we don’t have it in a form that’s easy to use or recognise. Recalling that both differentiation and summation are linear operators10, we can then swap the order of the two as needed. Let’s begin by first using the Product Rule, and then rearrange the difference of summations so that they almost entirely cancel: \\[\n\\begin{aligned}\nf(t|\\alpha,\\lambda) &= -\\frac{\\partial}{\\partial t} e^{-\\lambda t} \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\\\\n&\\qquad \\text{\\emph{Product Rule}}\\ \\ldots \\\\\n&= -\\left\\{ \\left[ \\frac{\\partial}{\\partial t} e^{-\\lambda t} \\right] \\left[ \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\right] +  e^{-\\lambda t} \\frac{\\partial}{\\partial t} \\left[ \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\right] \\right\\}\\\\\n&= -\\left\\{ \\left[ -\\lambda e^{-\\lambda t} \\right] \\left[ \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\right] +  e^{-\\lambda t} \\frac{\\partial}{\\partial t} \\left[ \\frac{(\\lambda t)^0}{0!} + \\sum_{k = 1}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\right] \\right\\}\\\\\n&= e^{-\\lambda t} \\left\\{\\left[ \\sum_{k = 0}^{\\alpha - 1} \\frac{\\lambda^{k+1} t^k}{k!} \\right] - \\frac{\\partial}{\\partial t} \\left[ 1 + \\sum_{k = 1}^{\\alpha - 1} \\frac{\\lambda^k}{k!}t^k \\right] \\right\\}\\\\\n&\\qquad \\text{\\emph{Differentiation is linear}}\\ \\ldots \\\\\n&= e^{-\\lambda t} \\left\\{ \\left[ \\frac{\\lambda^{\\alpha} t^{\\alpha - 1}}{(\\alpha - 1)!} + \\sum_{k = 0}^{\\alpha - 2} \\frac{\\lambda^{k+1} t^k}{k!} \\right] - \\left[ 0 + \\sum_{k = 1}^{\\alpha - 1} \\frac{\\lambda^k}{k!} \\frac{\\partial}{\\partial t} t^k \\right] \\right\\}\\\\\n&\\qquad \\text{\\emph{Let}}\\ k + 1 = j\\ \\ldots \\\\\n&= e^{-\\lambda t} \\left\\{ \\frac{\\lambda^{\\alpha} t^{\\alpha - 1}}{(\\alpha - 1)!} + \\left[ \\sum_{j = 1}^{\\alpha - 1} \\frac{\\lambda^j t^{j - 1}}{(j - 1)!} \\right] - \\left[ \\sum_{k = 1}^{\\alpha - 1} \\frac{\\lambda^k}{k!} kt^{k-1} \\right] \\right\\} \\\\\n&= e^{-\\lambda t} \\left\\{ \\frac{\\lambda^{\\alpha} t^{\\alpha - 1}}{(\\alpha - 1)!} + \\left[ \\sum_{j = 1}^{\\alpha - 1} \\frac{\\lambda^j t^{j - 1}}{(j - 1)!} \\right] - \\left[ \\sum_{k = 1}^{\\alpha - 1} \\frac{\\lambda^k t^{k-1}}{(k - 1)!} \\right] \\right\\} \\\\\n&= e^{-\\lambda t} \\left\\{ \\frac{\\lambda^{\\alpha} t^{\\alpha - 1}}{(\\alpha - 1)!} + 0 \\right\\} \\\\\n&= \\frac{\\lambda^{\\alpha}}{(\\alpha - 1)!} t^{\\alpha - 1} e^{-\\lambda t},\n\\end{aligned}\n\\] which is the probability function of the Erlang Distribution over \\(t\\in\\mathbb{R}^+\\) with parameters \\(\\lambda\\in\\mathbb{R}^+\\) and \\(\\alpha\\in\\mathbb{N}\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#deriving-the-distribution-the-gamma-distribution",
    "href": "chapters/gamma_20250310.html#deriving-the-distribution-the-gamma-distribution",
    "title": "7  The Gamma Distribution",
    "section": "7.4 Deriving the Distribution: The Gamma Distribution",
    "text": "7.4 Deriving the Distribution: The Gamma Distribution\nTo generalize the Erlang Distribution to allow for \\(\\alpha\\in\\mathbb{R}^+\\) requires more sophisticated integrals than I have been able to understand. I will give a less rigorous approach, but at some point in the following derivation I’m going to simply “wave my hands and perform magic”. Let’s start back with the Cumulative Probability Function, and then apply the Lower Incomplete Gamma Function (which we presented in the lesson on Gamma and Beta Functions): \\[\n\\begin{aligned}\nF(t|\\alpha,\\lambda) &= 1 - \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} e^{\\lambda t} \\\\\n&= \\frac{\\Gamma(\\alpha)}{\\Gamma(\\alpha)} \\left[ 1 - e^{\\lambda t} \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\right] \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\left( \\Gamma(\\alpha) \\left[ 1 - e^{\\lambda t} \\sum_{k = 0}^{\\alpha - 1} \\frac{(\\lambda t)^k}{k!} \\right] \\right) \\\\\n&\\qquad\\text{\\emph{Defn. of Lower Incomplete Gamma Function}} \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\Biggl( \\gamma(\\alpha, x = \\lambda t) \\Biggr) \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\left( \\int_0^{\\lambda t} s^{\\alpha - 1} e^{-s} ds \\right).\n\\end{aligned}\n\\] While we started with the restriction on the cumulative probability function that \\(\\alpha\\in\\mathbb{N}\\), after applying the lower incomplete Gamma function, that restriction is no longer necessary. We can now “wave our hands” and allow \\(\\alpha\\in\\mathbb{R}^+\\).\nFurthermore, what we have above is the cumulative probability function, \\(F\\). We want the probability function, which is the first derivative of \\(F\\). So, we need to use Leibniz’ Integral Rule (that we showed above) to simplify the derivative of this integral, specifically because the variable of differentiation is in the bounds of the integral. Hence, \\[\n\\begin{aligned}\nF(t|\\alpha,\\lambda) &= \\frac{1}{\\Gamma(\\alpha)} \\left( \\int_0^{\\lambda t} s^{\\alpha - 1} e^{-s} ds \\right) \\\\\n\\Longrightarrow f(t|\\alpha,\\lambda) &= \\frac{\\partial}{\\partial t} \\frac{1}{\\Gamma(\\alpha)} \\int_0^{\\lambda t} s^{\\alpha - 1} e^{-s} ds \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\left[ [\\lambda t]^{\\alpha - 1} e^{-[\\lambda t]} \\frac{\\partial}{\\partial t} (\\lambda t) - [0]^{\\alpha - 1} e^{-[0]} \\frac{\\partial}{\\partial t} (0) \\right] \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\left[ (\\lambda t)^{\\alpha - 1} e^{-\\lambda t} (\\lambda) - 0 \\right] \\\\\n&= \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t^{\\alpha - 1} e^{-\\lambda t},\n\\end{aligned}\n\\] which is our more familiar form of the Gamma Distribution.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#example-random-samples",
    "href": "chapters/gamma_20250310.html#example-random-samples",
    "title": "7  The Gamma Distribution",
    "section": "7.5 Example Random Samples",
    "text": "7.5 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxSymm &lt;- rgamma(n = 500, shape = 10, scale = 1)\nsamplesSymm_ls &lt;- list(\n  n5   = xSymm[1:5],\n  n30  = xSymm[1:30],\n  n60  = xSymm[1:60],\n  n500 = xSymm\n)\n\nxSkew &lt;- rgamma(n = 500, shape = 0.9, scale = 3)\nsamplesSkew_ls &lt;- list(\n  n5   = xSkew[1:5],\n  n30  = xSkew[1:30],\n  n60  = xSkew[1:60],\n  n500 = xSkew\n)\n\nrange_num &lt;- range(c(xSymm, xSkew))\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSymm_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSkew_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/gamma_20250310.html#show-that-this-is-a-distribution",
    "title": "7  The Gamma Distribution",
    "section": "7.6 Show that this is a Distribution",
    "text": "7.6 Show that this is a Distribution\nUp to this point, we have devoted an entire chapter to understanding the Gamma and Beta Functions. Then, we did all the work above to derive the distribution, first for \\(\\alpha\\in\\mathbb{N}\\), and then subsequently for \\(\\alpha\\in\\mathbb{R}^+\\). After all this setup, confirming that this is a distribution is comparatively trivial. First, consider the probability function of the Gamma Distribution, \\[\nf_{\\Gamma}(t|\\alpha,\\lambda) = \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t^{\\alpha - 1} e^{-\\lambda t},\n\\] for \\(\\alpha,\\lambda,t\\in\\mathbb{R}^+\\). We can see that these individual components are all non-negative, so \\(f \\ge 0\\).\nNow we will show that the total probability is 1. Because we derived the probability function from the cumulative probability function, we don’t need to integrate \\(f\\). Instead, we can simply take the limit of \\(F\\) as \\(t\\to\\infty\\). We note that if the upper bound of the lower incomplete Gamma function is \\(\\infty\\), then it’s no longer the incomplete Gamma function, but the Gamma function itself. Thus, \\[\n\\begin{aligned}\n\\lim_{t\\to\\infty} F_{\\Gamma}(t|\\alpha,\\lambda) &= \\lim_{t\\to\\infty} \\frac{1}{\\Gamma(\\alpha)} \\left( \\int_0^{\\lambda t} s^{\\alpha - 1} e^{-s} ds \\right) \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\left( \\int_0^{\\infty} s^{\\alpha - 1} e^{-s} ds \\right) \\\\\n&= \\frac{1}{\\Gamma(\\alpha)} \\Biggl( \\Gamma(\\alpha) \\Biggr) \\\\\n&= 1.\n\\end{aligned}\n\\] Ergo, the Gamma Distribution is a true distribution.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/gamma_20250310.html#derive-the-moment-generating-function",
    "title": "7  The Gamma Distribution",
    "section": "7.7 Derive the Moment Generating Function",
    "text": "7.7 Derive the Moment Generating Function\nWe will start with the traditional approach, but we will recognize that the process will include integrating the probability function of the Gamma Distribution over its entire support. This involves integrating like a statistician, which we describe above. Let’s begin, using \\(s\\) for the nuisance parameter of the MGF: \\[\n\\begin{aligned}\nM_t(s) &= \\int_{\\mathcal{S}(t)} e^{ts} dF_{\\Gamma}(t|\\alpha,\\lambda) \\\\\n&= \\int_0^{\\infty} e^{ts} \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t^{\\alpha - 1} e^{-\\lambda t} dt \\\\\n&= \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\int_0^{\\infty} t^{\\alpha - 1} e^{ts - \\lambda t} dt \\\\\n&= \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\int_0^{\\infty} t^{\\alpha - 1} e^{-t(\\lambda - s)} dt,\\qquad \\lambda &gt; s \\\\\n&\\qquad\\text{\\emph{Gamma Distribution Kernel}...} \\\\\n&= \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\left[\\frac{\\Gamma(\\alpha)}{(\\lambda - s)^{\\alpha}}\\right] \\int_0^{\\infty} \\left[\\frac{(\\lambda - s)^{\\alpha}}{\\Gamma(\\alpha)}\\right] t^{\\alpha - 1} e^{-t(\\lambda - s)} dt \\\\\n&\\qquad\\text{\\emph{Integrates to 1}...} \\\\\n&= \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\left[\\frac{\\Gamma(\\alpha)}{(\\lambda - s)^{\\alpha}}\\right] (1) \\\\\n&= \\frac{\\lambda^{\\alpha}}{1} \\frac{1}{(\\lambda - s)^{\\alpha}} \\\\\n&= \\left( \\frac{\\lambda}{\\lambda - s} \\right)^{\\alpha}.\n\\end{aligned}\n\\] Honestly, this form of the MGF is just fine, but we have to take derivatives with respect to \\(s\\). So, many texts will take the algebra a step further: \\[\nM_t(s) = \\left( \\frac{\\lambda}{\\lambda - s} \\right)^{\\alpha} = \\left( \\frac{\\lambda - s}{\\lambda} \\right)^{-\\alpha} = \\left( 1 - \\frac{s}{\\lambda} \\right)^{-\\alpha}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/gamma_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "7  The Gamma Distribution",
    "section": "7.8 Method of Moments Estimates from Observed Data",
    "text": "7.8 Method of Moments Estimates from Observed Data\nLet’s generate some random data. We continue our “clinic” example, but this time we want to know how long it will take us to have 3 patients within one hour. Our motivation could be as follows: we only have three nurses working in the clinic, and so we want to know how long we have to wait before all three nurses have a patient to see. We generate 7 “waiting times” until the third patient walks in. For a single experiment, that is, when we first open the clinic, how long will we have to wait for the third patient to arrive? Let’s assume the same rate of \\(\\lambda = 5\\) for one hour (just like we used in the Exponential and Poisson lessons), and we are waiting for event \\(\\alpha = 3\\). We can generate data (in fractional hours) by\n\n\nCode\nset.seed(20150516)\n\nnTrials_int &lt;- 7L\nrate_num &lt;- 5\nsuccessCount_num &lt;- 3\nGammat_num &lt;- rgamma(n = nTrials_int, shape = successCount_num, rate = rate_num)\nGammat_num\n[1] 0.906 0.542 0.402 0.909 0.779 0.725 1.427\nGammat_num * 60\n[1] 54.3 32.5 24.1 54.5 46.7 43.5 85.6\n\n\nSo, for these 7 independent trials where the waiting times \\(T\\) have an identical Gamma distribution with rate of 5 patients per hour, we wait 54.3, 32.5, 24.1, 54.5, 46.7, 43.5, 85.6 minutes to see the third patient.\n\n7.8.1 \\(\\mathbb{E}[t]\\)\nConsider \\[\n\\begin{aligned}\nM_t(s) &= \\left( 1 - \\frac{s}{\\lambda} \\right)^{-\\alpha} \\\\\n\\Longrightarrow M^{\\prime}_t(s) &= \\frac{\\partial}{\\partial s} \\left( 1 - \\frac{s}{\\lambda} \\right)^{-\\alpha} \\\\\n&= -\\alpha \\left( 1 - \\frac{s}{\\lambda} \\right)^{-\\alpha - 1} \\left(-\\frac{1}{\\lambda}\\right) \\\\\n&= \\frac{\\alpha}{\\lambda} \\left( 1 - \\frac{s}{\\lambda} \\right)^{-(\\alpha + 1)} \\\\\n\\Longrightarrow M^{\\prime}_t(0) &= \\frac{\\alpha}{\\lambda} \\left( 1 - \\frac{[0]}{\\lambda} \\right)^{-(\\alpha + 1)} \\\\\n&= \\frac{\\alpha}{\\lambda} \\\\\n&= \\mathbb{E}[t].\n\\end{aligned}\n\\]\n\n\n7.8.2 \\(\\mathbb{E}[t^2]\\) and \\(\\text{Var}[t]\\)\nSimilarly, \\[\n\\begin{aligned}\nM^{\\prime}_t(s) &= \\frac{\\alpha}{\\lambda} \\left( 1 - \\frac{s}{\\lambda} \\right)^{-(\\alpha + 1)} \\\\\n\\Longrightarrow M^{\\prime\\prime}_t(s) &= \\frac{\\partial}{\\partial s} \\frac{\\alpha}{\\lambda} \\left( 1 - \\frac{s}{\\lambda} \\right)^{-(\\alpha + 1)} \\\\\n&= \\frac{\\alpha}{\\lambda} [-(\\alpha + 1)] \\left( 1 - \\frac{s}{\\lambda} \\right)^{-(\\alpha + 2)} \\left(-\\frac{1}{\\lambda}\\right) \\\\\n&= \\frac{\\alpha(\\alpha + 1)}{\\lambda^2} \\left( 1 - \\frac{s}{\\lambda} \\right)^{-(\\alpha + 2)} \\\\\n\\Longrightarrow M^{\\prime\\prime}_t(0) &= \\frac{\\alpha(\\alpha + 1)}{\\lambda^2} \\left( 1 - \\frac{[0]}{\\lambda} \\right)^{-(\\alpha + 2)} \\\\\n&= \\frac{\\alpha(\\alpha + 1)}{\\lambda^2} \\\\\n&= \\mathbb{E}[t^2].\n\\end{aligned}\n\\]\nThus, \\[\n\\begin{aligned}\n\\text{Var}[t] &= \\mathbb{E}[t^2] - \\left[ \\mathbb{E}[t] \\right]^2 \\\\\n&= \\frac{\\alpha(\\alpha + 1)}{\\lambda^2} - \\left[ \\frac{\\alpha}{\\lambda} \\right]^2 \\\\\n&= \\frac{\\alpha(\\alpha + 1) - \\alpha^2}{\\lambda^2} \\\\\n&= \\frac{\\alpha^2 + \\alpha - \\alpha^2}{\\lambda^2} \\\\\n&= \\frac{\\alpha}{\\lambda^2}.\n\\end{aligned}\n\\]\n\n\n7.8.3 Solving the System\nBased on the sample we saw above, \\(\\bar{x}\\) = 0.813 and \\(s^2\\) = 0.108. We then solve the following system: \\[\n\\begin{aligned}\n(1)&\\qquad \\bar{x} = \\frac{\\alpha}{\\lambda} \\Rightarrow \\alpha = \\bar{x}\\lambda, \\\\\n(2)&\\qquad s^2 = \\frac{\\alpha}{\\lambda^2} \\Rightarrow \\alpha = s^2\\lambda^2.\n\\end{aligned}\n\\] So, \\[\n\\bar{x}\\lambda = s^2\\lambda^2 \\Rightarrow \\bar{x} = s^2\\lambda \\Rightarrow \\hat{\\lambda}_{MoM} = \\frac{\\bar{x}}{s^2}.\n\\] Substituting this back into Equation (1), we have \\[\n\\hat{\\alpha}_{MoM} = \\bar{x}\\left[\\frac{\\bar{x}}{s^2}\\right] = \\frac{\\bar{x}^2}{s^2}.\n\\] We calculate these from the data we “observed”:\n\n\nCode\n(lambdaHat_MoM &lt;- mean(Gammat_num) / var(Gammat_num))\n[1] 7.55\n(alphaHat_MoM &lt;- mean(Gammat_num)^2 / var(Gammat_num))\n[1] 6.14\n\n\nThus, our Method of Moments estimates are \\(\\hat{\\lambda}_{MoM}\\) = 7.551 and \\(\\hat{\\alpha}_{MoM}\\) = 6.136, while the true values were \\(\\lambda = 5\\) and \\(\\alpha = 3\\). In my simulations, the Method of Moments estimates didn’t get “good” until I had over 70 samples.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/gamma_20250310.html#maximum-likelihood-estimators",
    "title": "7  The Gamma Distribution",
    "section": "7.9 Maximum Likelihood Estimators",
    "text": "7.9 Maximum Likelihood Estimators\nAssume that we have observed a sample of waiting times \\(\\textbf{t} = (t_1, t_2, \\ldots, t_n)\\) which were generated from a Gamma waiting process.\n\n7.9.1 The Log-Likelihood Function\nThen, \\[\n\\begin{aligned}\n\\mathcal{L}(\\alpha,\\lambda|\\textbf{t}) &= \\prod_{i = 1}^n \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t_i^{\\alpha - 1} e^{-\\lambda t_i} \\\\\n\\Longrightarrow \\ell(\\alpha,\\lambda|\\textbf{t}) &= \\log \\left[ \\prod_{i = 1}^n \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t_i^{\\alpha - 1} e^{-\\lambda t_i} \\right] \\\\\n&= \\sum_{i = 1}^n \\log \\left[ \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} t_i^{\\alpha - 1} e^{-\\lambda t_i} \\right] \\\\\n&= \\sum_{i = 1}^n \\left[ \\alpha\\log(\\lambda) - \\log(\\Gamma(\\alpha)) + (\\alpha - 1)\\log(t_i) - \\lambda t_i \\right] \\\\\n&= n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1) \\sum_{i = 1}^n \\log(t_i) - \\lambda \\sum_{i = 1}^n t_i \\\\\n&= n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1) \\sum_{i = 1}^n \\log(t_i) - n\\lambda\\bar{t},\n\\end{aligned}\n\\] which we then have to take partial derivatives of with respect to both \\(\\lambda\\) and \\(\\alpha\\).\n\n\n7.9.2 MLE for \\(\\lambda\\)\nThe (much) simpler case is when we know how many “events”, \\(\\alpha\\), the observers were waiting for when they recorded \\(\\textbf{t}\\). If \\(\\alpha\\) is known, then \\[\n\\begin{aligned}\n\\ell(\\alpha,\\lambda|\\textbf{t}) &= n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1) \\sum_{i = 1}^n \\log(t_i) - n\\lambda\\bar{t} \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\lambda} \\ell(\\alpha,\\lambda|\\textbf{t}) &= \\frac{\\partial}{\\partial\\lambda} \\left[ n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1) \\sum_{i = 1}^n \\log(t_i) - n\\lambda\\bar{t} \\right] \\\\\n&= \\frac{n\\alpha}{\\lambda} - 0 + 0 - n\\bar{t} \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{n\\alpha}{\\hat{\\lambda}} - n\\bar{t} \\\\\n\\Longrightarrow n\\bar{t} &= \\frac{n\\alpha}{\\hat{\\lambda}} \\\\\n\\Longrightarrow \\bar{t} &= \\frac{\\alpha}{\\hat{\\lambda}} \\\\\n\\Longrightarrow \\hat{\\lambda} &= \\frac{\\alpha}{\\bar{t}}.\n\\end{aligned}\n\\] Moreover, we see quickly that the second derivative with respect to \\(\\lambda\\) is \\(-n\\alpha\\lambda^{-2} &lt; 0\\), so \\(\\hat{\\lambda}\\) maximizes the likelihood. If we knew that the observers who collected the data were recording waiting times until they had observed three successes, then we can estimate the rate: \\(\\hat{\\lambda}_{MLE}\\) = 3.691.\n\n\n7.9.3 MLE for \\(\\alpha\\)\nIf \\(\\alpha\\) is unknown, we start with the same log-likelikelihood as above, but quickly run out of “algebra” to do: \\[\n\\begin{aligned}\n\\ell(\\alpha,\\lambda|\\textbf{t}) &= n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1) \\sum_{i = 1}^n \\log(t_i) - n\\lambda\\bar{t} \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\alpha} \\ell(\\alpha,\\lambda|\\textbf{t}) &= \\frac{\\partial}{\\partial\\alpha} \\left[ n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1) \\sum_{i = 1}^n \\log(t_i) - n\\lambda\\bar{t} \\right] \\\\\n&= n\\log(\\lambda) - n \\frac{\\partial}{\\partial\\alpha} \\log(\\Gamma(\\alpha)) + \\sum_{i = 1}^n \\log(t_i) \\\\\n&= n\\log(\\lambda) - n \\frac{\\partial}{\\partial\\alpha} \\log(\\Gamma(\\alpha)) + n\\overline{\\log(t)},\n\\end{aligned}\n\\] where \\(\\overline{\\log(t)}\\) denotes the average of the natural logarithms of the observed times (it’s still a fixed quantity).\n\n7.9.3.1 Regular Solution\nWhen we set this equal to 0, we have two “routes” to estimate a solution for this problem. The first option uses the derivative of the natural logarithm of the Gamma Function, known as the Digamma Function11, and symbolized \\(\\varphi(\\alpha)\\). Then, \\[\n\\begin{aligned}\n0 &\\overset{\\text{set}}{=} n\\log(\\lambda) - n \\frac{\\partial}{\\partial\\alpha} \\log(\\Gamma(\\alpha)) + n\\overline{\\log(t)} \\\\\n&= \\log(\\lambda) - \\varphi(\\alpha) + \\overline{\\log(t)} \\\\\n\\Longrightarrow \\varphi(\\alpha) &= \\log(\\lambda) + \\overline{\\log(t)}.\n\\end{aligned}\n\\] This would require numerical routines to estimate a solution for \\(\\hat{\\alpha}\\). Here’s what the Digamma function looks like:\n\n\nCode\nx &lt;- c(0.25, 0.5, 0.75, 1:30)\nplot(\n  x = x,\n  y = digamma(x)\n)\n\n\n\n\n\n\n\n\n\nSo, we have that \\(\\hat{\\lambda} = \\alpha/\\bar{t}\\) and \\(\\varphi(\\hat{\\alpha}) = \\log(\\lambda) + \\overline{\\log(t)}\\). That’s two equations and two unknowns, which we might be able to approximate a solution to.\n\n\n7.9.3.2 Another (Probably Bad) Option\nThe second option is a work in progress, and I’m not sure it’s even viable. I’m including it here to show some of my thought process. We will leave the derivative with respect to \\(\\alpha\\) and work with the resulting differential equation. Thankfully this differential equation is in the form \\(y^{\\prime} = C\\) with respect to \\(\\alpha\\): \\[\n\\begin{aligned}\n0 &\\overset{\\text{set}}{=} n\\log(\\lambda) - n \\frac{\\partial}{\\partial\\alpha} \\log(\\Gamma(\\alpha)) + n\\overline{\\log(t)} \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\alpha} \\log(\\Gamma(\\alpha)) &= \\log(\\lambda) + \\overline{\\log(t)} \\\\\n\\Longrightarrow \\log(\\Gamma(\\alpha)) &= \\alpha\\left( \\log(\\lambda) + \\overline{\\log(t)} \\right) + C.\n\\end{aligned}\n\\] We also need numerical routines to solve this. But the difficult part here is that we know very little about what kind of boundary conditions the Gamma Distribution has. We know that when \\(\\alpha = 1\\), the Gamma Distribution reduces back to the Exponential Distribution, and we know that the MLE for \\(\\lambda\\) in the Exponential Distribution is \\((\\bar{t})^{-1}\\), which we can substitute in to solve for C:12 \\[\n\\begin{aligned}\n\\log(\\Gamma([1])) &= [1]\\left( \\log(\\bar{t}^{-1}) + \\overline{\\log(t)} \\right) + C \\\\\n\\Longrightarrow \\log(1) &= \\log(\\bar{t}^{-1}) + \\overline{\\log(t)} + C \\\\\n\\Longrightarrow 0 &= -\\log(\\bar{t}) + \\overline{\\log(t)} + C \\\\\n\\Longrightarrow C &= \\log(\\bar{t}) - \\overline{\\log(t)}.\n\\end{aligned}\n\\] Therefore, we would use a numerical routine to find \\(\\hat{\\alpha}\\) as the solution to \\[\n\\begin{aligned}\n\\log(\\Gamma(\\alpha)) &= \\alpha\\left( \\log(\\lambda) + \\overline{\\log(t)} \\right) + \\log(\\bar{t}) - \\overline{\\log(t)} \\\\\n&= \\alpha\\left( -\\log(\\bar{t}) + \\overline{\\log(t)} \\right) + \\log(\\bar{t}) - \\overline{\\log(t)} \\\\\n&= -\\alpha\\left( \\log(\\bar{t}) - \\overline{\\log(t)} \\right) + \\log(\\bar{t}) - \\overline{\\log(t)} \\\\\n&= -\\alpha K + K \\\\\n&= K(1 - \\alpha),\n\\end{aligned}\n\\] where \\(K = \\log(\\bar{t}) - \\overline{\\log(t)}\\). Now what does this \\(K\\) look like? For fixed \\(\\alpha\\), we can generate vectors \\(\\textbf{t}\\) with increasing \\(\\lambda\\). Then we can plot the values of \\(\\log(\\bar{t}) - \\overline{\\log(t)}\\) (on a log scale for \\(\\lambda\\)).\n\n\nCode\nset.seed(20150516)\n\nx_df &lt;- purrr::map(\n  .x = c(seq(0.01, 0.99, length.out = 30), 1:30),\n  .f = ~{\n    gammaSamp_num &lt;- rgamma(10000, shape = 5, rate = .x)\n    tibble(\n      lambda = .x,\n      logTbar = log(mean(gammaSamp_num)),\n      barLogT = mean(log(gammaSamp_num))\n    ) %&gt;% \n      mutate(difference = logTbar - barLogT)\n  }\n) %&gt;% \n  bind_rows() \n\nggplot(data = x_df) +\n  aes(x = lambda, y = difference) + \n  scale_x_log10() + \n  geom_hline(yintercept = 0) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nWe can see that \\(\\forall\\lambda\\ K &gt; 0\\).\nFor a discussion of numerical routines related to the MLEs for the Gamma with both parameters unknown, see https://tminka.github.io/papers/minka-gamma.pdf.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#exercises",
    "href": "chapters/gamma_20250310.html#exercises",
    "title": "7  The Gamma Distribution",
    "section": "7.10 Exercises",
    "text": "7.10 Exercises\nThe \\(\\chi^2\\) Distribution is a special case of the Gamma Distribution with \\(\\alpha = \\nu/2\\) and \\(\\lambda = 1/2\\).\n\nUse “integration like a statistician” to show that the \\(\\chi^2_{\\nu}\\) Distribution is a proper distribution.\nShow that the MGF is \\(M_t(s) = (1 - 2s)^{-\\nu/2}\\).\nThink about the \\(\\nu\\) parameter of this distribution. In what cases would \\(\\nu\\) be unknown?\n\nOther exercises to be determined.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/gamma_20250310.html#footnotes",
    "href": "chapters/gamma_20250310.html#footnotes",
    "title": "7  The Gamma Distribution",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Erlang_distribution↩︎\nhttps://en.wikipedia.org/wiki/Gamma_distribution↩︎\nhttps://www.clayford.net/statistics/deriving-the-gamma-distribution/↩︎\nhttps://en.wikipedia.org/wiki/Fundamental_theorem_of_calculus↩︎\nhttps://en.wikipedia.org/wiki/Leibniz_integral_rule↩︎\nhttps://tutorial.math.lamar.edu/classes/calci/defnofdefiniteintegral.aspx↩︎\nhttps://en.wikipedia.org/wiki/Improper_integral↩︎\nhttps://en.wikipedia.org/wiki/Kernel_(statistics)#Bayesian_statistics↩︎\nhttps://www.chegg.com/homework-help/questions-and-answers/722-solve-following-integrals-without-calculus-recognizing-integrand-related-known-probabi-q43101946↩︎\nhttps://en.wikipedia.org/wiki/Operator_(mathematics)#Linear_operators↩︎\nhttps://en.wikipedia.org/wiki/Digamma_function↩︎\nGo back to the MLE section of the Exponential Distribution chapter: https://gabriel.quarto.pub/stat-distributions-primer/chapters/exponential_20250310.html#maximum-likelihood-estimators↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Gamma Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html",
    "href": "chapters/beta_20250310.html",
    "title": "8  The Beta Distribution",
    "section": "",
    "text": "8.1 Formal Foundations",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#formal-foundations",
    "href": "chapters/beta_20250310.html#formal-foundations",
    "title": "8  The Beta Distribution",
    "section": "",
    "text": "8.1.1 Marginalizing a Likelihood\nSo far in our chapters, we have created quite a few likelihood functions. When we introduced likelihoods at the very beginning1, we were careful to state that likelihoods are not probability functions. However, we know two things:\n\nlikelihood functions are always non-negative (recall that the products of any number of non-negative numbers will still be non-negative), and\nfor well-behaved distributions, the area under the likelihood function will be finite (for a single finite data point from any well-behaved distribution, the parameter estimate for that data point will also be finite, and the product of finite values is finite).\n\nBecause the likelihood function is non-negative and the area under this curve is finite, we can turn it into a distribution by a process called finding the marginal likelihood2 and dividing the likelihood function by this marginal likelihood.\nMore formally, consider a probability function \\(f(x|\\boldsymbol{\\theta})\\) with some finite but unknown parameter vector \\(\\boldsymbol{\\theta} \\in\\mathbb{R}_p\\). Further, consider an independent and identical sample, \\(\\textbf{x}\\), of size \\(n\\) from this distribution, represented as \\(x_i \\overset{iid}{\\sim} f(x|\\boldsymbol\\theta),\\ i = 1, 2, \\ldots, n\\). The resulting likelihood is \\[\n\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x}) = \\prod_{i = 1}^n f(x_i|\\boldsymbol\\theta).\n\\] In order to transform \\(\\mathcal{L}\\) into a probability function, we must divide by the integral of \\(\\mathcal{L}\\) over the support3 (all possible values) of \\(\\boldsymbol\\theta\\), where \\(\\mathcal{S}(\\boldsymbol\\theta)\\) represents this support. For some distributions, especially those with a mixture of discrete and continuous parameters4, this support, \\(\\mathcal{S}(\\boldsymbol\\theta)\\), may be quite complex.\nGiven this setup, the marginal likelihood is defined as \\[\nm(\\boldsymbol\\theta|\\textbf{x}) = \\int_{\\mathcal{S}(\\boldsymbol\\theta)} \\mathcal{L}(\\boldsymbol\\theta|\\textbf{x}) \\pi(\\boldsymbol\\theta) d\\boldsymbol\\theta.\n\\] This \\(\\pi(\\boldsymbol\\theta)\\) may come as a surprise, as we haven’t defined what it is. In Bayesian Statistics5, this \\(\\pi(\\boldsymbol\\theta)\\) is known as a prior distribution6. In the context of Bayesian inference, this prior distribution represents all the expert knowledge about the unknown parameter vector \\(\\boldsymbol\\theta\\) that was known before the sample \\(\\textbf{x}\\) was collected. However, for this class, we will make the statement that we don’t know much, if anything, about \\(\\boldsymbol\\theta\\), so we set \\(\\pi(\\boldsymbol\\theta) = 1\\). Then, for our examples, \\[\nm(\\boldsymbol\\theta|\\textbf{x}) = \\int_{\\mathcal{S}(\\boldsymbol\\theta)} \\mathcal{L}(\\boldsymbol\\theta|\\textbf{x}) d\\boldsymbol\\theta.\n\\]\nFinally, in order to transform the likelihood function of \\(\\boldsymbol\\theta\\) into a probability function of \\(\\boldsymbol\\theta\\), we will divide the likelihood by its integral. So, the probability function of \\(\\boldsymbol\\theta\\) given the observed data \\(\\textbf{x}\\) is \\[\nf(\\boldsymbol\\theta|\\textbf{x}) = \\frac{\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x})}{m(\\boldsymbol\\theta|\\textbf{x})} = \\frac{\\mathcal{L}(\\boldsymbol\\theta|\\textbf{x})}{\\int_{\\mathcal{S}(\\boldsymbol\\theta)} \\mathcal{L}(\\boldsymbol\\theta|\\textbf{x}) d\\boldsymbol\\theta}.\n\\] We comment that distributions derived this way are true statistical distributions because they will always be non-negative, and an integral divided by itself equals 1 (so the total probability will be 1 by definition). In practice, this integral may be impossible to solve, so often numerical routines are used to estimate \\(f\\) directly. Such topics are beyond the scope of this course.\n\n\n8.1.2 Fubini’s Theorem\nOne small piece of theory we will need below is to swap the order of integration and summation (which we have done quite loosely up to this point). Basically, if we have two properties: 1) that \\(f \\ge 0\\), and \\(F &lt; \\infty\\), then \\[\n\\int \\sum_n f_n(x) dx = \\sum_n \\int f_n(x) dx.\n\\] This is an extension of Fubini’s Theorem7 which allows us to swap the order of summation and integration, as long as the function \\(f\\) is non-negative and the integral converges. Note that if \\(f\\) is a probability function of a statistical distribution, then we have both properties automatically.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#deriving-the-distribution",
    "href": "chapters/beta_20250310.html#deriving-the-distribution",
    "title": "8  The Beta Distribution",
    "section": "8.2 Deriving the Distribution",
    "text": "8.2 Deriving the Distribution\nWe will begin this process by considering an independent and identical sample \\(\\textbf{x}\\), with size \\(n\\), from an Binomial Distribution (with \\(p\\) unknown); that is \\(x_i \\overset{iid}{\\sim} \\text{Binom}(N, p),\\ i = 1, 2, \\ldots, n\\). Further, we will take a play from the Negative Binomial distribution, and let \\(k_i\\) and \\(r_i\\) denote the number of successes and failures in Binomial sample \\(i\\), respectively. Thus, \\[\n\\begin{align}\n\\mathcal{L}(p|\\textbf{x}) &= \\prod_{i = 1}^n {N \\choose x_i} p^{x_i} (1 - p)^{N - x_i} \\\\\n\\Longrightarrow \\mathcal{L}(p|\\textbf{r},\\textbf{k}) &= \\prod_{i = 1}^n {r_i + k_i \\choose k_i} p^{k_i} (1 - p)^{r_i} \\\\\n&= \\left[ \\prod_{i = 1}^n {r_i + k_i \\choose k_i} \\right] \\times \\left[ \\prod_{i = 1}^n p^{k_i} \\right] \\times \\left[ \\prod_{i = 1}^n (1 - p)^{r_i} \\right] \\\\\n&= \\left[ \\prod_{i = 1}^n {r_i + k_i \\choose k_i} \\right] p^{S_k} (1 - p)^{S_r},\n\\end{align}\n\\] where \\[\nS_k = \\sum_{i = 1}^n k_i,\\ \\text{and}\\ S_r = \\sum_{i = 1}^n r_i.\n\\]\nAs we discussed in our Formal Foundations section, we can marginalize this likelihood to create a probability function \\(f\\), of the parameter \\(p\\), given the sufficient statistics8 of the observed data \\(S_k\\) and \\(S_r\\). That is, \\[\n\\begin{align}\nf(p|S_r, S_k) &= \\frac{\\mathcal{L}(p|\\textbf{r},\\textbf{k})}{m(p|\\textbf{r},\\textbf{k})} \\\\\n&= \\frac{\\mathcal{L}(p|\\textbf{r},\\textbf{k})}{\\int_{\\mathcal{S}(p)} \\mathcal{L}(p|\\textbf{r},\\textbf{k}) dp } \\\\\n&= \\frac{ \\left[ \\prod_{i = 1}^n {r_i + k_i \\choose k_i} \\right] p^{S_k} (1 - p)^{S_r} }{\\int_0^1 \\left[ \\prod_{i = 1}^n {r_i + k_i \\choose k_i} \\right] p^{S_k} (1 - p)^{S_r} dp } \\\\\n&= \\frac{ \\left[ \\prod_{i = 1}^n {r_i + k_i \\choose k_i} \\right] p^{S_k} (1 - p)^{S_r} }{ \\left[ \\prod_{i = 1}^n {r_i + k_i \\choose k_i} \\right] \\int_0^1 p^{S_k} (1 - p)^{S_r} dp } \\\\\n&= \\frac{ p^{S_k} (1 - p)^{S_r} }{ \\int_0^1 p^{S_k} (1 - p)^{S_r} dp } \\\\\n&= \\frac{ p^{(S_k + 1) - 1} (1 - p)^{(S_r + 1) - 1} }{ \\int_0^1 p^{(S_k + 1) - 1} (1 - p)^{(S_r + 1) - 1} dp } \\\\\n&= \\frac{ p^{\\alpha - 1} (1 - p)^{\\beta - 1} }{ \\int_0^1 p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp },\n\\end{align}\n\\] where \\(\\alpha = S_k + 1\\) (1 plus the total number of successes in the \\(n\\) Binomial trials) and \\(\\beta = S_r + 1\\) (1 plus the total number of failures in the \\(n\\) Binomial trials).\nThis integral in the denominator should look familiar: it is the definition of the Complete Beta Function, which we covered in the “Formal Foundations” chapter on the Gamma and Beta functions. Thus, \\[\n\\begin{align}\nf(p|S_r, S_k) &= \\frac{ p^{\\alpha - 1} (1 - p)^{\\beta - 1} }{ \\int_0^1 p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp } \\\\\n&= \\left[ \\int_0^1 p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\right]^{-1} p^{\\alpha - 1} (1 - p)^{\\beta - 1} \\\\\n&= \\left[ \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)} \\right]^{-1} p^{\\alpha - 1} (1 - p)^{\\beta - 1} \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1},\n\\end{align}\n\\] which is the standard form of the Beta Distribution with \\(p\\in(0,1)\\).\nWhat are the allowed values for \\(\\alpha\\) and \\(\\beta\\)? Because we derived the Beta Distribution as the probability function of the Binomial Distribution’s parameter \\(p\\), we had an added restriction that \\(S_k\\) and \\(S_r\\) were non-negative integers (that is, \\(S_k,\\ S_r \\in 0\\cup\\mathbb{N} = 0, 1, 2, 3, \\ldots\\)). This would impose the restriction that \\(\\alpha = S_k + 1\\) and \\(\\beta = S_r + 1\\) must be elements of \\(\\mathbb{N} = 1, 2, 3, \\ldots\\) (not including 0). However, notice that the form of \\(f\\) above uses Gamma functions, so it does not require that \\(\\alpha\\) and \\(\\beta\\) be restricted to the integers. What would it mean to have fractional/decimal counts of successes or failures? Well, some games allow for ties, which could be counted as half a success and half a failure. Other experiments could involve Likert-scale9 responses, where “strongly disagree” maps to 0, “strongly agree” maps to 1, but the values in between map to various fractions between 0 and 1.10 Thus, we state that \\(\\alpha\\) and \\(\\beta\\) simply need to be non-negative real numbers (\\(\\alpha,\\beta\\in\\mathbb{R}^+\\)).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#example-random-samples",
    "href": "chapters/beta_20250310.html#example-random-samples",
    "title": "8  The Beta Distribution",
    "section": "8.3 Example Random Samples",
    "text": "8.3 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxSymm &lt;- rbeta(n = 500, shape1 = 10, shape2 = 10)\nsamplesSymm_ls &lt;- list(\n  n10  = xSymm[1:10],\n  n30  = xSymm[1:30],\n  n60  = xSymm[1:60],\n  n500 = xSymm\n)\n\nxSkew &lt;- rbeta(n = 500, shape1 = 5, shape2 = 1.5)\nsamplesSkew_ls &lt;- list(\n  n10  = xSkew[1:10],\n  n30  = xSkew[1:30],\n  n60  = xSkew[1:60],\n  n500 = xSkew\n)\n\nrange_num &lt;- c(0, 1)\n\nrm(xSymm, xSkew)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSymm_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSymm_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesSkew_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesSkew_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/beta_20250310.html#show-that-this-is-a-distribution",
    "title": "8  The Beta Distribution",
    "section": "8.4 Show that this is a Distribution",
    "text": "8.4 Show that this is a Distribution\nGiven all our work to derive this distribution, we can show that it is a distribution directly. First, note that because \\(p\\in(0,1)\\) and \\(\\alpha,\\beta &gt; 0\\), we have that \\(f(p|\\alpha,\\beta) &gt; 0\\). Then, starting with the Riemann-Stieltjes integral and applying the definition of the Complete Beta Function11 we have \\[\n\\begin{align}\n\\int_{\\mathcal{S}(p)} dF(p|\\alpha,\\beta) &= \\int_0^1 \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\int_0^1 p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\left[ \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)} \\right] \\\\\n&= 1.\n\\end{align}\n\\] Therefore, the Beta Distribution is a proper distribution.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/beta_20250310.html#derive-the-moment-generating-function",
    "title": "8  The Beta Distribution",
    "section": "8.5 Derive the Moment Generating Function",
    "text": "8.5 Derive the Moment Generating Function\nWhen I was in grad school, some of my professors ignored deriving the Moment Generating Function of the Beta Distribution. When you look at its form in the back of a statistical theory textbook, you can probably see why (it’s unpleasant). However, we are going to derive it anyway. Many derivations you might find online involve using the Kummer’s Function of the First Kind12, which requires even more theoretical foundations to cover than I would ever want to write. Instead, we will opt for a longer derivation, but one that uses Formal Foundations that we have already covered, namely the Riemann-Stieljes Integral (that you should be comfortable with by now), the MacLaurin Series13 of \\(e^x\\), swapping the order of integration and summation via Fubini’s Theorem,14 the definition of the Complete Beta Function,15 and the Continued Recurrence Property of the Gamma Function.16\nLet’s begin: \\[\n\\begin{aligned}\nM_p(t) &= \\int_{\\mathcal{S}(p)} e^{tp}dF(p|\\alpha,\\beta) \\\\\n&= \\int_0^1 e^{tp} \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\\\\n&\\qquad\\text{\\emph{MacLaurin Series of }} e^{tp} \\text{\\emph{...}} \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\int_0^1 \\left[ \\sum_{k = 0}^{\\infty} \\frac{(tp)^k}{k!} \\right] p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\int_0^1 \\sum_{k = 0}^{\\infty} \\frac{t^k}{k!} p^k p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\\\\n&\\qquad\\text{\\emph{Fubini's Theorem...}} \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\sum_{k = 0}^{\\infty} \\int_0^1 \\frac{t^k}{k!} p^k p^{\\alpha - 1} (1 - p)^{\\beta - 1} dp \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\sum_{k = 0}^{\\infty} \\frac{t^k}{k!} \\int_0^1 p^{\\alpha + k - 1} (1 - p)^{\\beta - 1} dp \\\\\n&\\qquad\\text{\\emph{Defn. of Beta Function...}} \\\\\n&= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\sum_{k = 0}^{\\infty} \\frac{t^k}{k!} \\left[ \\frac{\\Gamma(\\alpha + k)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta + k)} \\right] \\\\\n&= \\sum_{k = 0}^{\\infty} \\frac{t^k}{k!} \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha + \\beta + k)} \\frac{\\Gamma(\\alpha + k)}{\\Gamma(\\alpha)} \\right] \\\\\n&\\qquad\\text{\\emph{``Peel off'' the first summand...}} \\\\\n&= \\frac{t^0}{0!} \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha + \\beta + 0)} \\frac{\\Gamma(\\alpha + 0)}{\\Gamma(\\alpha)} \\right] + \\sum_{k = 1}^{\\infty} \\frac{t^k}{k!} \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha + \\beta + k)} \\frac{\\Gamma(\\alpha + k)}{\\Gamma(\\alpha)} \\right] \\\\\n&\\qquad\\text{\\emph{Gamma Function Recurrence Property...}} \\\\\n&= 1 + \\sum_{k = 1}^{\\infty} \\frac{t^k}{k!} \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{ \\prod_{j = 0}^{k - 1} (\\alpha + \\beta + j) \\Gamma(\\alpha + \\beta) } \\frac{ \\prod_{j = 0}^{k - 1} (\\alpha + j) \\Gamma(\\alpha) }{\\Gamma(\\alpha)} \\right] \\\\\n&= 1 + \\sum_{k = 1}^{\\infty} \\frac{t^k}{k!} \\left[ \\frac{1}{ \\prod_{j = 0}^{k - 1} (\\alpha + \\beta + j) } \\frac{ \\prod_{j = 0}^{k - 1} (\\alpha + j) }{1} \\right] \\\\\n&= 1 + \\sum_{k = 1}^{\\infty} \\frac{t^k}{k!} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right],\n\\end{aligned}\n\\] which is the standard form of the Beta Distribution’s MGF. We “peeled off” the first summand (incrementing from \\(k = 0\\) to \\(k = 1\\)) to make taking the first derivative easier. When we are ready to take the second derivative, we will “peel off” the second summand (incrementing from \\(k = 1\\) to \\(k = 2\\)) then.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/beta_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "8  The Beta Distribution",
    "section": "8.6 Method of Moments Estimates from Observed Data",
    "text": "8.6 Method of Moments Estimates from Observed Data\n\n8.6.1 Effect of \\(\\alpha\\) and \\(\\beta\\) on Sampled Probabilities\nFollowing our Binomial example with probability of success \\(p_0 = 0.35\\), let’s create a probability distribution from which this \\(p_0\\) is the most likely value. For the Beta Distribution, the formula for the mode17 is known, so we set it equal to 0.35, and we will have a frontier18 where one unknown variable can be written as a function of another: \\[\n\\begin{aligned}\n0.35 &= \\frac{\\alpha - 1}{\\alpha + \\beta - 2} \\\\\n\\Longrightarrow 0.35\\alpha + 0.35\\beta - 0.7 &= \\alpha - 1 \\\\\n\\Longrightarrow 0.35\\beta &= 0.65\\alpha - 0.3 \\\\\n\\Longrightarrow \\beta(\\alpha) = \\frac{13}{7}\\alpha + \\frac{6}{7}.\n\\end{aligned}\n\\] Notice that if we pick a value for one parameter of the Beta Distribution, while holding the mode constant, then the other value is determined.\nLet’s pick a range of values for \\(\\alpha\\), calculate the corresponding values of \\(\\beta\\), and then look at the distribution of values as \\(\\alpha\\) and \\(\\beta\\) increase.\n\n\nCode\nalpha_num &lt;- 2^seq(from = 0, to = 6, length.out = 6)\nbeta_num &lt;- (13/7) * alpha_num + (6/7)\n\nset.seed(20150516)\n\npar(mfrow = c(3, 2))\nfor (i in seq_along(alpha_num)) {\n  hist(\n    x = rbeta(n = 10000, shape1 = alpha_num[i], beta_num[i]),\n    xlim = c(0, 1),\n    main = paste0(\n      \"alpha = \", round(alpha_num[i], 2),\n      \"; beta = \", round(beta_num[i], 2)\n    ),\n    xlab = NULL\n  )\n  abline(v = 0.35, col = \"red\", lwd = 2)\n}\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(1,1))\n\n\nNotice that for small values of \\(\\alpha\\), the mode of the distribution is not the desired 0.35. However, as \\(\\alpha\\) grows larger, the mode both gets closer to 0.35 and the distribution gets tighter around the desired value of 0.35.\nThe intuition for this goes back to the motivating derivation of the Beta Distribution. The parameters \\(\\alpha\\) and \\(\\beta\\) represent the total number of successes and failures, respectfully, in repeated independent Binomial experiments. The more total successes and failures we’ve observed, the more information we have about the true value of \\(p\\). Therefore, the distribution must shrink and become more narrow around the intended value of \\(p_0 = 0.35\\). In practice, larger parameters of the Beta Distribution represent more prior information known about the probability of success, \\(p\\).\n\n\n8.6.2 A “Random Sample” of Probabilities\nLet’s generate some random data. Before we do this, we should think critically about this exercise. When, if ever, is it truly possible to “observe” a probability? We can observe successes and failures, but in the health science context, I can’t think of any case where we could actually take a random sample of probabilities themselves. However, this somewhat nonsensical step is necessary to move forward with our examples for the Method of Moments estimators and also to describe the forms of the solutions to the MLE exercises. So, we will press onward.\nWe will assume that we already know that in prior independent Binomial experiments, we observed a total of 64 successes and 120 failures. Let’s assume that we somehow “observed” \\(n = 12\\) probabilities from a Beta distribution with \\(\\alpha =  64 + 1\\) and \\(\\beta = 120 + 1\\). This would yield a theoretical mode value of \\((65 - 1)/(65 + 121 - 2) \\approx 0.348\\). We can sample these values as shown below:\n\n\nCode\nset.seed(20150516)\nalphaParam_int &lt;- 65\nbetaParam_int &lt;- 121\n(p_num &lt;- rbeta(n = 12, shape1 = alphaParam_int, shape2 = betaParam_int))\n [1] 0.396 0.355 0.337 0.341 0.290 0.334 0.344 0.376 0.365 0.345 0.299 0.324\n\n\nThus, the 12 “observed” probabilities are 0.396, 0.355, 0.337, 0.341, 0.29, 0.334, 0.344, 0.376, 0.365, 0.345, 0.299, 0.324.\n\n\n8.6.3 \\(\\mathbb{E}[p]\\)\nLet’s get to work: \\[\n\\begin{aligned}\nM_p(t) &= 1 + \\sum_{k = 1}^{\\infty} \\frac{t^k}{k!} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\\\\n\\Longrightarrow M^{\\prime}_p(t) &= 0 + \\frac{\\partial}{\\partial t} \\sum_{k = 1}^{\\infty} \\frac{t^k}{k!} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\\\\n&= \\sum_{k = 1}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{\\partial}{\\partial t} \\frac{t^k}{k!} \\\\\n&= \\sum_{k = 1}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{kt^{k - 1}}{k!} \\\\\n&= \\sum_{k = 1}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 1}}{(k - 1)!} \\\\\n&\\qquad\\text{\\emph{``Peel off''}}\\ k = 1\\ldots \\\\\n&= \\left\\{ \\left[ \\prod_{j = 0}^{[1] - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{[1] - 1}}{([1] - 1)!} \\right\\} + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 1}}{(k - 1)!} \\\\\n&= \\left\\{ \\left[ \\frac{\\alpha + 0}{\\alpha + \\beta + 0} \\right] \\frac{t^0}{0!} \\right\\} + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 1}}{(k - 1)!} \\\\\n&= \\frac{\\alpha}{\\alpha + \\beta} + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 1}}{(k - 1)!} \\\\\n\\Longrightarrow M^{\\prime}_p(0) &= \\frac{\\alpha}{\\alpha + \\beta} + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{[0]^{k - 1}}{(k - 1)!} \\\\\n&= \\frac{\\alpha}{\\alpha + \\beta} + 0 \\\\\n&= \\mathbb{E}[p].\n\\end{aligned}\n\\]\n\n\n8.6.4 \\(\\mathbb{E}[p^2]\\) and \\(\\text{Var}[p]\\)\nSimilarly, \\[\n\\begin{aligned}\nM^{\\prime}_p(t) &= \\frac{\\alpha}{\\alpha + \\beta} + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 1}}{(k - 1)!} \\\\\n\\Longrightarrow M^{\\prime\\prime}_p(t) &= \\frac{\\partial}{\\partial t} \\left\\{ \\frac{\\alpha}{\\alpha + \\beta} + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 1}}{(k - 1)!} \\right\\} \\\\\n&= 0 + \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{\\partial}{\\partial t} \\frac{t^{k - 1}}{(k - 1)!} \\\\\n&= \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{(k - 1)t^{k - 2}}{(k - 1)!} \\\\\n&= \\sum_{k = 2}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 2}}{(k - 2)!} \\\\\n&\\qquad\\text{\\emph{``Peel off''}}\\ k = 2\\ldots \\\\\n&= \\left\\{ \\left[ \\prod_{j = 0}^{[2] - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{[2] - 2}}{([2] - 2)!} \\right\\} + \\sum_{k = 3}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 2}}{(k - 2)!} \\\\\n&= \\left\\{ \\left[ \\prod_{j = 0}^1 \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^0}{0!} \\right\\} + \\sum_{k = 3}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 2}}{(k - 2)!} \\\\\n&= \\left\\{ \\left[ \\frac{\\alpha + 0}{\\alpha + \\beta + 0} \\times \\frac{\\alpha + 1}{\\alpha + \\beta + 1} \\right] [1] \\right\\} + \\sum_{k = 3}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 2}}{(k - 2)!} \\\\\n&= \\left[ \\frac{\\alpha}{\\alpha + \\beta} \\frac{\\alpha + 1}{\\alpha + \\beta + 1} \\right] + \\sum_{k = 3}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{t^{k - 2}}{(k - 2)!} \\\\\n\\Longrightarrow M^{\\prime\\prime}_p(0) &= \\left[ \\frac{\\alpha}{\\alpha + \\beta} \\frac{\\alpha + 1}{\\alpha + \\beta + 1} \\right] + \\sum_{k = 3}^{\\infty} \\left[ \\prod_{j = 0}^{k - 1} \\frac{\\alpha + j}{\\alpha + \\beta + j} \\right] \\frac{[0]^{k - 2}}{(k - 2)!} \\\\\n&= \\left[ \\frac{\\alpha}{\\alpha + \\beta} \\frac{\\alpha + 1}{\\alpha + \\beta + 1} \\right] + 0 \\\\\n&= \\mathbb{E}[p^2].\n\\end{aligned}\n\\]\nThus, \\[\n\\begin{aligned}\n\\text{Var}[p] &= \\mathbb{E}[p^2] - \\left[\\mathbb{E}[p]\\right]^2 \\\\\n&= \\left[ \\frac{\\alpha}{\\alpha + \\beta} \\frac{\\alpha + 1}{\\alpha + \\beta + 1} \\right] - \\left[ \\frac{\\alpha}{\\alpha + \\beta} \\right]^2 \\\\\n&= \\frac{\\alpha(\\alpha + 1)}{(\\alpha + \\beta)(\\alpha + \\beta + 1)}\\frac{(\\alpha + \\beta)}{(\\alpha + \\beta)} - \\frac{\\alpha^2}{(\\alpha + \\beta)^2}\\frac{(\\alpha + \\beta + 1)}{(\\alpha + \\beta + 1)} \\\\\n&= \\frac{\\alpha(\\alpha + 1)(\\alpha + \\beta) - \\alpha^2(\\alpha + \\beta + 1)}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)} \\\\\n&= \\frac{\\alpha(\\alpha^2 + \\alpha\\beta + \\alpha + \\beta) - (\\alpha^3 + \\alpha^2\\beta + \\alpha^2)}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)} \\\\\n&= \\frac{(\\alpha^3 + \\alpha^2\\beta + \\alpha^2) + \\alpha\\beta - (\\alpha^3 + \\alpha^2\\beta + \\alpha^2)}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)} \\\\\n&= \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)} \\\\\n\\end{aligned}\n\\]\n\n\n8.6.5 Solving the System\nAfter these derivations, we have the following system of equations: \\[\n\\bar{p} = \\frac{\\alpha}{\\alpha + \\beta};\\ s^2 = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}.\n\\] Let’s solve the first equation for \\(\\beta\\), since it only appears once: \\[\n\\begin{aligned}\n\\bar{p} &= \\frac{\\alpha}{\\alpha + \\beta} \\\\\n\\Longrightarrow \\alpha\\bar{p} + \\beta\\bar{p} &= \\alpha \\\\\n\\Longrightarrow \\beta\\bar{p} &= \\alpha - \\alpha\\bar{p} \\\\\n\\Longrightarrow \\beta &= \\frac{\\alpha}{\\bar{p}} - \\alpha.\n\\end{aligned}\n\\]\nWe will now substitute this value for \\(\\beta\\), which depends on the known value of \\(\\bar{p}\\) and the unknown value of \\(\\alpha\\), into the second equation: \\[\n\\begin{aligned}\ns^2 &= \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)} \\\\\n&= \\frac{\\alpha\\left[ \\frac{\\alpha}{\\bar{p}} - \\alpha \\right]}{\\left(\\alpha + \\left[ \\frac{\\alpha}{\\bar{p}} - \\alpha \\right]\\right)^2 \\left(\\alpha + \\left[ \\frac{\\alpha}{\\bar{p}} - \\alpha \\right] + 1\\right)} \\\\\n&= \\frac{ \\alpha^2\\left[ \\frac{1}{\\bar{p}} - 1 \\right] }{\\left( \\frac{\\alpha}{\\bar{p}} \\right)^2 \\left( \\frac{\\alpha}{\\bar{p}} + 1 \\right)} \\\\\n&= \\frac{ \\alpha^2\\left[ \\frac{1}{\\bar{p}} - 1 \\right] }{ \\alpha^2 \\left( \\frac{\\alpha}{\\bar{p}^3} + \\frac{1}{\\bar{p}^2} \\right)} \\times \\frac{\\bar{p}^3}{\\bar{p}^3} \\\\\n&= \\frac{ \\left[ 1 - \\bar{p} \\right] \\bar{p}^2 }{ \\frac{\\alpha\\bar{p}^3}{\\bar{p}^3} + \\frac{\\bar{p}^3}{\\bar{p}^2} } \\\\\n&= \\frac{ (1 - \\bar{p})\\bar{p}^2 }{\\alpha + \\bar{p}} \\\\\n\\Longrightarrow s^2(\\alpha + \\bar{p}) &= (1 - \\bar{p})\\bar{p}^2 \\\\\n\\Longrightarrow s^2\\alpha &= (1 - \\bar{p})\\bar{p}^2 - s^2\\bar{p} \\\\\n\\Longrightarrow \\hat{\\alpha} &= (1 - \\bar{p})\\frac{\\bar{p}^2}{s^2} - \\bar{p}.\n\\end{aligned}\n\\]\nFinally, we can substitute this estimate for \\(\\alpha\\), which is entirely in terms of the known quantities \\(\\bar{p}\\) and \\(s^2\\), back into the first equation that we solved for \\(\\beta\\). Thus, \\[\n\\begin{aligned}\n\\beta &= \\frac{\\alpha}{\\bar{p}} - \\alpha \\\\\n&= \\left[ \\alpha \\right]\\left[ \\frac{1}{\\bar{p}} - 1 \\right] \\\\\n\\Longrightarrow \\hat{\\beta} &= \\left[ (1 - \\bar{p})\\frac{\\bar{p}^2}{s^2} - \\bar{p} \\right] \\left[ \\frac{1}{\\bar{p}} - 1 \\right].\n\\end{aligned}\n\\]\nNow that we have these two equations in terms of the known quantities, we can find the Method of Moments estimates for \\(\\alpha\\) and \\(\\beta\\) given the \\(n = 12\\) “observed” data points:\n\n\nCode\npBar &lt;- mean(p_num)\npS2 &lt;- var(p_num)\n\n(alphaHat_MoM &lt;- (1 - pBar)*(pBar^2 / pS2) - pBar^2)\n[1] 86.7\n(betaHat_MoM &lt;- alphaHat_MoM * (1 / pBar - 1))\n[1] 167\n\n\nSo, while the true parameter values used to generate this sample of \\(n = 12\\) probabilities were \\(\\alpha\\) = 65 and \\(\\beta\\) = 121, our Method of Moments estimates are \\(\\hat{\\alpha}\\) = 86.7 and \\(\\hat{\\beta}\\) = 166.7.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/beta_20250310.html#maximum-likelihood-estimators",
    "title": "8  The Beta Distribution",
    "section": "8.7 Maximum Likelihood Estimators",
    "text": "8.7 Maximum Likelihood Estimators\nWe have similar qualms here as in the Method of Moments section, in that it’s a strange thing to think about “observing” probabilities. However, we can still work through some of the MLE steps for the Beta Distribution. Let \\(\\textbf{p} = p_1, p_2, \\ldots, p_n\\) be an independent and identical sample from a Beta Distribution with unknown parameters \\(\\alpha\\) and \\(\\beta\\). We start with the Likelihood function: \\[\n\\begin{aligned}\n\\mathcal{L}(\\alpha, \\beta|\\textbf{p}) &= \\prod_{i = n}^n \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p_i^{\\alpha - 1} (1 - p_i)^{\\beta - 1} \\\\\n\\Longrightarrow \\ell(\\alpha, \\beta|\\textbf{p}) &= \\sum_{i = 1}^n \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p_i^{\\alpha - 1} (1 - p_i)^{\\beta - 1} \\right] \\\\\n&= \\sum_{i = 1}^n \\left\\{ \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\right] + \\log \\left[ p_i^{\\alpha - 1} \\right] + \\log \\left[ (1 - p_i)^{\\beta - 1} \\right] \\right\\} \\\\\n&= n\\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\right] + (\\alpha - 1) \\sum_{i = 1}^n \\log(p_i) + (\\beta - 1)\\sum_{i = 1}^n \\log(1 - p_i).\n\\end{aligned}\n\\]\nWe immediately see two problems:\n\nWe are taking the partial derivatives with respect to \\(\\alpha\\) and \\(\\beta\\), which are inside of Gamma functions, so we will not have a closed-form solution regardless.\nThe \\(\\Gamma(\\alpha + \\beta)\\) term is a single Gamma function with both \\(\\alpha\\) and \\(\\beta\\) inside, so any partial derivatives with respect to one variable will still contain the other variable. These parameters cannot be estimated independently.\n\nThe partial derivative with respect to \\(\\alpha\\) is found by: \\[\n\\begin{aligned}\n\\ell(\\alpha, \\beta|\\textbf{p}) &= n\\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\right] + (\\alpha - 1) \\sum_{i = 1}^n \\log(p_i) + (\\beta - 1)\\sum_{i = 1}^n \\log(1 - p_i) \\\\\n&= n\\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)} \\right] - n\\log \\left[ \\Gamma(\\beta) \\right] + (\\alpha - 1) \\sum_{i = 1}^n \\log(p_i) + (\\beta - 1)\\sum_{i = 1}^n \\log(1 - p_i) \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial \\alpha} \\ell(\\alpha, \\beta|\\textbf{p}) &= n \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)} \\right] - [0] + \\sum_{i = 1}^n \\log(p_i) + [0] \\\\\n&= n \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)} \\right] + n\\overline{\\log(p)} \\\\\n0 &\\overset{\\text{set}}{=} n \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)} \\right] + n\\overline{\\log(p)} \\\\\n\\Longrightarrow -\\overline{\\log(p)} &= \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)} \\right].\n\\end{aligned}\n\\] We can’t get much further than this analytically. If either \\(\\alpha\\) or \\(beta\\) are known to be an integer (for instance, if we know that these parameters truly represent integer counts of successes and failures in prior studies), then we can employ the Continued Recurrence Property of the Gamma Function as follows (but it doesn’t make the problem much easier): \\[\n\\begin{aligned}\n-\\overline{\\log(p)} &= \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)} \\right] \\\\\n&= \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\frac{\\Gamma(\\alpha) \\prod_{j = 0}^{\\beta - 1} (\\alpha + j)}{\\Gamma(\\alpha)} \\right] \\\\\n&= \\frac{\\partial}{\\partial \\alpha} \\log \\left[ \\prod_{j = 0}^{\\beta - 1} (\\alpha + j) \\right] \\\\\n&= \\frac{\\partial}{\\partial \\alpha} \\sum_{j = 0}^{\\beta - 1} \\log (\\alpha + j) \\\\\n&= \\sum_{j = 0}^{\\beta - 1} \\frac{\\partial}{\\partial \\alpha} \\log (\\alpha + j) \\\\\n&= \\sum_{j = 0}^{\\beta - 1} \\frac{1}{\\alpha + j} \\\\\n&= \\frac{1}{\\alpha} + \\frac{1}{\\alpha + 1} + \\ldots + \\frac{1}{\\alpha + \\beta - 1}.\n\\end{aligned}\n\\] Now, this may look easier to work with (and it is easier computationally, because this is a smooth, positive, decreasing function for \\(\\alpha &gt; 0\\)), but notice that the unknown parameter \\(\\beta\\) is now in the support of the computation for \\(\\alpha\\). So, we are still in a situation where we need to estimate one parameter first in order to approximate a value for the second. If we have a guess for \\(\\beta\\) then this becomes a manageable coding problem to estimate \\(\\alpha\\). Also, note that because \\(p\\in(0,1)\\), \\(-\\overline{\\log(p)} \\in (0,\\infty)\\), so there will be a solution to the problem.\nThe partial derivative with respect to \\(\\beta\\) is almost identical, so I will skip some of the same steps we saw above: \\[\n\\begin{aligned}\n\\ell(\\alpha, \\beta|\\textbf{p}) &= n\\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\right] + (\\alpha - 1) \\sum_{i = 1}^n \\log(p_i) + (\\beta - 1)\\sum_{i = 1}^n \\log(1 - p_i) \\\\\n&= n\\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)} \\right] - n\\log \\left[ \\Gamma(\\alpha) \\right] + (\\alpha - 1) \\sum_{i = 1}^n \\log(p_i) + (\\beta - 1)\\sum_{i = 1}^n \\log(1 - p_i) \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial \\beta} \\ell(\\alpha, \\beta|\\textbf{p}) &= n \\frac{\\partial}{\\partial \\beta} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)} \\right] - [0] + [0] + \\sum_{i = 1}^n \\log(1 - p_i) \\\\\n&= n \\frac{\\partial}{\\partial \\beta} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)} \\right] + n\\overline{\\log(1 - p)} \\\\\n0 &\\overset{\\text{set}}{=} n \\frac{\\partial}{\\partial \\beta} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)} \\right] + n\\overline{\\log(1 - p)} \\\\\n\\Longrightarrow -\\overline{\\log(1 - p)} &= \\frac{\\partial}{\\partial \\beta} \\log \\left[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\beta)} \\right] \\\\\n&\\qquad\\text{\\emph{Assuming one parameter can be an integer...}} \\\\\n&= \\frac{\\partial}{\\partial \\beta} \\log \\left[ \\frac{\\Gamma(\\beta) \\prod_{j = 0}^{\\alpha - 1} (\\beta + j)}{\\Gamma(\\beta)} \\right] \\\\\n&= \\frac{\\partial}{\\partial \\beta} \\sum_{j = 0}^{\\alpha - 1} \\log (\\beta + j) \\\\\n&= \\sum_{j = 0}^{\\alpha - 1} \\frac{1}{\\beta + j}.\n\\end{aligned}\n\\]\nWe now have a system of two equations and two unknowns (assuming that we can limit \\(\\alpha\\) and \\(\\beta\\) to the integers—if we cannot, then we have to use the Digamma functions19). That system is: \\[\n-\\overline{\\log(p)} = \\sum_{j = 0}^{\\beta - 1} \\frac{1}{\\alpha + j};\\quad -\\overline{\\log(1 - p)} = \\sum_{j = 0}^{\\alpha - 1} \\frac{1}{\\beta + j}.\n\\] Theoretically, we could solve this numerically. Often, we would use the Method of Moments estimates as the initial values for \\(\\alpha\\) and \\(\\beta\\).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#exercises",
    "href": "chapters/beta_20250310.html#exercises",
    "title": "8  The Beta Distribution",
    "section": "8.8 Exercises",
    "text": "8.8 Exercises\n\n8.8.1 The Uniform Distribution\nThe Continuous Uniform Distribution over \\((0,1)\\) is a special case of the Beta Distribution with \\(\\alpha = 1\\) and \\(\\beta = 1\\).\n\nShow that the Uniform Distribution is a proper distribution.\nShow that the MGF is \\(M_p(t) = \\frac{1}{t}(e^t - 1)\\).\nFind \\(\\mathbb{E}[p]\\) and \\(\\text{Var}[p]\\).\n\n\n\n8.8.2 Computational Solution to the MLEs\nTry to write some code that will estimate \\(\\alpha\\) and \\(\\beta\\) from a vector of known “observed” probabilities, \\(\\textbf{p}\\).\nOther exercises to be determined.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/beta_20250310.html#footnotes",
    "href": "chapters/beta_20250310.html#footnotes",
    "title": "8  The Beta Distribution",
    "section": "",
    "text": "https://gabriel.quarto.pub/stat-distributions-primer/chapters/bernoulli_20250310.html#the-likelihood-function↩︎\nhttps://en.wikipedia.org/wiki/Marginal_likelihood↩︎\nhttps://en.wikipedia.org/wiki/Support_(mathematics)#Support_of_a_distribution↩︎\nFor example, the Negative Binomial distribution has parameter vector \\(\\langle n,p \\rangle\\) when \\(n\\) is unknown, where \\(p\\in (0,1)\\) and \\(n\\in\\mathbb{N}\\).↩︎\nhttps://en.wikipedia.org/wiki/Bayesian_statistics↩︎\nhttps://en.wikipedia.org/wiki/Prior_probability↩︎\nhttps://en.wikipedia.org/wiki/Fubini%27s_theorem↩︎\nhttps://en.wikipedia.org/wiki/Sufficient_statistic↩︎\nhttps://en.wikipedia.org/wiki/Likert_scale↩︎\nSee this discussion for more details: https://math.stackexchange.com/questions/4244890/intuition-of-beta-distribution-with-less-than-one-parameters↩︎\nCovered in our Formal Foundations chapter on the Gamma and Beta functions↩︎\nhttps://mathworld.wolfram.com/ConfluentHypergeometricFunctionoftheFirstKind.html↩︎\nhttps://gabriel.quarto.pub/stat-distributions-primer/chapters/negative_binomial_20250310.html#taylormaclaurin-series↩︎\nhttps://en.wikipedia.org/wiki/Fubini%27s_theorem↩︎\nhttps://gabriel.quarto.pub/stat-distributions-primer/chapters/theory_gamma_function_20250707.html#the-complete-beta-function↩︎\nhttps://gabriel.quarto.pub/stat-distributions-primer/chapters/theory_gamma_function_20250707.html#the-gamma-continued-recurrence-equation↩︎\nFor continuous distributions, the mode is the most likely value.↩︎\nA constrained set of possible values, inspired by the concept of a production frontier in economics. See https://en.wikipedia.org/wiki/Production%E2%80%93possibility_frontier↩︎\nhttps://en.wikipedia.org/wiki/Digamma_function↩︎",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html",
    "href": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html",
    "title": "9  Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test",
    "section": "",
    "text": "9.1 Overview\nTo prepare for the derivation of the Normal Distribution, we need a refresher on derivatives of trigonometric functions (and a few identities of trigonometric functions as well.) Also, for the maximum likelihood estimators that we’ve seen so far, the likelihood functions were either 1) univariate (having only one unknown parameter), like the Binomial or Exponential Distributions, or 2) bivariate (having two unknown parameters), but were so complicated that no closed form solution for the MLEs existed. However, for the Normal Distribution, we will have a bivariate likelihood (with both \\(\\mu\\) and \\(\\sigma^2\\) unknown), but we will be able get a closed-form system of two equations for these two unknowns which can be solved analytically. This means that we need a version of the Second Derivative Test that works for bivariate functions; this is called the Saddlepoint Test.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test</span>"
    ]
  },
  {
    "objectID": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#trigonometric-functions-and-the-unit-circle",
    "href": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#trigonometric-functions-and-the-unit-circle",
    "title": "9  Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test",
    "section": "9.2 Trigonometric Functions and the Unit Circle",
    "text": "9.2 Trigonometric Functions and the Unit Circle\n\n9.2.1 The Unit Circle\nThis is the Unit Circle, and it is crucial for our understanding of basic trigonometric functions.1 The radius of the unit circle is 1, and we mostly use it to create right triangles2 where the hypotenuse3 is the radius of the circle.\n\n\n\n9.2.2 Sines and Cosines\nLet’s draw a triangle within this unit circle (image from this high school maths website).\n\nWe now have a right triangle from the origin to the edge of the unit circle. The sine function takes in the angle, often symbolized by \\(\\theta\\), and returns the height of this triangle. Technically speaking, the sine function returns the ratio of the height of the triangle to its hypotenuse, but the hypotenuse of these triangles will be the radius of the unit circle, i.e. 1. The cosine function takes in this same angle and returns the width of this triangle. Because of this relationship, we often describe the unit circle relationship on the \\(\\langle x, y \\rangle\\) plane with \\(x = \\cos(\\theta)\\) and \\(y = \\sin(\\theta)\\). Also, applying the standard algebraic formula for a circle, we arrive at the most famous trigonometric identity4: \\[\n\\begin{aligned}\nr^2 &= x^2 + y^2 \\\\\n\\Longrightarrow 1 &= x^2 + y^2 \\\\\n\\Longrightarrow 1 &= \\cos^2(\\theta) + \\sin^2(\\theta).\n\\end{aligned}\n\\]\n\nThe common mnemonic device to remember this is “SOH-CAH-TOA” (pronounced “sow kuh towuh” in American English):\n\nSine: Opposite side (height) divided by Hypotenuse\nCosine: Adjacent side (width) divided by Hypotenuse\nTangent: Opposite side (height) divided by Adjacent side (width)\n\n\nLet’s calculate these values in R. Unfortunately, the trigonometric functions do not allow for input in degrees, so we must convert from degrees to radians.5 The formulae to convert between degrees and radians (and back) are \\[\n\\text{Rad} = \\text{Degrees}\\times\\frac{\\pi}{180};\\ \\ \\text{Degrees} = \\text{Rad}\\times\\frac{180}{\\pi}.\n\\]\nLet’s use the R sin() and cos() functions to confirm that a \\(30^{\\circ}\\) triangle has a height of 0.5 and a width of \\(\\frac{1}{2}\\sqrt{3}\\):\n\n\nCode\nrads30_num &lt;- 30 * pi / 180\nsin(rads30_num)\n[1] 0.5\ncos(rads30_num)\n[1] 0.866\nsqrt(3)/2\n[1] 0.866\n\n\nOne other important piece of information to know about these two functions is their graph over all \\(360^{\\circ}\\) of a circle. Here is the sine:\n\n\nCode\ndegrees_int &lt;- 1:360\nrads_num &lt;- degrees_int * pi / 180\nplot(\n  x = degrees_int, y = sin(rads_num),\n  main = \"The Sine Function\",\n  xaxt = \"n\", xlab = \"Degrees\", ylab = \"Sine\"\n)\naxis(side = 1, at = seq(0, 360, by = 45))\nabline(h = 0)\n\n\n\n\n\n\n\n\n\nAnd here is the cosine:\n\n\nCode\nplot(\n  x = degrees_int, y = cos(rads_num),\n  main = \"The Cosine Function\",\n  xaxt = \"n\", xlab = \"Degrees\", ylab = \"Cosine\"\n)\naxis(side = 1, at = seq(0, 360, by = 45))\nabline(h = 0)\n\n\n\n\n\n\n\n\n\n\n\n9.2.3 The Tangent Function\nNow, there is one other main function in trigonometry that we mentioned but haven’t discussed: the tangent. From the calculus perspective, the term “tangent” refers to a straight line with the slope that’s equal to a curve at a particular point. For a refresher, go back to the Formal Foundations section on the Limit Definition of the Derivative in the Poisson Distribution lesson. For trigonometry, the term “tangent” refers to a function relating the angle of a triangle to the ratio of its height and width. Using R, let’s confirm that this ratio for this triangle above is \\((1/2) \\div (\\frac{1}{2}\\sqrt{3})\\):\n\n\nCode\ntan(rads30_num)\n[1] 0.577\n(1/2) / (sqrt(3)/2)\n[1] 0.577\n\n\nRecall that the width of these triangles will oscillate from a maximum of 1 (when the angle is a multiple of \\(180^{\\circ}\\)) to a width of 0 (when the angle is half of a multiple of \\(180^{\\circ}\\)). Therefore, because the tangent is defined by the ratio of height to width, the tangent will be undefined (due to division by 0) when when the angle is half of a multiple of \\(180^{\\circ}\\). Let’s plot the tangent as well:\n\n\nCode\nplot(\n  x = degrees_int, y = tan(rads_num), ylim = c(-5, 5),\n  main = \"The Tangent Function\",\n  xaxt = \"n\", xlab = \"Degrees\", ylab = \"Tangent\"\n)\naxis(side = 1, at = seq(0, 360, by = 45))\nabline(v = c(90, 270))\n\n\n\n\n\n\n\n\n\n\n\n9.2.4 Inverse Trigonometric Functions\nAs with almost all mathematical operators, the trigonometric functions have inverse functions.6 These are functions that “undo” the effects of the original function. For example, if \\(f(x) = \\sqrt{x}\\), then \\(g(x) = x^2\\) “undoes” the effects of \\(f\\). For the trigonometric functions, these inverse functions are called the “arc” functions and defined as follows: \\[\n\\begin{aligned}\n\\arcsin(\\sin(\\theta)) &= \\theta, \\\\\n\\arccos(\\cos(\\theta)) &= \\theta, \\\\\n\\arctan(\\tan(\\theta)) &= \\theta.\n\\end{aligned}\n\\] So, these “arc” functions “undo” their corresponding trigonometric functions. These often come up when solving equations for an angle \\(\\theta\\). For example: \\[\n\\begin{aligned}\n\\sin(\\theta) &= \\frac{\\text{height}}{\\text{width}} \\\\\n\\Longrightarrow \\arcsin(\\sin(\\theta)) &= \\arcsin\\left( \\frac{\\text{height}}{\\text{width}} \\right) \\\\\n\\Longrightarrow \\theta &= \\arcsin\\left( \\frac{\\text{height}}{\\text{width}} \\right).\n\\end{aligned}\n\\]\nWe will also graph these three functions, but we remark that their domains will be different. For sine and cosine, the domain was \\([0^{\\circ}, 360^{\\circ}]\\); the range was \\([-1,1]\\). For tangent, the domain was \\([0^{\\circ}, 360^{\\circ}]\\) except for the vertical asymptotes at \\(\\{90^{\\circ}, 270^{\\circ}\\}\\); the range was \\((-\\infty, \\infty)\\). Also, as before, R uses radians instead of degrees, so we will also have to transform back the results to degrees.\nLet’s plot these inverse trigonometric functions, but pay special attention to their domains and ranges. Let’s start with the arcsine (using the asin() function):\n\n\nCode\ntriangleHeights_num &lt;- seq(-1, 1, length.out = 101)\nthetaRads_num &lt;- asin(triangleHeights_num)\nplot(\n  x = triangleHeights_num, y = 180 * thetaRads_num / pi, ylim = c(-90, 90),\n  main = \"The Arcsine Function\",\n  xaxt = \"n\", xlab = \"Triangle Heights\",\n  yaxt = \"n\", ylab = \"Generating Angle\"\n)\naxis(side = 1, at = seq(-1, 1, length.out = 9))\naxis(side = 2, at = seq(-90, 90, by = 30))\nabline(h = 0)\n\n\n\n\n\n\n\n\n\nSimilarly, we can plot the arccosine (using the acos() function):\n\n\nCode\ntriangleWidths_num &lt;- seq(-1, 1, length.out = 101)\nthetaRads_num &lt;- acos(triangleWidths_num)\nplot(\n  x = triangleWidths_num, y = 180 * thetaRads_num / pi, ylim = c(0, 180),\n  main = \"The Arccosine Function\",\n  xaxt = \"n\", xlab = \"Triangle Widths\",\n  yaxt = \"n\", ylab = \"Generating Angle\"\n)\naxis(side = 1, at = seq(-1, 1, length.out = 9))\naxis(side = 2, at = seq(0, 180, by = 30))\nabline(h = 0)\n\n\n\n\n\n\n\n\n\nFinally, for the arctangent, because this function takes the ratio of triangle heights and widths as its input, the domain of possible values includes the entire Real line. However, the range of the function is only from \\((-90^{\\circ}, 90^{\\circ})\\) (or \\(-\\frac{\\pi}{2}\\) to \\(-\\frac{\\pi}{2}\\) in radians). We now plot the this function (using the atan() function):\n\n\nCode\ntriangleTan_num &lt;- seq(-4, 4, length.out = 81)\nthetaRads_num &lt;- atan(triangleTan_num)\nplot(\n  x = triangleTan_num, y = 180 * thetaRads_num / pi, ylim = c(-90, 90),\n  main = \"The Arctangent Function\",\n  xaxt = \"n\", xlab = \"Triangle (Height / Width)\",\n  yaxt = \"n\", ylab = \"Generating Angle\"\n)\naxis(side = 1, at = seq(-4, 4, length.out = 9))\naxis(side = 2, at = seq(-180, 180, by = 45))\nabline(h = 0)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test</span>"
    ]
  },
  {
    "objectID": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#trigonometric-derivatives",
    "href": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#trigonometric-derivatives",
    "title": "9  Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test",
    "section": "9.3 Trigonometric Derivatives",
    "text": "9.3 Trigonometric Derivatives\nNow that we’ve had a basic refresher on the trigonometric functions, we want to get some intuition for the well-known trigonometric derivatives. These derivatives are \\[\n\\begin{aligned}\n\\frac{d}{d\\theta} \\sin(\\theta) &= \\cos(\\theta), \\\\\n\\frac{d}{d\\theta} \\cos(\\theta) &= -\\sin(\\theta), \\\\\n\\frac{d}{d\\theta} \\tan(\\theta) &= 1 + \\tan^2(\\theta).\n\\end{aligned}\n\\]\n\n9.3.1 Derivatives of Sine and Cosine\nRather than going through the deep dive7 needed to prove these derivatives, we will simply plot the slope of the sine function at many very small intervals. First, recall the graph of the sine (this time in radians):\n\n\nCode\nplot(\n  x = rads_num, y = sin(rads_num),\n  main = \"The Sine Function\",\n  xaxt = \"n\", xlab = \"Radians\", ylab = \"Sine\"\n)\naxis(side = 1, at = seq(0, 2*pi, by = pi/4))\nabline(h = 0)\n\n\n\n\n\n\n\n\n\nWe already see that the slope at 0 is 1, the slope at \\(\\pi/2\\) is 0, the slope at \\(\\pi\\) is negative 1, the slope at \\(3\\pi/2\\) is 0 again, and the slope at \\(2\\pi\\) is 1 again. (Also, since we don’t care about the angles themselves, I’m going to leave the computing in radians. It won’t matter to the shape of the curve.) Here are those points plotted (with the cosine curve in green):\n\n\nCode\nplot(\n  x = seq(0, 2 * pi, length.out = 5), y = c(1, 0, -1, 0, 1),\n  xaxt = \"n\", xlab = \"Radians\", xlim = c(0, 2*pi),\n  yaxt = \"n\", ylab = \"Slopes\", ylim = c(-1, 1),\n  main = \"Slopes of the Sine Function\"\n)\naxis(side = 1, at = seq(0, 2*pi, by = pi/4))\naxis(side = 2, at = seq(-1, 1, by = 0.5))\ncurve(cos(x), add = TRUE, col = \"darkgreen\", lwd = 2)\n\n\n\n\n\n\n\n\n\nLet’s write a function to calculate these slopes at more than these five simple points. (And we want the computer to calculate slopes for us.) I’m going to start very “rough”, and evaluate the slope at only 9 points:\n\n\nCode\nnPoints_int &lt;- 9\nradsSparse_num &lt;- seq(0, 2 * pi, length.out = nPoints_int + 1)\nsineSlopes_num &lt;- vector(mode = \"numeric\", length = nPoints_int)\nmidpoints_num &lt;- vector(mode = \"numeric\", length = nPoints_int)\n\nfor (x in seq_len(nPoints_int)) {\n  \n  deltaY &lt;- sin(radsSparse_num[x + 1]) - sin(radsSparse_num[x])\n  deltaTheta &lt;- radsSparse_num[x + 1] - radsSparse_num[x]\n  \n  sineSlopes_num[x] &lt;- deltaY / deltaTheta\n  midpoints_num[x]  &lt;- (radsSparse_num[x + 1] + radsSparse_num[x]) / 2\n  \n}\n\nplot(\n  x = midpoints_num, y = sineSlopes_num,\n  xaxt = \"n\", xlab = \"Radians\", xlim = c(0, 2*pi),\n  yaxt = \"n\", ylab = \"Slopes\", ylim = c(-1, 1),\n  main = \"Slopes of the Sine Function\"\n)\naxis(side = 1, at = seq(0, 2*pi, by = pi/4))\naxis(side = 2, at = seq(-1, 1, by = 0.5))\ncurve(cos(x), add = TRUE, col = \"darkgreen\", lwd = 2)\n\n\n\n\n\n\n\n\n\nBecause the computer is doing all the work, let’s increase to 99 points:\n\n\nCode\nnPoints_int &lt;- 99\nradsSparse_num &lt;- seq(0, 2 * pi, length.out = nPoints_int + 1)\nsineSlopes_num &lt;- vector(mode = \"numeric\", length = nPoints_int)\nmidpoints_num &lt;- vector(mode = \"numeric\", length = nPoints_int)\n\nfor (x in seq_len(nPoints_int)) {\n  \n  deltaY &lt;- sin(radsSparse_num[x + 1]) - sin(radsSparse_num[x])\n  deltaTheta &lt;- radsSparse_num[x + 1] - radsSparse_num[x]\n  \n  sineSlopes_num[x] &lt;- deltaY / deltaTheta\n  midpoints_num[x]  &lt;- (radsSparse_num[x + 1] + radsSparse_num[x]) / 2\n  \n}\n\nplot(\n  x = midpoints_num, y = sineSlopes_num,\n  xaxt = \"n\", xlab = \"Radians\", xlim = c(0, 2*pi),\n  yaxt = \"n\", ylab = \"Slopes\", ylim = c(-1, 1),\n  main = \"Slopes of the Sine Function\"\n)\naxis(side = 1, at = seq(0, 2*pi, by = pi/4))\naxis(side = 2, at = seq(-1, 1, by = 0.5))\ncurve(cos(x), add = TRUE, col = \"darkgreen\", lwd = 2)\n\n\n\n\n\n\n\n\n\nAs we can see, as the difference between each angle shrinks (i.e. as \\(\\Delta\\theta \\to 0\\)), the slopes of the lines tangent to the sine function approach the values given by the cosine function. Not to belabour the point, but we can apply the exact same effort to show that the derivative of the cosine function is \\(-1\\) times the sine function. This line of reasoning is not a proof (for a formal proof, see the link to Prof. Brown’s notes that I also included in the footnote above), but it does help us understand what is going on a bit better.\n\n\n9.3.2 Derivative of Tangent\nNow that we have the derivative of \\(\\sin(\\theta)\\) and \\(\\cos(\\theta)\\), the derivative of \\(\\tan(\\theta)\\) is far more straightforward, using the Quotient Rule and the two derivatives we just reviewed: \\[\n\\begin{aligned}\n\\frac{d}{d\\theta} \\tan(\\theta) &= \\frac{d}{d\\theta} \\frac{\\sin(\\theta)}{\\cos(\\theta)} \\\\\n&= \\frac{\\cos(\\theta) \\frac{d}{d\\theta} \\sin(\\theta) - \\sin(\\theta) \\frac{d}{d\\theta} \\cos(\\theta)}{[\\cos(\\theta)]^2} \\\\\n&= \\frac{\\cos(\\theta) \\times [\\cos(\\theta)] - \\sin(\\theta) \\times [-\\sin(\\theta)]}{\\cos^2(\\theta)} \\\\\n&= \\frac{\\cos^2(\\theta) + \\sin^2(\\theta)}{\\cos^2(\\theta)} \\\\\n&= \\frac{\\cos^2(\\theta)}{\\cos^2(\\theta)} + \\frac{\\sin^2(\\theta)}{\\cos^2(\\theta)} \\\\\n&= 1 + \\tan^2(\\theta).\n\\end{aligned}\n\\]\n\n\n9.3.3 Derivative of the Arctangent\nThis derivative is more non-traditional (that is, creative). Let’s begin by letting \\(\\arctan(x) = \\theta\\), which implies that \\(\\tan(\\theta) = x\\). Then,8 \\[\n\\begin{aligned}\n\\frac{d}{dx} \\tan(\\theta) &= \\frac{d}{dx}x \\\\\n\\qquad\\text{\\emph{Chain rule...}}& \\\\\n\\Longrightarrow \\left( 1 + \\tan^2(\\theta) \\right) \\frac{d\\theta}{dx} &= 1 \\\\\n\\left( 1 + [\\tan(\\theta)]^2 \\right) \\frac{d[\\theta]}{dx} &= 1 \\\\\n\\qquad\\text{\\emph{Substitute back in...}}& \\\\\n\\left( 1 + [x]^2 \\right) \\frac{d[\\arctan(x)]}{dx} &= 1 \\\\\n\\Longrightarrow \\frac{\\left( 1 + x^2 \\right)}{\\left( 1 + x^2 \\right)} \\frac{d}{dx}\\arctan(x) &= \\frac{1}{1 + x^2} \\\\\n\\Longrightarrow \\frac{d}{dx}\\arctan(x) &= \\frac{1}{1 + x^2}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test</span>"
    ]
  },
  {
    "objectID": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#the-saddlepoint-test",
    "href": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#the-saddlepoint-test",
    "title": "9  Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test",
    "section": "9.4 The Saddlepoint Test",
    "text": "9.4 The Saddlepoint Test\n\nAs a comment, parts of this “Formal Foundations” section requires a foundational understanding of vectors and linear algebra, which is well beyond the scope of this text. For a primer on linear algebra, I recommend Prof. Gilbert Strang’s MIT Linear Algebra course here: https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/. It’s completely free, but it will take you a few weeks to get through it all.\n\n\n9.4.1 Introduction\nWhen we find the maximum likelohood estimators, we were careful to also check the second derivatives to ensure that those derivatives were negative at our candidate points for the MLEs (these candidate values are the solution points to the systems of first order partial derivatives, also known as critical points9). In the simple \\(x,y\\) (2-dimensional) plane for introductory calculus, for some critical point \\(x_0\\), checking if \\(x_0 \\ni f^{\\prime}(x_0) = 0\\) was a minimum or maximum was often quite simple (and we will go over a refresher example below). This is because changes could only ever be in one dimension: along \\(x\\).\nHowever, for a function in higher dimensions, such as \\(z = f(x,y)\\), changes can happen in infinitely many directions, as long as they are some combination of changes in \\(x\\) and \\(y\\). We can’t simply check the derivatives along the \\(x\\) axis or the \\(y\\) axis only; we also have to check the infinitely many derivatives across every direction between \\(x\\) and \\(y\\). This already sounds like a problem, and we’ve only described a simple surface in 3 dimensions!\nInstead of trying to walk through uncountably infinitely many partial derivatives in every direction around a critical point, we will use the geometric properties of the likelihood function instead. If we have found a point where the gradient10 of \\(f\\) equals 0, then there are a few options:\n\n\\(f\\) is concave up, and the point is a local minimum,\n\\(f\\) is concave down, and the point is a local maximum,\naround the point, \\(f\\) is increasing in some directions and decreasing in others, so the point is a saddlepoint11, or\n\\(f\\) is not second-order differentiable at the point (which means you’re in trouble). We won’t really cover this last option for our work in optimizing likelihood functions, but it is theoretically possible.\n\n\nOne beneficial heuristic to understanding these shapes is to check for their ability to “hold water”. In the figure above, the shapes in (a) and (b) could be rotated around to eventually serve as a bowl of some kind. For part (a), the figure stays the same; for part (b), we would have to flip it over. However, in part (c), we notice that no possible rotation exists for the shape to hold water. Therefore, the figures in parts (a) and (b) have local extrema at their critical points, but the figure in part (c) has a saddlepoint.\n\n\n9.4.2 Two-Dimensional Use Case\nLet’s take a step back and look at an example on the \\(x,y\\) plane. We have a function \\(f\\), and we will take its first two derivatives: \\[\n\\begin{aligned}\nf(x) &= x^3 - 3x + 2 \\\\\nf^{\\prime}(x) &= 3x^2 - 3 \\\\\nf^{\\prime\\prime}(x) &= 6x.\n\\end{aligned}\n\\] We set our first derivative equal to 0 to find the critical points: \\[\n\\begin{aligned}\n0 &\\overset{\\text{set}}{=} 3x^2 - 3 \\\\\n\\Longrightarrow 0 &= x^2 - 1 \\\\\n&= (x - 1)(x + 1) \\\\\n\\Longrightarrow x &= \\{-1, 1\\}.\n\\end{aligned}\n\\] If we were doing statistics or biostatistics, many students at this point would shout and say “I’ve found the maximum!” or “I’ve found the minimum!”—which ever one they were looking for in the first place. Well, let’s graph this function to find out:\n\n\nCode\ndomain_num &lt;- seq(-3, 3, length.out = 101)\nf_num &lt;- (domain_num)^3 - 3*(domain_num) + 2\n\nplot(\n  x = domain_num, y = f_num,\n  main = \"\", xlab = \"x\", ylab = \"y\"\n)\n\n\n\n\n\n\n\n\n\nIt appears that we have a local maxima at \\(x = -1\\) and a local minima at \\(x = 1\\). However, many real problems are not so easy, as we’ve seen in this class. For example, in our statistical distributions, the parameters were arbitrary, not fixed numbers, so there would be no way to graph the likelihood anyway. We need analytical solutions.\n\n\n9.4.3 The First Derivative Test\nHow do we know that what the critical point we’ve found is a maximum? (Or minimum?) We need to know what’s happening to \\(f\\) near these two points. Let \\(x^*\\) denote the \\(x\\) values of our critical points. Here are our two decision schemes:\n\nThe First Derivative Test\n\nIf where \\(x &lt; x^*\\), the derivative is negative, AND, where \\(x &gt; x^*\\), the derivative is positive, then \\(x^*\\) is a minima of \\(f\\).\nIf where \\(x &lt; x^*\\), the derivative is positive, AND, where \\(x &gt; x^*\\), the derivative is negative, then \\(x^*\\) is a maxima of \\(f\\).\nIf the derivative has the same sign on both sides of \\(x^*\\), then the critical value is neither a minima nor a maxima.\n\n\nHere’s an example from some undergrad worksheet (this text uses critical number instead of critical value, but they mean the same thing; also I have no idea what textbook this is from to be honest). \nFor our function \\(f\\) above:\n\n\\(f^{\\prime}(-2) = 3(-2)^2 - 3 = 3(4) - 3 = 9 &gt; 0\\), so \\(f\\) is increasing for \\(x &lt; -1\\),\n\\(f^{\\prime}(0) = -3\\), so \\(f\\) is decreasing for \\(-1 &lt; x &lt; 1\\), and\n\\(f^{\\prime}(2) = 3(2)^2 - 3 = 3(4) - 3 = 9 &gt; 0\\), so \\(f\\) is increasing for \\(x &gt; 1\\).\n\nTherefore, \\(f\\) is increasing on the left side and decreasing on the right side of \\(x^* = -1\\), so this critical point is a local maximum. Additionally, \\(f\\) is decreasing on the left side and increasing on the right side of \\(x^* = 1\\), so this critical point is a local minimum.\n\n\n9.4.4 The Second Derivative Test\nThere is another option to find if a critical point is a minimum/maximum/neither (in case you think that plugging in values all around the critical points is tedious). The second derivative test checks the concavity12 of \\(f\\) around critical values. Imaging rain falling on our function \\(f\\); think about concavity as the ability to “hold” the rainwater (concave up, like a bucket) or “shelter” from the rainwater (concave down, like an umbrella).13\n\nThe Second Derivative Test\n\nIf \\(f^{\\prime\\prime}(x^*) &gt; 0\\), then \\(f\\) is concave up at \\(x^*\\), and this point is a minima of \\(f\\).\nIf \\(f^{\\prime\\prime}(x^*) &lt; 0\\), then \\(f\\) is concave down at \\(x^*\\), and this point is a maxima of \\(f\\).\nIf \\(f^{\\prime\\prime}(x^*) = 0\\), then the critical value is neither a minima nor a maxima.\n\n\nHere is another visual aide (from some other unknown calculus textbook):\n\nFor our function \\(f\\) above:\n\n\\(f^{\\prime\\prime}(-1) = 6(-1) = -6 &lt; 0\\), so \\(f\\) is concave down at \\(x = -1\\), so this critical point is a local maximum.\n\\(f^{\\prime\\prime}(1) = 6(1) = 6 &gt; 0\\), so \\(f\\) is concave up at \\(x = 1\\), so this critical point is a local minimum.\n\n\n\n9.4.5 Extending to Higher Dimensions\nThe work that we’ve done so far is great if we have our response as a function of a single predictor (like \\(y = f(x)\\)). But many of the likelihoods we’ve encountered so far have two or more unknown parameters. What happens then?\nLet’s start with a simple function in 3 dimensions (ChatGPT helped me come up with this): \\[\nf(x,y) = x^3 + y^3 - 3xy.\n\\]\nWhat does it look like? Can we clearly tell where any minima/maxima are?\n\n\nCode\n# Define the function\nf &lt;- function(x, y) {\n  x^3 + y^3 - 3*x*y\n}\n\n# Create a grid of x and y values\nx &lt;- seq(-2, 2, length.out = 20)\ny &lt;- seq(-2, 2, length.out = 20)\nz &lt;- outer(x, y, f)\n\n# Create the perspective plot\npersp(\n  x, y, z,\n  theta = 45, phi = 30,    # Viewing angles\n  expand = 0.6,            # Zoom\n  col = \"lightblue\",       # Surface color\n  xlab = \"x\", ylab = \"y\", zlab = \"f(x, y)\",\n  ticktype = \"detailed\",   # Detailed axis ticks\n  shade = 0.5              # Shading for depth\n)\n\n\n\n\n\n\n\n\n\nWe should start by taking some derivatives. \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial x} f(x,y) &= 3x^2 - 3y \\\\\n\\frac{\\partial}{\\partial y} f(x,y) &= 3y^2 - 3x.\n\\end{aligned}\n\\] Setting these equations to 0 yields the following system (I also divide out the 3): \\[\n\\begin{aligned}\n0 &= x^2 - y \\Rightarrow y = x^2 \\\\\n0 &= y^2 - x \\Rightarrow y = \\pm\\sqrt{x}.\n\\end{aligned}\n\\] Let’s equate these.\n\nFirst take the option for \\(y = -\\sqrt{x}\\). Where is \\(x^2 = -\\sqrt{x}\\)? Only at \\(x = 0\\). Therefore \\(\\{x = 0, y = 0\\}\\) are the \\(x,y\\) coordinates of a critical point of \\(f(x,y)\\). At this point, \\(f(0,0) = 0\\), so the candidate critical 3-tuple14 is \\(\\langle 0, 0, 0 \\rangle\\).\nNow take the option for \\(y = \\sqrt{x}\\). Where is \\(x^2 = \\sqrt{x}\\)? We should quickly see by substitution that this is only true when \\(x \\in \\{0,1\\}\\). However, we will also show it analytically: \\[\n\\begin{aligned}\nx^2 &= \\sqrt{x} \\\\\n\\Rightarrow x^4 &= x \\\\\n\\Rightarrow x^4 - x &= 0 \\\\\n\\Rightarrow x(x^3 - 1) &= 0.\n\\end{aligned}\n\\] Thus, \\(x = 0\\) and \\(x^3 = 1 \\Rightarrow x = 1\\). Subsequently, \\(y = 0\\) and \\(y = 1\\). Therefore, at these points, the \\(f\\) values are: \\[\nf(0,0) = 0;\\ \\ f(1,1) = 1 + 1 - 3(1)(1) = -1.\n\\] Hence, the critical 3-tuples are \\(\\langle 0, 0, 0 \\rangle\\) (which we saw above), and \\(\\langle 1, 1, -1 \\rangle\\).\n\n\n\n9.4.6 “Holding Water”\nOne of the best ways I’ve found to understand the shape of surfaces in higher dimensions is to think about a rain shower falling from above onto the surface. If there is a region that water can “pool” (collect) in, then there will be at least one local minimum in that region. Similarly, if I flip the surface upside down, and I then get a region for water to pool in, then the original surface has at least one local maximum in that region. Finally, if the water never collects in a region, even if I flip the surface upside down, then that region does not have any local extrema.\nLet’s go back to our graph of \\(f(x) = x^3 - 3x + 2\\):\n\n\nCode\ndomain_num &lt;- seq(-3, 3, length.out = 101)\nf_num &lt;- (domain_num)^3 - 3*(domain_num) + 2\n\nplot(\n  x = domain_num, y = f_num,\n  main = \"\", xlab = \"x\", ylab = \"y\"\n)\n\n\n\n\n\n\n\n\n\nIf I allow rain to fall on \\(f\\) from “above”, then water will collect in a pool around the point \\(x = 1\\); this point is a local minimum of \\(f\\). If allow rain to fall on \\(-f\\) from above (where I’ve flipped \\(f\\) over vertically), then water will collect in a pool around the point \\(x = -1\\); this point is a local maximum of \\(f\\).\nThis example of “holding water” extends easily to higher dimensions. If, around a point in \\(\\mathbb{R}_p\\), the surface forms a “bowl” shape, then there will be a local minimum. If, around a point in \\(\\mathbb{R}_p\\), the surface forms an “umbrella” shape, then there will be a local maximum. The way that we measure if a higher dimensional shape has “volume” is with the determinant15 For clarity, both bowl and umbrella shapes can hold some water in them, but we make a fancy abstraction and say that the umbrella holds “negative” water—that is, that it would hold water if you flipped it upside down.\n\n\n9.4.7 The Hessian Matrix\nThe Hessian Matrix16 is a matrix of all the second-order partial derivatives of a function. The “volume” of this matrix at a point in \\(\\mathbb{R}_p\\) will tell us if \\(f\\) has a bowl shape, an umbrella shape, or no water-holding shape at all at that point. Again, we measure the volume of a matrix by calculating the determinant.\n\nThe Hessian Determinant and Saddlepoint Test\nLet \\(\\textbf{H}\\) be the Hessian Matrix of all second-order partial derivatives of \\(f:\\mathbb{R}_p \\to \\mathbb{R}\\). As long as \\(\\det\\{\\textbf{H}[f(\\textbf{x})]\\} &gt; 0\\), then \\(f\\) has volume at this point (but we won’t know if it’s positive or negative volume). To check if the volume is positive or negative, we look at the second derivative in any direction. Why? Because a bowl is increasing every direction and an umbrella is decreasing in every direction, so once we know \\(f\\) has a bowl/umbrella shape, it doesn’t matter which second derivative we look at. Here are the decision rules:\n\nIf \\(\\det\\{\\textbf{H}[f(\\textbf{x})]\\} &gt; 0\\) at the point \\(\\textbf{x}\\), then we check if the diagonals are positive:\n\n\nIf so, then \\(f\\) is concave up (\\(f\\) would collect water around this point) and \\(\\textbf{x}\\) is a local minimum.\nIf not, then \\(f\\) is concave down (-\\(f\\) would collect water around this point, but \\(f\\) would act like an umbrella there) and \\(\\textbf{x}\\) is a local maximum.\n\n\nIf \\(\\det\\{\\textbf{H}[f(\\textbf{x})]\\} &lt; 0\\) at the point \\(\\textbf{x}\\), then \\(\\textbf{x}\\) is called a saddlepoint of \\(f\\). The point \\(\\textbf{x}\\) is neither a minimum nor a maximum.\nIf \\(\\det\\{\\textbf{H}[f(\\textbf{x})]\\} = 0\\) at the point \\(\\textbf{x}\\), then the saddlepoint test is inconclusive (and you’re in trouble).\n\n\nLet’s go back to our 3-D function, \\(f(x,y) = x^3 + y^3 - 3xy\\). Using the first derivatives, we found that \\(\\langle 0, 0, 0 \\rangle\\) and \\(\\langle 1, 1, -1 \\rangle\\) are critical points of the function \\(f\\). Now let’s calculate the Hessian. Recall that: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial x} f(x,y) &= 3x^2 - 3y \\\\\n\\frac{\\partial}{\\partial y} f(x,y) &= 3y^2 - 3x.\n\\end{aligned}\n\\] Therefore, \\[\n\\begin{aligned}\n\\textbf{H}[f(x,y)] &= \\begin{bmatrix}\n  \\frac{\\partial}{\\partial x} \\frac{\\partial f}{\\partial x} & \\frac{\\partial}{\\partial x} \\frac{\\partial f}{\\partial y} \\\\\n  \\frac{\\partial}{\\partial y} \\frac{\\partial f}{\\partial x} & \\frac{\\partial}{\\partial y} \\frac{\\partial f}{\\partial y}\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  \\frac{\\partial}{\\partial x} 3x^2 - 3y & \\frac{\\partial}{\\partial x} 3y^2 - 3x \\\\\n  \\frac{\\partial}{\\partial y} 3x^2 - 3y & \\frac{\\partial}{\\partial y} 3y^2 - 3x\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  6x & -3 \\\\\n  -3 & 6y\n\\end{bmatrix}.\n\\end{aligned}\n\\]\nThe first critical point was \\(\\{x = 0, y = 0\\}\\). Let’s check the determinant17 at this point: \\[\n\\begin{aligned}\n\\textbf{H}[f(0,0)] &= \\begin{bmatrix}\n  6[0] & -3 \\\\\n  -3 & 6[0]\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  0 & -3 \\\\\n  -3 & 0\n\\end{bmatrix} \\\\\n\\Longrightarrow \\det\\{\\textbf{H}[f(0,0)]\\} &= [0][0] - [-3][-3] \\\\\n&= -9.\n\\end{aligned}\n\\] Therefore, the surface given by \\(f(x,y)\\) is neither concave up nor concave down at the point \\(\\{x = 0, y = 0\\}\\). Thus, this is a saddlepoint. The name comes from the seat of a saddle, but it always reminded me more of the shape of a Pringle crisp.18 In the figure below, we see that the shape is concave up on one axis, but concave down in the orthogonal19 direction.\n\nWhat about the critical point at \\(\\{x = 1, y = 1\\}\\)? The Hessian determinant is \\[\n\\begin{aligned}\n\\textbf{H}[f(1,1)] &= \\begin{bmatrix}\n  6[1] & -3 \\\\\n  -3 & 6[1]\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  6 & -3 \\\\\n  -3 & 6\n\\end{bmatrix} \\\\\n\\Longrightarrow \\det\\{\\textbf{H}[f(0,0)]\\} &= [6][6] - [-3][-3] \\\\\n&= 36 - 9 \\\\\n&= 27.\n\\end{aligned}\n\\] The surface given by \\(f(x,y)\\) is either concave up or concave down at the point \\(\\{x = 1, y = 1\\}\\), but we don’t yet know which. We at least know that either \\(f\\) or \\(-f\\) could “hold water” at \\(\\{x = 1, y = 1\\}\\). We now check either of the two diagonal values; both second-order derivatives \\(\\left( \\frac{\\partial^2f}{\\partial x^2}, \\frac{\\partial^2f}{\\partial y^2} \\right)\\) are positive at this point, so \\(f\\) is concave up there. Thus, the critical value at \\(\\{x = 1, y = 1\\}\\) is a local minimum. Let’s try to “zoom in” on \\(f\\) around this point:\n\n\nCode\n# Define the function\nf &lt;- function(x, y) {\n  x^3 + y^3 - 3*x*y\n}\n\n# Create a grid of x and y values\nx &lt;- seq(0.5, 1.5, length.out = 30)\ny &lt;- seq(0.5, 1.5, length.out = 30)\nz &lt;- outer(x, y, f)\n\n# Create the perspective plot\npersp(\n  x, y, z,\n  theta = 30, phi = 15,    # Viewing angles\n  expand = 0.6,            # Zoom\n  col = \"lightblue\",       # Surface color\n  xlab = \"x\", ylab = \"y\", zlab = \"f(x, y)\",\n  ticktype = \"detailed\",   # Detailed axis ticks\n  shade = 0.5              # Shading for depth\n)\n\n\n\n\n\n\n\n\n\nIt looks like a little puddle could form if some rain fell on this surface.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test</span>"
    ]
  },
  {
    "objectID": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#footnotes",
    "href": "chapters/theory_saddlepoint_and_trig_derivatives_20250728.html#footnotes",
    "title": "9  Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Unit_circle↩︎\nhttps://en.wikipedia.org/wiki/Right_triangle↩︎\nThe name for the longest side of a triangle↩︎\nhttps://en.wikipedia.org/wiki/Pythagorean_trigonometric_identity↩︎\nhttps://en.wikipedia.org/wiki/Radian↩︎\nhttps://en.wikipedia.org/wiki/Inverse_function#Standard_inverse_functions↩︎\nRead Prof. R. Brown’s supplemental proof on this: https://math.jhu.edu/~brown/courses/f11/Concepts/Section3.3.pdf↩︎\nNote that it’s “bad form” to manipulate a string of equations on the left hand side, but I’m doing it anyway.↩︎\nhttps://tutorial.math.lamar.edu/classes/calci/criticalpoints.aspx↩︎\nhttps://en.wikipedia.org/wiki/Gradient↩︎\nhttps://en.wikipedia.org/wiki/Saddle_point↩︎\nhttps://www.khanacademy.org/math/ap-calculus-ab/ab-diff-analytical-applications-new/ab-5-6b/a/concavity-review↩︎\nThis idea of being able to “hold water” is a recurring theme for understanding the Saddlepoint Test, which we are leading up to.↩︎\nhttps://en.wikipedia.org/wiki/Tuple↩︎\nThis note requires you to remember some linear algebra: https://textbooks.math.gatech.edu/ila/determinants-volumes.html↩︎\nhttps://en.wikipedia.org/wiki/Hessian_matrix↩︎\nThe determinant of a \\(2x2\\) matrix is \\(ad - bc\\). See https://www.cuemath.com/algebra/determinant-of-matrix/↩︎\nThere is some cool math/physics behind the geometry of this crisp shape: https://www.mechead.com/food-science-geometry-of-pringles/↩︎\nhttps://en.wikipedia.org/wiki/Orthogonality↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Formal Foundations: Trigonometric Derivatives and the Saddlepoint Test</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html",
    "href": "chapters/normal_20250310.html",
    "title": "10  The Normal Distribution",
    "section": "",
    "text": "10.1 Deriving the Error Distribution\nThe Normal Distribution (also called the Gaussian Distribution after Carl Friedrich Gauss1) is first and foremost the “mistakes” distribution. Gauss derived this distribution to explain the discrepencies between multiple junior (or even senior) astronomers’ reported planetary positions. As a quick note, this derivation is absolutely monstrous (Gauss’ genius was orders of magnitude beyond my intelligence). We will follow the general premise of Prof. Xi Chen’s translation and understanding of Gauss’ original notes (and Prof. Chen’s comprehensive understanding of the history of mathematics and statistics); he published his thoughts in his blog “Not a Rocket Scientist” in his 27 January 2023 post.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#deriving-the-error-distribution",
    "href": "chapters/normal_20250310.html#deriving-the-error-distribution",
    "title": "10  The Normal Distribution",
    "section": "",
    "text": "10.1.1 Preliminary Notation and Assumptions\nWe begin by noting that if we have only one measurement, that single measurement is our best guess for the truth. Let’s denote it \\(m\\). Also, we assume that:\n\nIf we add more independent measurements, we can use the arithmetic mean to “summarize” them well.\nIf we add more independent measurements from similarly trained astronomers, these new values can be described positive or negative deviations (i.e., mistakes or errors) from the first measurement.\nThese mistakes/deviations/errors should be independently and symmetrically distributed around 0\n\nby random chance, an astronomer is just as likely to write down a number slightly smaller than the “truth” as they would be to write down a slightly larger number; and,\nthese astronomers are all similarly trained and trying their best, so we expect the mistake distribution to be the same for all astronomers.\n\nSmaller mistakes/deviations/errors are more likely to occur than larger errors.\n\n\n“It has been customary to regard as an axiom the hypothesis that if any quantity has been determined by several direct observations, made under the same circumstances and with equal care, the arithmetic mean of the observed values will yield the most probable value…\nGauss, Theoria Motus, as shown in “Gauss’ First Argument for Least Squares”, p. 43. https://www.jstor.org/stable/41133877?seq=3\n\nWe start by assuming that the first measurement is the correct one (which is obviously wrong, but it allows us to understand what’s happening, and the assumption will be quickly discarded). If we have \\(n\\) independent attempts to measure the same true value (like the angle of one planet relative to another), denoted \\(X_1, X_2, \\ldots, X_n\\), the mistake (error) components of these measures can be defined as \\[\n[E_1, E_2, \\ldots, E_n] = [X_1, X_2, \\ldots, X_n] - m.\n\\]\n\n\n10.1.2 Applying Assumptions\nAs we assumed above, these mistakes are all independent and identically distributed according to some distribution. We denote this as \\[\nE_i \\overset{iid}{\\sim} f_E(\\varepsilon).\n\\] As we already assumed, errors are symmetric around 0. Thus, we know that \\(f_E(\\varepsilon) = f_E(-\\varepsilon)\\). Further, because we also assume that errors near 0 are more likely than errors further away, this leads us to create a likelihood function. While, we do have a vector of observed data (the errors, \\(E_i\\)), we don’t know what kinds of parameter space we are optimizing over. So, we will present the general form of some likelihood function optimization with an unspecified parameter suite (the empty dot): \\[\n\\begin{aligned}\n\\mathcal{L}(\\circ|\\textbf{E}) &= \\prod_{i = 1}^n f(\\varepsilon_i|\\circ) \\\\\n\\Longrightarrow \\ell(\\circ|\\textbf{E}) &= \\sum_{i = 1}^n \\log\\left[ f(\\varepsilon_i|\\circ) \\right] \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\circ} \\ell(\\circ|\\textbf{E}) &= \\sum_{i = 1}^n \\frac{f^{\\prime}(\\varepsilon_i|\\circ)}{f(\\varepsilon_i|\\circ)}.\n\\end{aligned}\n\\]\nNow we have to take a step back here. We have no idea what \\(f\\) looks like, so we have no idea what \\(\\ell\\) looks like, and we certainly have no idea to take a derivative with respect to some unknown group of parameters (we don’t even know how many there are), or even if we are taking the derivative with respect to the parameters at all! All we know is that we are taking the derivative of some function \\(\\ell\\) with respect to something, and that we are treating the data as fixed so that we can find the functions \\(\\ell\\) and \\(f\\) which fit the data best.\nTo make the notation a touch easier, let \\(g_E(\\varepsilon) = f^{\\prime}(\\varepsilon_i) / f(\\varepsilon_i)\\). Now, let’s apply some of Gauss’ intuition, that the arithmetic mean would be a good approximation of the truth; that is, Gauss assumed that \\(\\bar{X} \\approx m\\). Thus, \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\circ} \\ell(\\circ|\\textbf{E}) &= \\sum_{i = 1}^n \\frac{f^{\\prime}(\\varepsilon_i|\\circ)}{f(\\varepsilon_i|\\circ)} \\\\\n&\\qquad\\text{\\emph{Easier notation...}} \\\\\n&= \\sum_{i = 1}^n g_E(\\varepsilon) \\\\\n&\\qquad\\text{\\emph{By definition...}} \\\\\n&= \\sum_{i = 1}^n g_E(X_i - m) \\\\\n&\\qquad\\text{\\emph{Gauss' intuition...}} \\\\\n&\\approx \\sum_{i = 1}^n g_E(X_i - \\bar{X}) \\\\\n&\\qquad\\text{\\emph{Assumption that mistakes centre around 0...}} \\\\\n&= 0.\n\\end{aligned}\n\\] This may look trivial (obviously the sum of mistakes which centre at 0 should be approximately 0), but it allows us to make more clarifying statements about the original error function. Now, we have that we are looking for some \\(f(\\textbf{E}|\\boldsymbol\\theta) \\ni \\nabla\\ell(\\boldsymbol\\theta|\\textbf{E}) = 0\\)2. Notice that this relationship will hold for any properly constructed sample \\(\\textbf{X}\\), because we are constructing \\(f\\) to have this property.\n\n\n10.1.3 Clues About \\(g_E\\)\nWe are being good little detectives so far. We know a couple things now: \\[\n\\begin{aligned}\n\\nabla \\ell(\\boldsymbol\\theta|\\textbf{E}) \\approx \\sum_{i = 1}^n g_E(X_i - \\bar{X}) &= 0 \\\\\n\\sum_{i = 1}^n x_i - n\\bar{x} &= 0.\n\\end{aligned}\n\\] The first is what we discovered last section. The second is by definition. So we need a family of functions for \\(g_E\\) so that \\[\n\\sum_{i = 1}^n g_E(X_i - \\bar{X}) = \\sum_{i = 1}^n X_i - n\\bar{X}.\n\\] So, we need a function \\(g_E\\) that will allow the summation operator to “pass through”, so that \\[\n\\sum_{i = 1}^n g_E(X_i - \\bar{X}) = g_E\\left( \\sum_{i = 1}^n [X_i - \\bar{X}]. \\right)\n\\] This means that we need \\(g_E\\) to be a linear transformation3. Also, we need \\[\n\\begin{align}\n0 &= \\sum_{i = 1}^n g_E(X_i - \\bar{X}) \\\\\n&\\qquad\\text{\\emph{We just assumed this...}} \\\\\n&= g_E\\left( \\sum_{i = 1}^n [X_i - \\bar{X}] \\right) \\\\\n&= g_E\\left( \\left[\\sum_{i = 1}^n X_i\\right] - n\\bar{X} \\right) \\\\\n&\\qquad\\text{\\emph{Because it's a linear transformation...}} \\\\\n&= g_E\\left( \\sum_{i = 1}^n X_i \\right) - g_E\\left( n\\bar{X} \\right).\n\\end{align}\n\\] This last requirement is much more restrictive than you might think. We think of linear functions as anything of the form \\(y = mx + b\\), but this is technically an affine transformation4. Our function \\(g_E\\), in order to have the properties we need, cannot have a “shift” term. Thus, for some unknown constant \\(C\\), \\[\ng_E(\\varepsilon) = C\\varepsilon.\n\\] Only a function of this form will allow \\[\n\\begin{aligned}\n0 &= \\sum_{i = 1}^n X_i - n\\bar{X} \\\\\n&= g_E\\left( \\sum_{i = 1}^n X_i \\right) - g_E\\left( n\\bar{X} \\right) \\\\\n&= g_E\\left( \\sum_{i = 1}^n [X_i - \\bar{X}] \\right) \\\\\n&= \\sum_{i = 1}^n g_E(X_i - \\bar{X})\n\\end{aligned}\n\\] to all be simultaneously true.\n\n\n10.1.4 A Form for \\(\\ell\\)\nFinally, these baby steps are starting to add up! We now know that \\[\n\\sum_{i = 1}^n g_E(\\varepsilon_i|\\boldsymbol\\theta) = \\sum_{i = 1}^n C\\varepsilon_i.\n\\] This is incredible! We now can see that there is only one parameter in the derivative of our unknown parameter space, and it is some constant \\(C\\).\nThis allows us to “bend” our thinking again. When we started, we had to treat the data as fixed, and the form of \\(f\\) and \\(\\ell\\) as unknown. Well, now we have a form for the derivative of the log of \\(f\\). So, we will pivot, and now treat the form of \\(f\\) as fixed, and treat the data as unknown. This allows us to integrate with respect to the changing data, \\(\\varepsilon\\). Thus, for a single unknown data point, we have a differential equation: \\[\n\\begin{aligned}\nC\\varepsilon &= g_E(\\varepsilon|C) \\\\\n&= \\frac{\\frac{d}{d\\varepsilon} f_E(\\varepsilon|C)}{f_E(\\varepsilon|C)} \\\\\n\\Longrightarrow \\int C\\varepsilon d\\varepsilon &= \\int \\frac{\\frac{d}{d\\varepsilon} f_E(\\varepsilon|C)}{f_E(\\varepsilon|C)} d\\varepsilon \\\\\n\\Longrightarrow \\frac{C_1}{2}\\varepsilon^2 + C_2 &= \\log\\left[ f_E(\\varepsilon|C) \\right] + C_3 \\\\\n\\Longrightarrow \\frac{C_1}{2}\\varepsilon^2 + (C_2 - C_3) &= \\log\\left[ f_E(\\varepsilon|C) \\right] \\\\\n\\Longrightarrow e^{\\frac{C_1}{2}\\varepsilon^2 + (C_2 - C_3)} &= f_E(\\varepsilon|C).\n\\end{aligned}\n\\]\nNotice that this form of \\(f_E\\) has three unknown constants, so let’s clean these up: \\[\nf_E(\\varepsilon|C) = e^{\\frac{C_1}{2}\\varepsilon^2 + (C_2 - C_3)} = Ae^{\\frac{C_1}{2}\\varepsilon^2}.\n\\]\nNow, let’s check our original assumptions about \\(f_E(\\varepsilon)\\).\n\nWe assumed that \\(f_E(\\varepsilon) = f_E(-\\varepsilon)\\). Because we have an \\(e^{h\\varepsilon^2}\\), then negative or positive errors of the same magnitude will appear with the same likelihood5.\nWe assumed that larger errors are less likely than smaller errors. Well, this assumption is only true for \\(C_1 &lt; 0\\), so let’s make this explicit and build a negative sign directly into \\(f_E\\). So, \\[\nf_E(\\varepsilon|C) = Ae^{-\\frac{C}{2}\\varepsilon^2}.\n\\]\n\nFinally, we see that our likelihood function, \\(\\ell\\), will be built from this \\(f\\) which has these two properties: 1) that errors are symmetric around 0, and 2) that smaller errors are more likely than larger errors.\n\n\n10.1.5 Integrating the Likelihood to Find a Distribution\nAs we can see in the form of \\(f_E\\) above, this function will always be non-negative. So, as we’ve done before, to transition from likelihood to a probability function, we will marginalize this function to find the values of \\(A\\) and \\(C\\) which ensure that the total probability for this error distribution is equal to 1. But, because we have only one equation and two unknowns, we will solve for \\(A\\) as a function of \\(C\\) That is, we need to solve for \\(A_C\\) so that \\[\n\\int_{\\mathcal{S}(\\varepsilon)} dF(\\varepsilon|C) = \\int_{-\\infty}^{\\infty} f_E(\\varepsilon|C) d\\varepsilon = \\int_{-\\infty}^{\\infty} A_Ce^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon =  1.\n\\]\nThis integral will require quite a few substeps and substitutions to solve. We are solving for \\(A\\) as a function of \\(C\\) that will allow this integral to converge to 1. Let’s begin by changing this single integral to a double integral, and then modifying the bounds of the integration. \\[\n\\begin{aligned}\n1 &= \\int_{-\\infty}^{\\infty} A_Ce^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n\\Longrightarrow 1^2 &= \\left[ \\int_{-\\infty}^{\\infty} A_Ce^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right] \\times \\left[ \\int_{-\\infty}^{\\infty} A_Ce^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right] \\\\\n&= \\left[ \\int_{-\\infty}^{\\infty} A_Ce^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right] \\times \\left[ \\int_{-\\infty}^{\\infty} A_Ce^{-\\frac{C}{2}\\varphi^2} d\\varphi \\right] \\\\\n&= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} A^2_C e^{-\\frac{C}{2}\\varepsilon^2} e^{-\\frac{C}{2}\\varphi^2} d\\varepsilon d\\varphi \\\\\n&= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} A^2_C e^{-\\frac{C}{2} \\left( \\varepsilon^2 + \\varphi^2 \\right)} d\\varepsilon d\\varphi \\\\\n&\\qquad\\text{\\emph{Recall that }} f_E \\text{\\emph{ is symmetric around 0...}} \\\\\n&= \\int_{\\varphi = 0}^{\\infty} 2 \\int_{\\varepsilon = 0}^{\\infty} 2A^2_C e^{-\\frac{C}{2} \\left( \\varepsilon^2 + \\varphi^2 \\right)} d\\varepsilon d\\varphi \\\\\n&= 4A^2_C \\int_{\\varphi = 0}^{\\infty} \\int_{\\varepsilon = 0}^{\\infty} e^{-\\frac{C}{2} \\left( \\varepsilon^2 + \\varphi^2 \\right)} d\\varepsilon d\\varphi.\n\\end{aligned}\n\\]\nNow, we will make our first substitution. Let \\(\\varphi = t\\varepsilon\\), so \\(d\\varphi = \\varepsilon dt\\). Because this is a linear function, the bounds of integration for \\(t\\) will be equivalent to those for \\(\\varphi\\). \\[\n\\begin{aligned}\n1^2 &= 4A^2_C \\int_{\\varphi = 0}^{\\infty} \\int_{\\varepsilon = 0}^{\\infty} e^{-\\frac{C}{2} \\left( \\varepsilon^2 + \\varphi^2 \\right)} d\\varepsilon d\\varphi \\\\\n&= 4A^2_C \\int_{[t] = 0}^{\\infty} \\int_{\\varepsilon = 0}^{\\infty} e^{-\\frac{C}{2} \\left( \\varepsilon^2 + [t\\varepsilon]^2 \\right)} d\\varepsilon [\\varepsilon dt] \\\\\n&= 4A^2_C \\int_{t = 0}^{\\infty} \\int_{\\varepsilon = 0}^{\\infty} e^{-\\frac{C}{2} \\varepsilon^2 (1 + t^2)} \\varepsilon d\\varepsilon dt.\n\\end{aligned}\n\\]\nIt took a bit of work, but we finally have an integrand that looks like \\(ve^{v^2}dv\\), which means that we can use \\(u\\)-substitution. Hence, we let \\[\nu = -\\frac{C}{2} \\varepsilon^2 (1 + t^2) \\Rightarrow du = -C\\varepsilon (1 + t^2) d\\varepsilon \\Rightarrow -\\frac{du}{C(1 + t^2)} = \\varepsilon d\\varepsilon.\n\\] Our bounds of integration do change for this transformation: when \\(\\varepsilon = 0, u = 0\\), but when \\(\\varepsilon \\to \\infty, u \\to -\\infty\\). For these steps, we will also flip the bounds of integration, and, at the last integral step, recognize the derivative of the arctangent function (which we covered in the Formal Foundations chapter with the review section on trigonometry): \\[\n\\begin{aligned}\n1^2 &= 4A^2_C \\int_{t = 0}^{\\infty} \\int_{\\varepsilon = 0}^{\\infty} e^{-\\frac{C}{2} \\varepsilon^2 (1 + t^2)} \\varepsilon d\\varepsilon dt \\\\\n&= 4A^2_C \\int_{t = 0}^{\\infty} \\int_{[u] = 0}^{-\\infty} e^{[u]} \\left[ -\\frac{du}{C(1 + t^2)} \\right] dt \\\\\n&\\qquad\\text{\\emph{Flip bounds of integration...}} \\\\\n&= 4A^2_C \\int_{t = 0}^{\\infty} \\int_{u = -\\infty}^0 -e^{u} \\left[ -\\frac{du}{C(1 + t^2)} \\right] dt \\\\\n&\\qquad\\text{\\emph{Separable integrals...}} \\\\\n&= 4A^2_C \\int_{t = 0}^{\\infty} \\left[ \\frac{1}{C(1 + t^2)} \\right] \\left( \\int_{u = -\\infty}^0 e^{u} du \\right) dt \\\\\n&= 4A^2_C \\int_{t = 0}^{\\infty} \\left[ \\frac{1}{C(1 + t^2)} \\right] \\left( \\lim_{k\\to -\\infty} \\left[ e^{u} \\right]_{u = k}^0 \\right) dt \\\\\n&= 4A^2_C \\int_{t = 0}^{\\infty} \\left[ \\frac{1}{C(1 + t^2)} \\right] \\left[ e^{[0]} - \\lim_{k\\to -\\infty} e^{[k]} \\right] dt \\\\\n&\\qquad\\text{\\emph{Recognize trigonometric derivative...}} \\\\\n&= \\frac{4}{C} A^2_C \\int_{t = 0}^{\\infty} \\left[ \\frac{1}{1 + t^2} \\right] [1] dt \\\\\n&= \\frac{4}{C} A^2_C \\left[ \\lim_{k\\to\\infty} \\arctan(t) \\right]_0^k \\\\\n&= \\frac{4}{C} A^2_C \\left[ \\lim_{k\\to\\infty} \\arctan(k) - \\arctan(0) \\right] \\\\\n&\\qquad\\text{\\emph{Horizontal asymptote...}} \\\\\n&= \\frac{4}{C} A^2_C \\left[ \\frac{\\pi}{2} - 0 \\right] \\\\\n\\Longrightarrow 1 &= \\frac{2\\pi}{C} A^2_C \\\\\n&\\qquad\\text{\\emph{Solve for }} A_C \\\\\n\\Longrightarrow \\frac{C}{2\\pi} &= A^2_C \\\\\n\\Longrightarrow \\sqrt{\\frac{C}{2\\pi}} &= A_C.\n\\end{aligned}\n\\]\nTherefore, the normalizing constant to make \\(\\ell\\) a probability function (in terms of some parameter \\(C\\)) is \\(\\sqrt{C/(2\\pi)}\\). Thus, the error distribution is \\[\nf_E(\\varepsilon|C) = \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#deriving-the-normal-distribution-from-the-error-distribution",
    "href": "chapters/normal_20250310.html#deriving-the-normal-distribution-from-the-error-distribution",
    "title": "10  The Normal Distribution",
    "section": "10.2 Deriving the Normal Distribution from the Error Distribution",
    "text": "10.2 Deriving the Normal Distribution from the Error Distribution\nIn the previous gargantuan section, we finally derived the error distribution. However, 1) it is not parametrised using the “variance” parameter we expect, and 2) it does not include a measure of center. For the Normal Distribution, \\[\n\\text{Var}[\\varepsilon] = \\sigma^2 = \\mathbb{E}[\\varepsilon^2] - [\\mathbb{E}[\\varepsilon]]^2.\n\\]\n\n10.2.1 Expectation of the Normal Distribution\nFor the expectation of \\(\\varepsilon\\), by assumption we have that this is 0. We can also show this directly. Because \\(f_E\\) is symmetric around \\(\\varepsilon = 0\\), this implies that \\[\n\\begin{aligned}\n\\mathbb{E}[\\varepsilon] &= \\int_{\\mathcal{S}(\\varepsilon)} \\varepsilon dF(\\varepsilon|C) \\\\\n&= \\int_{-\\infty}^{\\infty} \\varepsilon \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= \\int_{-\\infty}^0 \\varepsilon \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon + \\int_0^{\\infty} \\varepsilon \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= -\\int_0^{\\infty} \\varepsilon \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon + \\int_0^{\\infty} \\varepsilon \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= 0.\n\\end{aligned}\n\\]\nTherefore, \\[\n\\text{Var}[\\varepsilon] = \\sigma^2 = \\mathbb{E}[\\varepsilon^2] - [\\mathbb{E}[\\varepsilon]]^2 = \\mathbb{E}[\\varepsilon^2] - [0]^2 = \\mathbb{E}[\\varepsilon^2],\n\\] so the second moment is the variance parameter.\n\n\n10.2.2 The Second Moment\nBecause we know that the second theoretical moment must be equal to \\(\\sigma^2\\), we can finally solve for \\(C\\) as a function of \\(\\sigma^2\\). First, we will use the property that \\(f_E\\) is symmetric to simplify the bounds of integration. So, \\[\n\\begin{aligned}\n\\mathbb{E}[\\varepsilon^2] &= \\int_{\\mathcal{S}(\\varepsilon)} \\varepsilon^2 dF(\\varepsilon|C) \\\\\n&= \\int_{-\\infty}^{\\infty} \\varepsilon^2 \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= \\sqrt{\\frac{C}{2\\pi}} \\int_{-\\infty}^{\\infty} \\varepsilon^2 e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\int_0^{\\infty} \\varepsilon^2 e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\int_0^{\\infty} [\\varepsilon] \\left[ \\varepsilon e^{-\\frac{C}{2}\\varepsilon^2} \\right] d\\varepsilon.\n\\end{aligned}\n\\] Now we will use Integration by Parts to break the integral into smaller pieces. We will let \\(u = \\varepsilon \\Rightarrow du = d\\varepsilon\\) and \\(dv = \\varepsilon e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon\\). However we will add the substitution that \\(w = -\\frac{C}{2}\\varepsilon^2 \\Rightarrow dw = -C\\varepsilon d\\varepsilon\\), so \\(-\\frac{1}{C}dw = \\varepsilon d\\varepsilon\\). Therefore, our sub-integral of the \\(dv\\) term is \\[\n\\begin{aligned}\ndv &= \\varepsilon e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\\\\n&= e^{-\\frac{C}{2}\\varepsilon^2} \\varepsilon d\\varepsilon \\\\\n&= e^{[w]}\\left[ -\\frac{1}{C}dw \\right] \\\\\n\\Longrightarrow \\int dv &= -\\frac{1}{C} \\int e^wdw \\\\\n\\Longrightarrow v &= -\\frac{1}{C} e^w \\\\\n&= -\\frac{1}{C} e^{-\\frac{C}{2}\\varepsilon^2}.\n\\end{aligned}\n\\] Therefore, we substitute these values: \\(u = \\varepsilon\\), \\(v = -\\frac{1}{C} e^{-\\frac{C}{2}\\varepsilon^2}\\), and \\(du = d\\varepsilon\\). So we have \\[\n\\begin{aligned}\n\\mathbb{E}[\\varepsilon^2] &= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ \\int_0^{\\infty} [\\varepsilon] \\left[ \\varepsilon e^{-\\frac{C}{2}\\varepsilon^2} \\right] d\\varepsilon \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ [u][v] - \\int_0^{\\infty} [v][du] \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ \\lim_{k\\to\\infty} [\\varepsilon] \\left[ -\\frac{1}{C} e^{-\\frac{C}{2}\\varepsilon^2} \\right]_0^k - \\int_0^{\\infty} \\left[ -\\frac{1}{C} e^{-\\frac{C}{2}\\varepsilon^2} \\right] [d\\varepsilon] \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ \\lim_{k\\to\\infty} -\\frac{k}{C} e^{-\\frac{C}{2}k^2} - \\left( -\\frac{0}{C} e^{-\\frac{C}{2}0^2} \\right) + \\int_0^{\\infty} \\frac{1}{C} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ -\\lim_{k\\to\\infty} \\frac{k}{Ce^{\\frac{C}{2}k^2}} + 0 + \\frac{1}{2C} \\int_{-\\infty}^{\\infty} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right\\}.\n\\end{aligned}\n\\] We will evaluate the limit on the left via L’Hospital’s Rule (because this limit has the indeterminant form of \\(\\infty/\\infty\\)). The integral on the right is the kernel of the error distribution. Thus, \\[\n\\begin{aligned}\n\\mathbb{E}[\\varepsilon^2] &= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ -\\lim_{k\\to\\infty} \\frac{k}{Ce^{\\frac{C}{2}k^2}} + \\frac{1}{2C} \\int_{-\\infty}^{\\infty} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ -\\lim_{k\\to\\infty} \\frac{\\frac{d}{dk} k}{\\frac{d}{dk} Ce^{\\frac{C}{2}k^2}} + \\frac{1}{2C} \\sqrt{\\frac{2\\pi}{C}} \\int_{-\\infty}^{\\infty} \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ -\\lim_{k\\to\\infty} \\frac{1}{ Ce^{\\frac{C}{2}k^2}(Ck)} + \\frac{1}{2C} \\sqrt{\\frac{2\\pi}{C}} \\int_{-\\infty}^{\\infty} \\sqrt{\\frac{C}{2\\pi}} e^{-\\frac{C}{2}\\varepsilon^2} d\\varepsilon \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ -\\frac{1}{ \\infty} + \\frac{1}{2C} \\sqrt{\\frac{2\\pi}{C}} \\int_{-\\infty}^{\\infty} f_E(\\varepsilon|C) d\\varepsilon \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{ 0 + \\frac{1}{2C} \\sqrt{\\frac{2\\pi}{C}} [1] \\right\\} \\\\\n&= 2\\sqrt{\\frac{C}{2\\pi}} \\left\\{\\frac{1}{2C} \\sqrt{\\frac{2\\pi}{C}} \\right\\} \\\\\n&= \\frac{1}{C} \\\\\n&= \\sigma^2.\n\\end{aligned}\n\\]\n\n\n10.2.3 The Modern Form of the Normal Distribution\nThus, because \\(C = \\frac{1}{\\sigma^2}\\) we can finally parametrise our error distribution in terms of the variance: \\[\nf_E(\\varepsilon|\\sigma^2) = \\sqrt{\\frac{\\left[\\frac{1}{\\sigma^2}\\right]}{2\\pi}} e^{-\\frac{\\left[\\frac{1}{\\sigma^2}\\right]}{2}\\varepsilon^2} = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{\\varepsilon^2}{2\\sigma^2}}.\n\\] The last step is to undo one of the very first substitutions we made, that \\(\\varepsilon = x - m\\), where \\(m\\) was the true value to be measured. In modern notation, we use \\(\\mu\\) instead of \\(m\\), so \\[\nf_X(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}},\n\\] which is our expected modern form of the Normal Distribution.6",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#example-random-samples",
    "href": "chapters/normal_20250310.html#example-random-samples",
    "title": "10  The Normal Distribution",
    "section": "10.3 Example Random Samples",
    "text": "10.3 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxStandard &lt;- rnorm(n = 1000, mean = 0, sd = 1)\nsamplesStd_ls &lt;- list(\n  n5    = xStandard[1:5],\n  n30   = xStandard[1:30],\n  n60   = xStandard[1:60],\n  n1000 = xStandard\n)\n\nxShift &lt;- rnorm(n = 1000, mean = 1, sd = 2)\nsamplesShifted_ls &lt;- list(\n  n5    = xShift[1:5],\n  n30   = xShift[1:30],\n  n60   = xShift[1:60],\n  n1000 = xShift\n)\n\nrange_num &lt;- range(c(xStandard, xShift))\n\nrm(xSymm, xSkew)\nWarning in rm(xSymm, xSkew): object 'xSymm' not found\nWarning in rm(xSymm, xSkew): object 'xSkew' not found\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesStd_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesShifted_ls$n5, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesShifted_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesShifted_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesShifted_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/normal_20250310.html#show-that-this-is-a-distribution",
    "title": "10  The Normal Distribution",
    "section": "10.4 Show that this is a Distribution",
    "text": "10.4 Show that this is a Distribution\nAfter the absolutely Herculean task to derive this distribution, we have that it is a proper distribution by construction. It is nonnegative for all values of \\(x \\in \\mathbb{R}\\), and we constructed it so that \\(\\int_{\\mathcal{S}(x)} dF(x|\\mu, \\sigma^2) = 1\\).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#derive-the-moment-generating-function",
    "href": "chapters/normal_20250310.html#derive-the-moment-generating-function",
    "title": "10  The Normal Distribution",
    "section": "10.5 Derive the Moment Generating Function",
    "text": "10.5 Derive the Moment Generating Function\nAs we find the expectation of \\(e^{tx}\\), we will start with a \\(w\\)-substition as follows (I’m using \\(w\\) because \\(u\\) looks similar to \\(\\mu\\) as I get more exhausted). Let \\(w = \\frac{x - \\mu}{\\sqrt{\\sigma^2}}\\), so \\(dw = \\frac{1}{\\sqrt{\\sigma^2}} dx \\Rightarrow \\sqrt{\\sigma^2} dw = dx\\), and \\(x = w\\sqrt{\\sigma^2} + \\mu\\). The bounds of integration will not change. Now let’s begin our integration: \\[\n\\begin{aligned}\nM_x(t) &= \\int_{\\mathcal{S}(x)} e^{tx} dF(x|\\mu, \\sigma^2) \\\\\n&= \\int_{x = -\\infty}^{\\infty} e^{tx} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} dx \\\\\n&= \\int_{w = -\\infty}^{\\infty} e^{t[w\\sqrt{\\sigma^2} + \\mu]} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2}[w]^2} [\\sqrt{\\sigma^2} dw] \\\\\n&= \\int_{-\\infty}^{\\infty} e^{tw\\sqrt{\\sigma^2}}e^{t\\mu} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}w^2} dw \\\\\n&= \\frac{e^{t\\mu}}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2}w^2 + tw\\sqrt{\\sigma^2}} dw.\n\\end{aligned}\n\\]\nNotice that this yields a function with \\(w^2\\) and \\(w\\) in the exponent. We will use the technique of Completing the Square7 from preliminary algebra to factor this polynomial back into some function of \\(w\\) that is squared. Let’s pull out the exponent and work with it directly: \\[\n\\begin{aligned}\n\\text{Exponent} &= -\\frac{1}{2}w^2 + tw\\sqrt{\\sigma^2} \\\\\n&= -\\frac{1}{2}\\left\\{ w^2 - 2wt\\sqrt{\\sigma^2} \\right\\} \\\\\n&= -\\frac{1}{2}\\left\\{ w^2 - 2wt\\sqrt{\\sigma^2} + \\left[t\\sqrt{\\sigma^2}\\right]^2 - \\left[t\\sqrt{\\sigma^2}\\right]^2 \\right\\} \\\\\n&= -\\frac{1}{2}\\left\\{ \\left( w^2 - 2wt\\sqrt{\\sigma^2} + \\left[t\\sqrt{\\sigma^2}\\right]^2 \\right) - t^2\\sigma^2 \\right\\} \\\\\n&= -\\frac{1}{2}\\left\\{ \\left( w - t\\sqrt{\\sigma^2} \\right)^2 - t^2\\sigma^2 \\right\\} \\\\\n&= -\\frac{1}{2} \\left( w - t\\sqrt{\\sigma^2} \\right)^2 + \\frac{1}{2} t^2\\sigma^2 \\\\\n\\end{aligned}\n\\] Therefore, we continue our integration. We will quickly recognise the integral of the Normal Distribution with mean parameter \\(t\\sqrt{\\sigma^2}\\) and variance parameter \\(1\\). That is, \\[\n\\begin{aligned}\nM_x(t) &= \\frac{e^{t\\mu}}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2}w^2 + tw\\sqrt{\\sigma^2}} dw \\\\\n&= \\frac{e^{t\\mu}}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{-\\frac{1}{2} \\left( w - t\\sqrt{\\sigma^2} \\right)^2 + \\frac{1}{2} t^2\\sigma^2} dw \\\\\n&= e^{t\\mu} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left( w - t\\sqrt{\\sigma^2} \\right)^2} e^{\\frac{1}{2} t^2\\sigma^2} dw \\\\\n&= e^{t\\mu + \\frac{1}{2} t^2\\sigma^2} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left( w - t\\sqrt{\\sigma^2} \\right)^2} dw \\\\\n&= e^{t\\mu + \\frac{1}{2} t^2\\sigma^2} \\int_{-\\infty}^{\\infty} \\mathcal{N}(w|t\\sqrt{\\sigma^2}, 1) dw \\\\\n&= e^{t\\mu + \\frac{1}{2} t^2\\sigma^2} [1] \\\\\n&= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\\\\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#method-of-moments-estimates-from-observed-data",
    "href": "chapters/normal_20250310.html#method-of-moments-estimates-from-observed-data",
    "title": "10  The Normal Distribution",
    "section": "10.6 Method of Moments Estimates from Observed Data",
    "text": "10.6 Method of Moments Estimates from Observed Data\nLet’s generate some random data. Let’s generate \\(n = 7\\) random IQ scores, which have mean 100 and standard deviation 15.8\n\n\nCode\nset.seed(20150516)\nIQmu &lt;- 100\nIQvar &lt;- 15^2\nrIQ_num &lt;- rnorm(n = 7, mean = IQmu, sd = sqrt(IQvar))\n\n\nThe 7 IQ scores are 116.4, 101.9, 95.1, 96.9, 78.3, 93.9, 98.1.\n\n10.6.1 \\(\\mathbb{E}[k]\\)\nThese derivatives are rather straightforward applications of the chain rule: \\[\n\\begin{aligned}\nM_x(t) &= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\\\\n\\Longrightarrow M^{\\prime}_x(t) &= \\frac{\\partial}{\\partial t} \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\\\\n&= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\frac{\\partial}{\\partial t} \\left( t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right) \\\\\n&= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\left( \\mu + t\\sigma^2 \\right) \\\\\n\\Longrightarrow M^{\\prime}_x(0) &= \\exp\\left\\{ [0]\\mu + \\frac{1}{2} [0]^2\\sigma^2 \\right\\} \\left( \\mu + [0]\\sigma^2 \\right) \\\\\n&= \\exp\\left\\{ 0 \\right\\} \\left( \\mu \\right) \\\\\n&= \\mu \\\\\n&= \\mathbb{E}[x].\n\\end{aligned}\n\\]\n\n\n10.6.2 \\(\\mathbb{E}[k^2]\\) and \\(\\text{Var}[k]\\)\nSimilarly, by the product rule and the chain rule (again), we have \\[\n\\begin{aligned}\nM^{\\prime}_x(t) &= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\left( \\mu + t\\sigma^2 \\right) \\\\\n\\Longrightarrow M^{\\prime\\prime}_x(t) &= \\frac{\\partial}{\\partial t} \\left[ \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\left( \\mu + t\\sigma^2 \\right) \\right] \\\\\n&= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\frac{\\partial}{\\partial t} \\left( \\mu + t\\sigma^2 \\right) + \\left( \\mu + t\\sigma^2 \\right) \\frac{\\partial}{\\partial t} \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\\\\n&= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\sigma^2 + \\left( \\mu + t\\sigma^2 \\right) \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\left( \\mu + t\\sigma^2 \\right) \\\\\n&= \\exp\\left\\{ t\\mu + \\frac{1}{2} t^2\\sigma^2 \\right\\} \\left[ \\sigma^2 + \\left( \\mu + t\\sigma^2 \\right)^2 \\right] \\\\\n\\Longrightarrow M^{\\prime\\prime}_x(0) &= \\exp\\left\\{ [0]\\mu + \\frac{1}{2} [0]^2\\sigma^2 \\right\\} \\left[ \\sigma^2 + \\left( \\mu + [0]\\sigma^2 \\right)^2 \\right] \\\\\n&= \\exp\\left\\{ 0 \\right\\} \\left[ \\sigma^2 + \\mu^2 \\right] \\\\\n&= \\sigma^2 + \\mu^2 \\\\\n&= \\mathbb{E}[x^2].\n\\end{aligned}\n\\] So, unsurprisingly, \\[\n\\text{Var}[x] = \\mathbb{E}[x^2] - [\\mathbb{E}[x]]^2 = [\\sigma^2 + \\mu^2] - [\\mu]^2 = \\sigma^2.\n\\]\n\n\n10.6.3 Solving the System\nThis bit is quite anti-climactic. The system to “solve” is \\[\n\\mu = \\bar{x};\\ \\sigma^2 = s^2.\n\\] Et voilà! We’re done.9",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#maximum-likelihood-estimators",
    "href": "chapters/normal_20250310.html#maximum-likelihood-estimators",
    "title": "10  The Normal Distribution",
    "section": "10.7 Maximum Likelihood Estimators",
    "text": "10.7 Maximum Likelihood Estimators\nIn comparison to the MGF section, this one will require a lot more work, and we will have to apply the Saddlepoint Test that we learned in the previous “Formal Foundations” chapter. So, for parameters \\(\\mu\\) and \\(\\sigma^2\\) (not \\(\\sigma\\)), we find the log-likelihood in our traditional way: \\[\n\\begin{aligned}\n\\mathcal{L}(\\mu,\\sigma^2|\\textbf{x}) &= \\prod_{i = 1}^n f(x_i|\\mu, \\sigma^2) \\\\\n&= \\prod_{i = 1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}} \\\\\n&= \\prod_{i = 1}^n (2\\pi)^{-1/2} (\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2}(x_i - \\mu)^2} \\\\\n&= (2\\pi)^{-n/2} (\\sigma^2)^{-n/2} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2 \\right\\} \\\\\n\\Longrightarrow \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\log\\left( (2\\pi)^{-n/2} (\\sigma^2)^{-n/2} \\exp\\left\\{-\\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2 \\right\\} \\right) \\\\\n&= -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2.\n\\end{aligned}\n\\]\nNow, we have a function with two parameters, \\(\\mu\\) and \\(\\sigma^2\\). We will then have two first-order partial derivatives.\n\n10.7.1 Candidate MLE for \\(\\mu\\)\nLet’s first take the derivative with respect to \\(\\mu\\): \\[\n\\begin{aligned}\n\\ell(\\mu,\\sigma^2|\\textbf{x}) &= -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2 \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\mu} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{\\partial}{\\partial\\mu} \\left\\{ -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2 \\right\\} \\\\\n&= 0 - 0 - \\frac{1}{2\\sigma^2} \\frac{\\partial}{\\partial\\mu} \\sum_{i = 1}^n (x_i^2 - 2x_i\\mu + \\mu^2) \\\\\n&= -\\frac{1}{2\\sigma^2} \\sum_{i = 1}^n \\frac{\\partial}{\\partial\\mu} (x_i^2 - 2x_i\\mu + \\mu^2) \\\\\n&= -\\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (0 - 2x_i + 2\\mu) \\\\\n&= -\\frac{1}{2\\sigma^2} (-2n\\bar{x} + 2n\\mu) \\\\\n&= \\frac{n}{\\sigma^2} (\\bar{x} - \\mu) \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{n}{\\sigma^2} (\\bar{x} - \\hat{\\mu}_*) \\\\\n\\Longrightarrow \\hat{\\mu}_* &= \\bar{x}.\n\\end{aligned}\n\\] Notice that I haven’t declared that this \\(\\hat{\\mu}_*\\) to be \\(\\hat{\\mu}_{MLE}\\). We still have to find our candidate value for \\(\\hat{\\sigma}^2_*\\) and then we have to check the second derivatives. So I’m leaving it as a “candidate” value for now.\n\n\n10.7.2 Candidate MLE for \\(\\sigma^2\\)\nSimilarly, we take the derivative with respect to \\(\\sigma^2\\) \\[\n\\begin{aligned}\n\\ell(\\mu,\\sigma^2|\\textbf{x}) &= -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2 \\\\\n\\Longrightarrow \\frac{\\partial}{\\partial\\sigma^2} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{\\partial}{\\partial\\sigma^2} \\left\\{ -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (x_i - \\mu)^2 \\right\\} \\\\\n&= 0 -\\frac{n}{2}\\frac{1}{\\sigma^2} - \\frac{1}{2} \\left[ \\frac{\\partial}{\\partial\\sigma^2} \\frac{1}{\\sigma^2} \\right] \\sum_{i = 1}^n (x_i - \\mu)^2 \\\\\n&= -\\frac{n}{2\\sigma^2} - \\frac{1}{2} \\left[ -\\frac{1}{(\\sigma^2)^2} \\right] \\sum_{i = 1}^n (x_i - \\mu)^2 \\\\\n&= \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\sigma^2} \\\\\n\\Longrightarrow 0 &\\overset{\\text{set}}{=} \\frac{1}{2(\\hat\\sigma^2_*)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\hat\\sigma^2_*} \\\\\n\\Longrightarrow 2(\\hat\\sigma^2_*)^2 \\times 0 &= 2(\\hat\\sigma^2_*)^2 \\left[ \\frac{1}{2(\\hat\\sigma^2_*)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\hat\\sigma^2_*} \\right] \\\\\n\\Longrightarrow 0 &= \\sum_{i = 1}^n (x_i - \\mu)^2 - n\\hat\\sigma^2_* \\\\\n\\Longrightarrow n\\hat\\sigma^2_* &= \\sum_{i = 1}^n (x_i - \\mu)^2 \\\\\n\\Longrightarrow \\hat\\sigma^2_* &= \\frac{1}{n}\\sum_{i = 1}^n (x_i - \\mu)^2.\n\\end{aligned}\n\\] So, we found a candidate MLE for \\(\\sigma^2\\), but it depends on the unknown parameter \\(\\mu\\). Also, we still don’t know that these two candidates actually maximise the likelihood function. We need the Hessian (matrix of second-order partial derivatives) for that.\n\n\n10.7.3 The Hessian Matrix and its Determinant\nAs we alluded to previously (and spent an entire “Formal Foundations” section on), we will use the Saddlepoint Test to find out under what conditions these candidate values maximise the likelihood. Let’s find each of the second-order partial derivatives first. I’m going to start with the second derivative with respect to \\(\\sigma^2\\) (and we notice that our candidate MLE for \\(\\sigma^2\\) shows up at the end): \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\sigma^2} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\sigma^2} \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial(\\sigma^2)^2} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{\\partial}{\\partial\\sigma^2} \\left[ \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\sigma^2} \\right] \\\\\n&= -\\frac{1}{(\\sigma^2)^3} \\frac{n}{n} \\sum_{i = 1}^n (x_i - \\mu)^2 + \\frac{n}{2(\\sigma^2)^2} \\\\\n&= -\\frac{n}{(\\sigma^2)^2} \\left[ \\frac{1}{\\sigma^2} \\left( \\frac{1}{n}\\sum_{i = 1}^n (x_i - \\mu)^2 \\right) - \\frac{1}{2} \\right] \\\\\n&= -\\frac{n}{(\\sigma^2)^2} \\left[ \\frac{\\hat\\sigma^2_*}{\\sigma^2} - \\frac{1}{2} \\right].\n\\end{aligned}\n\\]\nNow, we will take the crossing partial derivatives: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\sigma^2} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\sigma^2} \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial\\mu \\partial\\sigma^2} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{\\partial}{\\partial\\mu} \\left[ \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n (x_i - \\mu)^2 - \\frac{n}{2\\sigma^2} \\right] \\\\\n&= \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n \\frac{\\partial}{\\partial\\mu} (x_i - \\mu)^2 - [0] \\\\\n&= \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n \\frac{\\partial}{\\partial\\mu} (x_i^2 - 2x_i\\mu + \\mu^2) \\\\\n&= \\frac{1}{2(\\sigma^2)^2} \\sum_{i = 1}^n (-2x_i + 2\\mu) \\\\\n&= \\frac{1}{(\\sigma^2)^2} (-n\\bar{x} + n\\mu) \\\\\n&= -\\frac{n}{(\\sigma^2)^2} (\\bar{x} - \\mu).\n\\end{aligned}\n\\] The other crossing partial should be equal to this one, but let’s confirm this: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\mu} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{n}{\\sigma^2} (\\bar{x} - \\mu) \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial\\sigma^2 \\partial\\mu} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{\\partial}{\\partial\\sigma^2} \\frac{n}{\\sigma^2} (\\bar{x} - \\mu) \\\\\n&= -\\frac{n}{(\\sigma^2)^2} (\\bar{x} - \\mu).\n\\end{aligned}\n\\] The last partial derivative we need is with respect to \\(\\mu\\) a second time: \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\mu} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{n}{\\sigma^2} (\\bar{x} - \\mu) \\\\\n\\Longrightarrow \\frac{\\partial^2}{\\partial\\mu^2} \\ell(\\mu,\\sigma^2|\\textbf{x}) &= \\frac{\\partial}{\\partial\\mu} \\frac{n}{\\sigma^2} (\\bar{x} - \\mu) \\\\\n&= \\frac{n}{\\sigma^2}(-1) \\\\\n&= -\\frac{n}{(\\sigma^2)^2} (\\sigma^2).\n\\end{aligned}\n\\] This last step might seem counterproductive, but notice that all three of the other second-order partial derivatives had the same leading multiplier.\nNow we can make the Hessian Matrix: \\[\n\\textbf{H}[\\ell(\\mu,\\sigma^2|\\textbf{x})] = -\\frac{n}{(\\sigma^2)^2} \\begin{bmatrix}\n  \\sigma^2 & (\\bar{x} - \\mu) \\\\\n  (\\bar{x} - \\mu) & \\left( \\frac{\\hat\\sigma^2_*}{\\sigma^2} - \\frac{1}{2} \\right)\n\\end{bmatrix}\n\\] Let’s inspect this matrix quickly. We don’t know what the determinant will be (yet), but we do know that the diagonal entries are both conditionally positive. Obviously \\(\\sigma^2 &gt; 0\\). Also, as long as \\(\\hat\\sigma^2_* &gt; \\frac{1}{2}\\sigma^2\\), then the other diagonal component will be positive as well.10 This means that the negative sign outside has the same effect on both diagonal components. Thus, if the matrix \\(\\textbf{H}\\) has a positive determinant, then we are dealing with a function that is concave down, and we will have found a local maximum. But again, this is a big “if”.\nSo what about this determinant? Before we take the determinant of this matrix, we should recall that for some square matrix \\(\\textbf{A}\\in\\mathbb{R}_p,\\ \\det(k\\textbf{A}) = k^p\\det(\\textbf{A})\\)11. Thus, the Hessian Determinant for all parameter values is: \\[\n\\begin{aligned}\n\\det\\left( \\textbf{H}[\\ell(\\mu,\\sigma^2|\\textbf{x})] \\right) &= \\det \\left( -\\frac{n}{(\\sigma^2)^2} \\begin{bmatrix}\n  \\sigma^2 & (\\bar{x} - \\mu) \\\\\n  (\\bar{x} - \\mu) & \\left( \\frac{\\hat\\sigma^2_*}{\\sigma^2} - \\frac{1}{2} \\right)\n\\end{bmatrix} \\right) \\\\\n&= \\left( -\\frac{n}{(\\sigma^2)^2} \\right)^2 \\left[ \\sigma^2 \\left( \\frac{\\hat\\sigma^2_*}{\\sigma^2} - \\frac{1}{2} \\right) - (\\bar{x} - \\mu)^2 \\right] \\\\\n&= \\frac{n^2}{(\\sigma^2)^4} \\left[ \\sigma^2 \\left( \\frac{\\hat\\sigma^2_*}{\\sigma^2} - \\frac{1}{2} \\right) - (\\bar{x} - \\mu)^2 \\right].\n\\end{aligned}\n\\] Now, let’s substitute in the candidate MLEs, \\(\\hat\\mu_* = \\bar{x}\\) for \\(\\mu\\) and \\(\\hat\\sigma^2_* = \\frac{1}{n}\\sum_{i = 1}^n (x_i - \\mu)^2\\) for \\(\\sigma^2\\). Delightfully, this simplifies nicely: \\[\n\\begin{aligned}\n\\det\\left( \\textbf{H}[\\ell(\\mu = \\hat\\mu_*,\\sigma^2 = \\hat\\sigma^2_*|\\textbf{x})] \\right) &= \\frac{n^2}{[\\hat\\sigma^2_*]^4} \\left[ [\\hat\\sigma^2_*] \\left( \\frac{\\hat\\sigma^2_*}{[\\hat\\sigma^2_*]} - \\frac{1}{2} \\right) - (\\bar{x} - [\\hat\\mu_*])^2 \\right] \\\\\n&= \\frac{n^2}{(\\hat\\sigma^2_*)^4} \\left[ \\hat\\sigma^2_* \\left( 1 - \\frac{1}{2} \\right) - (\\bar{x} - \\bar{x})^2 \\right] \\\\\n&= \\frac{n^2}{(\\hat\\sigma^2_*)^4} \\left[ \\frac{1}{2}\\hat\\sigma^2_* \\right] \\\\\n&= \\frac{n^2}{2(\\hat\\sigma^2_*)^3} \\\\\n&&gt; 0.\n\\end{aligned}\n\\]\n\n\n10.7.4 MLEs Confirmed\nTherefore, we have confirmed that the Hessian Matrix has “volume” at the critical points, and we saw above that the diagonal elements of the Hessian will both be negative (under the assumption that \\(\\hat\\sigma^2_*\\) isn’t a completely awful estimator for \\(\\sigma^2\\)). Therefore, these critical points we found indeed maximize the likelihood function. Thus, \\[\n\\hat\\mu_{MLE} = \\bar{x};\\ \\hat\\sigma^2_{MLE} = \\frac{1}{n}\\sum_{i = 1}^n (x_i - \\mu)^2.\n\\] For our real data, we don’t know \\(\\mu\\), so these estimates are:\n\n\nCode\n(muHat &lt;- xBar &lt;- mean(rIQ_num))\n[1] 97.2\n(sigma2Hat &lt;- (1 / 7) * sum((rIQ_num - mean(rIQ_num))^2))\n[1] 109\n\n\nWe generated data with a mean of 100 and a variance of \\(15^2\\) (which is 225). Our sample estimates are a mean of 97.2 and a variance of 109.1 (standard deviation of 10.4). Notice that I did not use the standard var() function. Why? This function calculates the sample standard deviation, \\(s^2\\), which is not the same as the MLE for \\(\\sigma^2\\). In contrast, \\(s^2\\) for this data is\n\n\nCode\nvar(rIQ_num)\n[1] 127",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#exercises",
    "href": "chapters/normal_20250310.html#exercises",
    "title": "10  The Normal Distribution",
    "section": "10.8 Exercises",
    "text": "10.8 Exercises\n\n10.8.1 The Log-Normal Distribution\nIf we let \\(Y\\sim\\mathcal{N}(\\mu, \\sigma^2)\\), and we let \\(Y = \\log(X)\\), then \\(X = e^Y\\) has a Log-Normal distribution.\n\nUse a transformation to find the PDF of this distribution. What is its support?\nShow that \\(\\mathbb{E}[X] = e^{\\mu + \\frac{1}{2}\\sigma^2}\\).\nShow that \\(\\text{Var}[X] = e^{2\\mu + 2\\sigma^2} - e^{2\\mu + \\sigma^2}\\).\n\n\n\n10.8.2 Simulating Properties of \\(\\sigma^2_{MLE}\\)\nWhile we were inspecting the Hessian Matrix above, we saw that \\(\\frac{\\partial^2\\ell}{\\partial(\\sigma^2)^2}\\) includes the term \\(\\frac{\\hat\\sigma^2_*}{\\sigma^2} - \\frac{1}{2}\\). Create a simulation study that increases the sample size and calculates this expression. How large of a sample (from a Normal distribution) would be required to be reasonably confident that this expression is positive?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/normal_20250310.html#footnotes",
    "href": "chapters/normal_20250310.html#footnotes",
    "title": "10  The Normal Distribution",
    "section": "",
    "text": "https://wikipedia.org/wiki/Carl_Friedrich_Gauss↩︎\nThis upside down triangle is called the “Del” or “nabla” symbol, and it denotes the vector of all possible first-order partial derivatives (because we don’t know how many dimensions the parameter space has). See https://en.wikipedia.org/wiki/Del↩︎\nIt’s technically a linear function, but that term has too many definitions. We need the “linear function” that means “non-affine”. See https://en.wikipedia.org/wiki/Linear_map↩︎\nhttps://en.wikipedia.org/wiki/Affine_transformation↩︎\nNotice I said likelihood, because we are still dealing with the form of \\(\\ell\\), and we haven’t gotten to any probabilities yet.↩︎\nAt this point, you deserve a drink or a nap. Your choice.↩︎\nYou should remember this, but just in case: https://www.mathsisfun.com/algebra/completing-square.html↩︎\nIt may seem strange to you that I’m creating a “variance” object, and then immediately taking the square root of it. This is keeping in line with my derivation above that used \\(\\sigma^2\\) as a symbol, rather than the quantity \\(\\sigma\\) which has been squared. This will make our MLE work easier when we have to take the derivative with respect to the symbol \\(\\sigma^2\\).↩︎\nI have a severe complaint against Quarto for how I had to add the accent over the “a” here. The “default” fix to add a grave accent over a letter is to open the document in the visual editor, then insert the letter from a UTF library by the “Special Characters” option. From what I’ve found, there is currently no solution to add an accent over the letter by typing the traditional LaTeX command (\\`{a}).↩︎\nThere is a homework exercise related to this question.↩︎\nhttps://en.wikipedia.org/wiki/Determinant#Properties↩︎",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Normal Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html",
    "href": "chapters/students_t_20250310.html",
    "title": "11  The Student’s t Distribution",
    "section": "",
    "text": "11.1 Deriving the Distribution\nBefore we dive in, I’m going to offer a comment on the structure of this chapter and the related chapter on the Central \\(\\mathcal{F}\\) distribution. These two chapters will be shorter. I do not include sections on the Method of Moments or Maximum Likelihood Estimators. These distributions are both parametrised by sample sizes. When independent samples are observed, then the sample sizes are known, and there’s no reason to estimate these parameters. When the observed samples are not independent, then we violate the assumptions for data used in the MoM and ML estimators anyway. In short, I haven’t found any real examples in my personal work where estimating “unknown parameters” from these distributions has been needed.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#deriving-the-distribution",
    "href": "chapters/students_t_20250310.html#deriving-the-distribution",
    "title": "11  The Student’s t Distribution",
    "section": "",
    "text": "11.1.1 Formal Foundations: The \\(\\chi^2\\) Distribution\nDeriving the \\(\\chi^2\\) Distribution was a homework exercise from the chapter on the Gamma Distribution, as it is a special case of the Gamma Distribution. The probability function for this distribution is: \\[\nf_{\\chi^2}(x|\\nu) = \\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)} x^{\\nu/2 - 1} e^{-x/2},\\ \\nu\\in\\mathbb{N},\n\\] where \\(\\nu\\), the degrees of freedom parameter, is pronounced “new” (the Greek letter “nu”).\n\n\n11.1.2 Formal Foundations: A Special Value of \\(\\Gamma(z)\\)\nCuriously, the constant \\(\\Gamma(1/2)\\) appears periodically in derivations of statistical distributions which include the Gamma and Beta functions. We will find a closed form for this value from the definition of the Gamma Function: \\[\n\\begin{align}\n\\Gamma(z) &= \\int_0^{\\infty} t^{z - 1} e^{-t} dt \\\\\n\\Longrightarrow \\Gamma\\left(\\frac{1}{2}\\right) &= \\int_0^{\\infty} t^{1/2 - 1} e^{-t} dt \\\\\n&= \\int_0^{\\infty} \\frac{1}{t^{1/2}} e^{-t} dt.\n\\end{align}\n\\] Now we’re going to perform a substitution: let \\(u = t^{1/2}\\Rightarrow du = \\frac{1}{2}t^{-1/2}dt\\Rightarrow 2du = t^{-1/2}dt\\) and \\(t = u^2\\). Also, for this substitution, the bounds of integration do not change (\\(\\sqrt{0} = 0\\) and \\(\\sqrt\\infty \\to \\infty\\)). Thus, remembering that \\(e^{-x^2}\\) is symmetric around \\(x = 0\\), we have that \\[\n\\begin{align}\n\\Gamma\\left(\\frac{1}{2}\\right) &= \\int_0^{\\infty} \\frac{1}{t^{1/2}} e^{-t} dt \\\\\n&= \\int_{t = 0}^{\\infty} e^{-t} \\frac{1}{t^{1/2}} dt \\\\\n&= \\int_{u = 0}^{\\infty} e^{-[u^2]} [2du] \\\\\n&= 2\\int_{u = 0}^{\\infty} e^{-u^2} du \\\\\n&\\qquad\\text{\\emph{Symmetric function...}} \\\\\n&= \\int_{u = -\\infty}^{\\infty} e^{-u^2} du \\\\\n&\\qquad\\text{\\emph{Multiply by well-placed 1...}} \\\\\n&= \\int_{u = -\\infty}^{\\infty} e^{-\\frac{u^2}{2(1/2)}} du \\\\\n&\\qquad\\text{\\emph{Kernel of a Normal Distribution...}} \\\\\n&= \\sqrt{2\\pi\\left(\\frac{1}{2}\\right)} \\int_{u = -\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\left(\\frac{1}{2}\\right)}} e^{-\\frac{1}{2}\\frac{(u - 0)^2}{\\frac{1}{2}}} du \\\\\n&= \\sqrt{2\\pi\\left(\\frac{1}{2}\\right)} [1] \\\\\n&= \\sqrt{\\pi}.\n\\end{align}\n\\]\n\n\n11.1.3 The Joint Distribution\nThe Student’s \\(t\\) Distribution is a weighted average of the Normal Distribution and the square root of a \\(\\chi^2\\) Distribution, scaled by its degrees of freedom. We begin by considering a random variable with a Standard Normal Distribution, say \\(X \\sim \\mathcal{N}(\\mu = 0, \\sigma^2 = 1)\\). Also, we consider \\(Y \\sim \\chi^2_{\\nu} \\ni X \\perp Y\\). The joint distribution of \\(X\\) and \\(Y\\) is then \\[\nf(x, y|\\mu,\\sigma^2,\\nu) = \\left[ \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x^2} \\right] \\left[ \\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)} y^{\\nu/2 - 1} e^{-y/2} \\right].\n\\]\nWe will employ a bivariate transformation, then integrate out one of the parameters as a nuisance parameter. First, let \\(S = Y\\) be the nuisance parameter; \\(\\mathcal{S}(Y) = \\mathcal{S}(S) = \\mathbb{R}^+\\). then let \\(T = X\\sqrt{\\frac{\\nu}{Y}}\\), so \\(X = T\\sqrt{\\frac{S}{\\nu}}\\); \\(\\mathcal{S}(X) = \\mathcal{S}(T) = \\mathbb{R}\\). Therefore, the Jacobian Determinant is found by \\[\n\\begin{aligned}\n\\textbf{J} &= \\begin{bmatrix}\n  \\frac{\\partial X}{\\partial T} & \\frac{\\partial Y}{\\partial T} \\\\\n  \\frac{\\partial X}{\\partial S} & \\frac{\\partial Y}{\\partial S} \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  \\frac{\\partial}{\\partial T} T\\sqrt{\\frac{S}{\\nu}} & \\frac{\\partial}{\\partial T} S \\\\\n  \\frac{\\partial}{\\partial S} T\\sqrt{\\frac{S}{\\nu}} & \\frac{\\partial}{\\partial S} S \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  \\sqrt{\\frac{S}{\\nu}} & 0 \\\\\n  \\frac{T}{2} \\left(\\frac{S}{\\nu}\\right)^{-\\frac{1}{2}} \\frac{1}{\\nu} & 1 \\\\\n\\end{bmatrix} \\\\\n\\Longrightarrow \\det(\\textbf{J}) &= \\sqrt{\\frac{S}{\\nu}}(1) - (0)\\frac{T}{2} \\left(\\frac{S}{\\nu}\\right)^{-\\frac{1}{2}} \\\\\n&= \\sqrt{\\frac{S}{\\nu}}.\n\\end{aligned}\n\\] Therefore, the marginal distribution of \\(T\\) requires us to apply this transformation and then integrate out the nuisance parameter \\(S\\). Thus, \\[\n\\begin{aligned}\nf(t, s|\\nu) &= \\left\\{ \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left[ t\\sqrt{\\frac{s}{\\nu}} \\right]^2} \\right\\} \\left\\{ \\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)} [s]^{\\nu/2 - 1} e^{-[s]/2} \\right\\} \\left\\{ \\sqrt{\\frac{s}{\\nu}} \\right\\} \\\\\n\\Longrightarrow f(t|\\nu) &= \\int_{\\mathcal{S}(s)} \\left\\{ \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left[ t\\sqrt{\\frac{s}{\\nu}} \\right]^2} \\right\\} \\left\\{ \\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)} [s]^{\\nu/2 - 1} e^{-[s]/2} \\right\\} \\left\\{ \\sqrt{\\frac{s}{\\nu}} \\right\\} ds \\\\\n&= \\frac{1}{\\sqrt{2\\pi}} \\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)} \\frac{1}{\\sqrt\\nu} \\int_0^{\\infty} e^{-\\frac{1}{2} t^2\\frac{s}{\\nu}} e^{-\\frac{s}{2}} s^{\\frac{\\nu}{2} - 1} s^{\\frac{1}{2}} ds \\\\\n&\\qquad \\sqrt\\pi \\text{\\emph{ is a special value of the Gamma Function...}} \\\\\n&= \\frac{1}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\frac{1}{2^{\\frac{\\nu + 1}{2}}} \\frac{1}{\\sqrt\\nu} \\int_0^{\\infty} s^{\\frac{\\nu + 1}{2} - 1} e^{-s\\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)} ds.\n\\end{aligned}\n\\]\nNow, we should recognize the “guts” of this integral as a kernel of the Gamma Distribution with \\(\\alpha = \\frac{\\nu + 1}{2}\\) and \\(\\lambda = \\frac{t^2}{2\\nu} + \\frac{1}{2}\\). Hence, \\[\n\\begin{aligned}\nf(t|\\nu) &= \\frac{1}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\frac{1}{2^{\\frac{\\nu + 1}{2}}} \\frac{1}{\\sqrt\\nu} \\int_0^{\\infty} s^{\\frac{\\nu + 1}{2} - 1} e^{-s\\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)} ds \\\\\n&\\qquad\\text{\\emph{Multiply by a well-placed 1...}} \\\\\n&= \\frac{1}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\frac{1}{2^{\\frac{\\nu + 1}{2}}} \\frac{1}{\\sqrt\\nu} \\int_0^{\\infty} \\left[ \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)^{\\frac{\\nu + 1}{2}} } \\right] \\left[ \\frac{ \\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)^{\\frac{\\nu + 1}{2}} }{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) } \\right] s^{\\frac{\\nu + 1}{2} - 1} e^{-s\\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)} ds \\\\\n&= \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\frac{1}{ 2^{\\frac{\\nu + 1}{2}} \\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)^{\\frac{\\nu + 1}{2}} } \\frac{1}{\\sqrt\\nu} \\int_0^{\\infty} \\frac{ \\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)^{\\frac{\\nu + 1}{2}} }{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) } s^{\\frac{\\nu + 1}{2} - 1} e^{-s\\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)} ds \\\\\n&\\qquad\\text{\\emph{Integrate out the Gamma Distribution...}} \\\\\n&= \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\frac{1}{ 2^{\\frac{\\nu + 1}{2}} \\left( \\frac{t^2}{2\\nu} + \\frac{1}{2} \\right)^{\\frac{\\nu + 1}{2}} } \\frac{1}{\\sqrt\\nu} [1] \\\\\n&= \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\frac{ \\left( 1 + \\frac{t^2}{\\nu} \\right)^{-\\frac{\\nu + 1}{2}} }{ 2^{\\frac{\\nu + 1}{2}} \\left(\\frac{1}{2}\\right)^{\\frac{\\nu + 1}{2}}  } \\frac{1}{\\sqrt\\nu} \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) \\nu^{-\\frac{1}{2}} }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\left( 1 + \\frac{t^2}{\\nu} \\right)^{-\\frac{\\nu + 1}{2}},\n\\end{aligned}\n\\] which will be very close to the form of the Student’s \\(t\\) Distribution presented in most textbooks.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#example-random-samples",
    "href": "chapters/students_t_20250310.html#example-random-samples",
    "title": "11  The Student’s t Distribution",
    "section": "11.2 Example Random Samples",
    "text": "11.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\nxStd &lt;- rt(n = 500, df = 300)\nsamplesStd_ls &lt;- list(\n  n10  = xStd[1:10],\n  n30  = xStd[1:30],\n  n60  = xStd[1:60],\n  n500 = xStd\n)\n\nxDiffuse &lt;- rt(n = 500, df = 3)\nsamplesDiffuse_ls &lt;- list(\n  n10  = xDiffuse[1:10],\n  n30  = xDiffuse[1:30],\n  n60  = xDiffuse[1:60],\n  n500 = xDiffuse\n)\n\nrange_num &lt;- range(c(xStd, xDiffuse))\n\nrm(xStd, xDiffuse)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesStd_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesStd_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesDiffuse_ls$n500, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/students_t_20250310.html#show-that-this-is-a-distribution",
    "title": "11  The Student’s t Distribution",
    "section": "11.3 Show that this is a Distribution",
    "text": "11.3 Show that this is a Distribution\n\n11.3.1 The Function is Non-Negative\nLet’s consider the variable components of the Student’s \\(t\\) Distribution shown here: \\[\nf_T(t|\\nu) = \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) \\nu^{-\\frac{1}{2}} }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\left( 1 + \\frac{t^2}{\\nu} \\right)^{-\\frac{\\nu + 1}{2}}.\n\\] Recall that the transformation we defined was \\(T = X\\sqrt{\\frac{\\nu}{Y}}\\). We know that \\(Y\\in\\mathbb{R}^+\\) and \\(\\nu\\in\\mathbb{N}\\), so \\(\\sqrt{\\frac{\\nu}{Y}}\\in\\mathbb{R}^+\\). Since \\(X\\in\\mathbb{R}\\), we then have that \\(\\mathcal{S}(t)\\subseteq\\mathbb{R}\\). Ergo, \\(t^2\\ge 0\\). Additionally, for the \\(\\chi^2\\) Distribution, we required that \\(\\nu\\in\\mathbb{N}\\), so the entire distribution is then non-negative. However, because we have Gamma Functions, we can extend this distribution to non-integer values of \\(\\nu\\) as well.1 Thus, \\(f_T &gt; 0\\ \\forall t\\in\\mathbb{R}\\) and \\(\\nu &gt; 0\\).\n\n\n11.3.2 The Function Integrates to 1\nAs we argued above, the support of the random variable \\(t\\) is the entire Real line. We will first use the “symmetry trick” as we’ve seen elsewhere (that \\(f_T(t) = f_T(-t)\\)) to change the limits of integration. \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(t)} dF(t|\\nu) &= \\int_{\\mathcal{S}(t)} \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) \\nu^{-\\frac{1}{2}} }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\left( 1 + \\frac{t^2}{\\nu} \\right)^{-\\frac{\\nu + 1}{2}} dt \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\int_{-\\infty}^{\\infty} \\frac{1}{\\nu^{\\frac{1}{2}} \\left( 1 + \\frac{t^2}{\\nu} \\right)^{\\frac{\\nu + 1}{2}}} dt \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } 2 \\int_{0}^{\\infty} \\frac{1}{\\sqrt\\nu \\left( 1 + \\frac{t^2}{\\nu} \\right)^{\\frac{\\nu + 1}{2}}} dt.\n\\end{aligned}\n\\] Now we perform a substitution. Let \\(u = t^2/\\nu \\Rightarrow du = \\frac{2}{\\nu}tdt\\). The problem is that we don’t have anything that looks like a \\(tdt\\) in our integrand. But, we do know that if \\(t &gt; 0\\), then we can “solve” \\(u = t^2/\\nu\\) for \\(t\\). That is, we see that \\(t = +\\sqrt{u\\nu}\\), because \\(t\\) is positive. As a welcome side effect, our bounds of integration stay the same. Thus, \\[\n\\begin{aligned}\ndu &= \\frac{2}{\\nu}tdt \\\\\n&= \\frac{2}{\\nu}[\\sqrt{u\\nu}]dt \\\\\n&= 2\\sqrt{u}\\frac{\\sqrt\\nu}{\\nu}dt \\\\\n\\Longrightarrow \\frac{1}{2\\sqrt{u}}du &= \\frac{1}{\\sqrt\\nu}dt,\n\\end{aligned}\n\\] which, thankfully, does show up in our integrand.\nHence, we have \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(t)} dF(t|\\nu) &= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } 2 \\int_{t = 0}^{\\infty} \\frac{1}{\\left( 1 + \\frac{t^2}{\\nu} \\right)^{\\frac{\\nu + 1}{2}}} \\frac{1}{\\sqrt\\nu} dt \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } 2 \\int_{u = 0}^{\\infty} \\frac{1}{\\left( 1 + [u] \\right)^{\\frac{\\nu + 1}{2}}} \\left[\\frac{1}{2\\sqrt{u}}du\\right] \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\int_{0}^{\\infty} \\frac{1}{\\left( 1 + u \\right)^{\\frac{\\nu + 1}{2}}} \\frac{1}{\\sqrt{u}}du \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\int_{0}^{\\infty} \\frac{u^{-\\frac{1}{2}}}{\\left( 1 + u \\right)^{\\frac{\\nu}{2} + \\frac{1}{2}}} du \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\int_{0}^{\\infty} \\frac{u^{\\frac{1}{2} - 1}}{\\left( 1 + u \\right)^{\\frac{\\nu}{2} + \\frac{1}{2}}} du.\n\\end{aligned}\n\\]\nWe can now recognise this integral as an alternate form of the Beta Function2 with \\(a = \\frac{\\nu}{2}\\) and \\(b = \\frac{1}{2}\\). Thus, \\[\n\\begin{aligned}\n\\int_{\\mathcal{S}(t)} dF(t|\\nu) &= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\int_{0}^{\\infty} \\frac{u^{\\frac{1}{2} - 1}}{\\left( 1 + u \\right)^{\\frac{\\nu}{2} + \\frac{1}{2}}} du \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\mathcal{B}\\left(a = \\frac{\\nu}{2}, b = \\frac{1}{2}\\right) \\\\\n&= \\frac{ \\Gamma\\left(\\frac{\\nu + 1}{2}\\right) }{ \\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{\\nu}{2}\\right) } \\frac{ \\Gamma\\left(\\frac{\\nu}{2}\\right)\\Gamma\\left(\\frac{1}{2}\\right) }{  \\Gamma\\left(\\frac{\\nu}{2} + \\frac{1}{2}\\right) } \\\\\n&= 1.\n\\end{aligned}\n\\] Thus, \\(f_T(t|\\nu)\\) is a proper distribution.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#exercises",
    "href": "chapters/students_t_20250310.html#exercises",
    "title": "11  The Student’s t Distribution",
    "section": "11.4 Exercises",
    "text": "11.4 Exercises\n\nShow that as \\(\\nu\\to\\infty\\), \\(f_T(t|\\nu) \\to \\mathcal{N}(\\mu = 0, \\sigma^2 = 1)\\). Hint: you should read about Stirling’s Approximation: https://mathworld.wolfram.com/StirlingsApproximation.html.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/students_t_20250310.html#footnotes",
    "href": "chapters/students_t_20250310.html#footnotes",
    "title": "11  The Student’s t Distribution",
    "section": "",
    "text": "Think about what this might mean in practice, as the degrees of freedom measure the number of independent observations. See https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)#Effective_degrees_of_freedom↩︎\nFor a review, see the corresponding section in the Formal Foundations chapter on the Gamma and Beta Functions.↩︎",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>The Student's t Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html",
    "href": "chapters/f_20250310.html",
    "title": "12  The Central F Distribution",
    "section": "",
    "text": "12.1 Deriving the Distribution\nAs with the chapter on the Student’s \\(t\\) distribution, we will not include sections on the Method of Moments or Maximum Likelihood Estimators. Also, before we move on, please review the definition of the \\(\\chi^2\\) Distribution from that chapter. We begin by letting \\(X \\sim \\chi^2_{\\nu_x}\\) and \\(Y \\sim \\chi^2_{\\nu_y}\\) and by assuming that \\(X \\perp Y\\). The joint distribution of \\(X\\) and \\(Y\\) is \\[\nf_{X,Y}(x,y|\\nu_x, \\nu_y) = \\left[ \\frac{2^{-\\frac{\\nu_x}{2}}}{\\Gamma\\left(\\frac{\\nu_x}{2}\\right)} x^{\\frac{\\nu_x}{2} - 1} e^{-\\frac{x}{2}} \\right] \\left[ \\frac{2^{-\\frac{\\nu_y}{2}}}{\\Gamma\\left(\\frac{\\nu_y}{2}\\right)} y^{\\frac{\\nu_y}{2} - 1} e^{-\\frac{y}{2}} \\right].\n\\]\nSimilarly to our work on the Student’s \\(t\\) Distribution, we will make a creative bivariate substitution. Let \\(G = Y\\) be the nuisance parameter, and let \\[\nH = \\frac{X/\\nu_x}{Y/\\nu_y} \\Rightarrow \\frac{Y}{\\nu_y}H = \\frac{X}{\\nu_x} \\Rightarrow \\frac{\\nu_x}{\\nu_y}GH = X.\n\\] For the support of these variables, recall that \\(X,Y &gt; 0\\), so \\(H,G &gt; 0\\). For this substitution, the Jacobian Determinant is found by \\[\n\\begin{aligned}\n\\textbf{J} &= \\begin{bmatrix}\n  \\frac{\\partial X}{\\partial H} & \\frac{\\partial Y}{\\partial H} \\\\\n  \\frac{\\partial X}{\\partial G} & \\frac{\\partial Y}{\\partial G} \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  \\frac{\\partial}{\\partial H} \\frac{\\nu_x}{\\nu_y}GH & \\frac{\\partial}{\\partial H} G \\\\\n  \\frac{\\partial}{\\partial G} \\frac{\\nu_x}{\\nu_y}GH & \\frac{\\partial}{\\partial G} G \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n  \\frac{\\nu_x}{\\nu_y}G & 0 \\\\\n  \\frac{\\nu_x}{\\nu_y}H & 1 \\\\\n\\end{bmatrix} \\\\\n\\Longrightarrow \\det(\\textbf{J}) &= \\frac{\\nu_x}{\\nu_y}G(1) - (0)\\frac{\\nu_x}{\\nu_y}H \\\\\n&= \\frac{\\nu_x}{\\nu_y}G.\n\\end{aligned}\n\\]\nNow let’s dive in: \\[\nf_{X,Y}(x,y|\\nu_x, \\nu_y) = \\left\\{ \\frac{2^{-\\frac{\\nu_x}{2}}}{\\Gamma\\left(\\frac{\\nu_x}{2}\\right)} x^{\\frac{\\nu_x}{2} - 1} e^{-\\frac{x}{2}} \\right\\} \\left\\{ \\frac{2^{-\\frac{\\nu_y}{2}}}{\\Gamma\\left(\\frac{\\nu_y}{2}\\right)} y^{\\frac{\\nu_y}{2} - 1} e^{-\\frac{y}{2}} \\right\\}\n\\] implies that \\[\n\\begin{aligned}\nf_{X,Y}(h,g|\\nu_x, \\nu_y) &= \\left\\{ \\frac{2^{-\\frac{\\nu_x}{2}}}{\\Gamma\\left(\\frac{\\nu_x}{2}\\right)} \\left[\\frac{\\nu_x}{\\nu_y}gh\\right]^{\\frac{\\nu_x}{2} - 1} e^{-\\frac{1}{2}\\left[\\frac{\\nu_x}{\\nu_y}gh\\right]} \\right\\} \\left\\{ \\frac{2^{-\\frac{\\nu_y}{2}}}{\\Gamma\\left(\\frac{\\nu_y}{2}\\right)} [g]^{\\frac{\\nu_y}{2} - 1} e^{-\\frac{[g]}{2}} \\right\\} \\left[\\frac{\\nu_x}{\\nu_y}g\\right] \\\\\n&= \\frac{2^{-\\frac{\\nu_x}{2}}}{\\Gamma\\left(\\frac{\\nu_x}{2}\\right)} \\frac{2^{-\\frac{\\nu_y}{2}}}{\\Gamma\\left(\\frac{\\nu_y}{2}\\right)} \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2} - 1} \\left[\\frac{\\nu_x}{\\nu_y}\\right] \\left( g^{\\frac{\\nu_x}{2} - 1} g^{\\frac{\\nu_y}{2} - 1} g \\right) h^{\\frac{\\nu_x}{2} - 1} e^{-\\left( \\frac{\\nu_x}{2\\nu_y}gh + \\frac{g}{2} \\right)} \\\\\n&= \\frac{ 2^{-\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right)\\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} h^{\\frac{\\nu_x}{2} - 1} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} \\\\\n\\Longrightarrow f_H(h|\\nu_x, \\nu_y) &= \\int_{\\mathcal{S}(g)} \\frac{ 2^{-\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right)\\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} h^{\\frac{\\nu_x}{2} - 1} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} dg \\\\\n&= \\frac{ 2^{-\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right) \\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} h^{\\frac{\\nu_x}{2} - 1}  \\int_0^{\\infty} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} dg,\n\\end{aligned}\n\\] which we should recognise as the kernel of a Gamma Distribution with \\(\\alpha = \\frac{\\nu_x + \\nu_y}{2}\\) and \\(\\lambda = \\frac{\\nu_x}{2\\nu_y}h - \\frac{1}{2}\\). This kernel then integrates to \\[\n\\begin{aligned}\nI &= \\int_0^{\\infty} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} dg \\\\\n&= \\int_0^{\\infty} \\left\\{ \\frac{ \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) }{ \\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)^{\\frac{\\nu_x + \\nu_y}{2}} } \\right\\} \\left\\{ \\frac{ \\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)^{\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) } \\right\\} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} dg \\\\\n&= \\left\\{ \\frac{ \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) }{ \\left(\\frac{1}{2}\\right)^{\\frac{\\nu_x + \\nu_y}{2}} \\left( \\frac{\\nu_x}{\\nu_y}h + 1 \\right)^{\\frac{\\nu_x + \\nu_y}{2}} } \\right\\} \\int_0^{\\infty} \\left\\{ \\frac{ \\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)^{\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) } \\right\\} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} dg \\\\\n&= \\left\\{ \\frac{ 2^{\\frac{\\nu_x + \\nu_y}{2}} \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) }{ \\left( \\frac{\\nu_x}{\\nu_y}h + 1 \\right)^{\\frac{\\nu_x + \\nu_y}{2}} } \\right\\} [1].\n\\end{aligned}\n\\]\nTherefore, our marginal distribution simplifies to \\[\n\\begin{aligned}\nf_H(h|\\nu_x, \\nu_y) &= \\frac{ 2^{-\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right) \\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} h^{\\frac{\\nu_x}{2} - 1}  \\int_0^{\\infty} g^{\\frac{\\nu_x + \\nu_y}{2} - 1} e^{-g\\left( \\frac{\\nu_x}{2\\nu_y}h + \\frac{1}{2} \\right)} dg \\\\\n&= \\frac{ 2^{-\\frac{\\nu_x + \\nu_y}{2}} }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right) \\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} h^{\\frac{\\nu_x}{2} - 1} \\left\\{ \\frac{ 2^{\\frac{\\nu_x + \\nu_y}{2}} \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) }{ \\left( \\frac{\\nu_x}{\\nu_y}h + 1 \\right)^{\\frac{\\nu_x + \\nu_y}{2}} } \\right\\} \\\\\n&= \\frac{ 2^{-\\frac{\\nu_x + \\nu_y}{2}} 2^{\\frac{\\nu_x + \\nu_y}{2}} \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right) \\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} \\frac{ h^{\\frac{\\nu_x}{2} - 1} }{ \\left( \\frac{\\nu_x}{\\nu_y}h + 1 \\right)^{\\frac{\\nu_x + \\nu_y}{2}} } \\\\\n&= \\frac{ \\Gamma\\left( \\frac{\\nu_x + \\nu_y}{2} \\right) }{ \\Gamma\\left(\\frac{\\nu_x}{2}\\right) \\Gamma\\left(\\frac{\\nu_y}{2}\\right) } \\left[\\frac{\\nu_x}{\\nu_y}\\right]^{\\frac{\\nu_x}{2}} \\frac{ h^{\\frac{\\nu_x}{2} - 1} }{ \\left( \\frac{\\nu_x}{\\nu_y}h + 1 \\right)^{\\frac{\\nu_x + \\nu_y}{2}} },\n\\end{aligned}\n\\] which is the Central \\(\\mathcal{F}\\) Distribution with \\(\\nu_x,\\nu_y\\) degrees of freedom.1",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#example-random-samples",
    "href": "chapters/f_20250310.html#example-random-samples",
    "title": "12  The Central F Distribution",
    "section": "12.2 Example Random Samples",
    "text": "12.2 Example Random Samples\n\n\nCode\nset.seed(20150516)\n\n# F for a well-posed linear model [p = 5, n = 100]\nxWP &lt;- rf(n = 1000, df1 = 4, df2 = 99)\nsamplesWP_ls &lt;- list(\n  n10   = xWP[1:10],\n  n30   = xWP[1:30],\n  n60   = xWP[1:60],\n  n1000 = xWP\n)\n\n# F for a poorly-posed linear model [p = 25, n = 100]\nxPP &lt;- rf(n = 1000, df1 = 24, df2 = 99)\nsamplesPP_ls &lt;- list(\n  n10   = xPP[1:10],\n  n30   = xPP[1:30],\n  n60   = xPP[1:60],\n  n1000 = xPP\n)\n\nrange_num &lt;- range(c(xWP, xPP))\n\nrm(xWP, xPP)\n\n\n\n\nCode\nPlotSharedDensity &lt;- function(x, range_x, bandwidth = \"nrd0\") {\n  \n  xDens_ls &lt;- density(x, bw = bandwidth)\n  xHist_ls &lt;- hist(x, plot = FALSE)\n  yLargest_num &lt;- max(max(xDens_ls$y), max(xHist_ls$density))\n  \n  hist(\n    x, prob = TRUE,\n    xlim = range_x, ylim = c(0, yLargest_num)\n  )\n  lines(xDens_ls, col = 4, lwd = 2)\n  \n}\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesWP_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesWP_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesWP_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesWP_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))\n\n# , bandwidth = 0.005\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\n\nPlotSharedDensity(\n  x = samplesPP_ls$n10, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPP_ls$n30, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPP_ls$n60, range_x = range_num\n)\nPlotSharedDensity(\n  x = samplesPP_ls$n1000, range_x = range_num\n)\n\npar(mfrow = c(1, 1))",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#show-that-this-is-a-distribution",
    "href": "chapters/f_20250310.html#show-that-this-is-a-distribution",
    "title": "12  The Central F Distribution",
    "section": "12.3 Show that this is a Distribution",
    "text": "12.3 Show that this is a Distribution",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#exercises",
    "href": "chapters/f_20250310.html#exercises",
    "title": "12  The Central F Distribution",
    "section": "12.4 Exercises",
    "text": "12.4 Exercises\nTo be determined.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "chapters/f_20250310.html#footnotes",
    "href": "chapters/f_20250310.html#footnotes",
    "title": "12  The Central F Distribution",
    "section": "",
    "text": "https://texasgateway.org/resource/132-f-distribution-and-f-ratio↩︎",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Central F Distribution</span>"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "13  Apache License",
    "section": "",
    "text": "Copyright 2025 Gabriel J. Odom\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\nVersion 2.0, January 2004 &lt;http://www.apache.org/licenses/&gt;\n\n13.0.1 Terms and Conditions for use, reproduction, and distribution\n\n13.0.1.1 1. Definitions\n“License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\n“Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\n“Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\n“You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License.\n“Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\n“Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\n“Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\n“Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\n“Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.”\n“Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\n\n\n13.0.1.2 2. Grant of Copyright License\nSubject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.\n\n\n13.0.1.3 3. Grant of Patent License\nSubject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.\n\n\n13.0.1.4 4. Redistribution\nYou may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n\n(a) You must give any other recipients of the Work or Derivative Works a copy of this License; and\n(b) You must cause any modified files to carry prominent notices stating that You changed the files; and\n(c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\n(d) If the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\n\nYou may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\n\n\n13.0.1.5 5. Submission of Contributions\nUnless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.\n\n\n13.0.1.6 6. Trademarks\nThis License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.\n\n\n13.0.1.7 7. Disclaimer of Warranty\nUnless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\n\n\n13.0.1.8 8. Limitation of Liability\nIn no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\n\n\n13.0.1.9 9. Accepting Warranty or Additional Liability\nWhile redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\nEND OF TERMS AND CONDITIONS",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Apache License</span>"
    ]
  }
]