---
title: "The Beta Distribution"
author: "Gabriel J. Odom"
date: last-modified
format:
  html:
    embed-resources: false
    code-fold: true
knitr:
  opts_chunk:        ########## set global options ############
    collapse: true   # keep code from blocks together (if shown)
    echo: true       # show code
    message: true    # show messages
    warning: true    # show warnings
    error: true      # show error messages
    comment: ""      # don't show ## with printed output
    dpi: 100         # image resolution (typically 300 for publication)
    fig-width: 6.5   # figure width
    fig-height: 4.0  # figure height
    R.options:    
      digits: 3    # round to three digits
editor: source
---

```{r, tidyverse-tidymodels}
#| echo: false

library(conflicted)
suppressPackageStartupMessages(library(tidymodels))
tidymodels_prefer()
suppressPackageStartupMessages(library(tidyverse))

# suppress "`summarise()` has grouped output by " messages
options(dplyr.summarise.inform = FALSE)
```



## Formal Foundations


### Marginalizing a Likelihood
So far in our chapters, we have created quite a few likelihood functions. When we introduced likelihoods at the very beginning^[<https://gabriel.quarto.pub/stat-distributions-primer/chapters/bernoulli_20250310.html#the-likelihood-function>], we were careful to state that likelihoods are **not probability functions**. However, we know two things:

1) likelihood functions are always non-negative (recall that the products of any number of non-negative numbers will still be non-negative), and 
2) for well-behaved distributions, the area under the likelihood function will be finite (for a single finite data point from any well-behaved distribution, the parameter estimate for that data point will also be finite, and the product of finite values is finite).

Because the likelihood function is non-negative and the area under this curve is finite, we can turn it into a distribution by a process called finding the **marginal likelihood**^[<https://en.wikipedia.org/wiki/Marginal_likelihood>] and dividing the likelihood function by this marginal likelihood.

More formally, consider a probability function $f(x|\boldsymbol{\theta})$ with some finite but unknown parameter vector $\boldsymbol{\theta} \in\mathbb{R}_p$. Further, consider an independent and identical sample, $\textbf{x}$, of size $n$ from this distribution, represented as $x_i \overset{iid}{\sim} f(x|\boldsymbol\theta),\ i = 1, 2, \ldots, n$. The resulting likelihood is
$$
\mathcal{L}(\boldsymbol\theta|\textbf{x}) = \prod_{i = 1}^n f(x_i|\boldsymbol\theta).
$$
In order to transform $\mathcal{L}$ into a probability function, we must divide by the integral of $\mathcal{L}$ over the **support**^[<https://en.wikipedia.org/wiki/Support_(mathematics)#Support_of_a_distribution>] (all possible values) of $\boldsymbol\theta$, where $\mathcal{S}(\boldsymbol\theta)$ represents this support. For some distributions, especially those with a mixture of discrete and continuous parameters^[For example, the Negative Binomial distribution has parameter vector $\langle n,p \rangle$ when $n$ is unknown, where $p\in (0,1)$ and $n\in\mathbb{N}$.], this support, $\mathcal{S}(\boldsymbol\theta)$, may be quite complex. 

Given this setup, the marginal likelihood is defined as
$$
m(\boldsymbol\theta|\textbf{x}) = \int_{\mathcal{S}(\boldsymbol\theta)} \mathcal{L}(\boldsymbol\theta|\textbf{x}) \pi(\boldsymbol\theta) d\boldsymbol\theta.
$$
This $\pi(\boldsymbol\theta)$ may come as a surprise, as we haven't defined what it is. In **Bayesian Statistics**^[<https://en.wikipedia.org/wiki/Bayesian_statistics>], this $\pi(\boldsymbol\theta)$ is known as a **prior distribution**^[<https://en.wikipedia.org/wiki/Prior_probability>]. In the context of Bayesian inference, this prior distribution represents all the expert knowledge about the unknown parameter vector $\boldsymbol\theta$ that was known **before** the sample $\textbf{x}$ was collected. However, for this class, we will make the statement that we don't know much, if anything, about $\boldsymbol\theta$, so we set $\pi(\boldsymbol\theta) = 1$. Then, for our examples,
$$
m(\boldsymbol\theta|\textbf{x}) = \int_{\mathcal{S}(\boldsymbol\theta)} \mathcal{L}(\boldsymbol\theta|\textbf{x}) d\boldsymbol\theta.
$$

Finally, in order to transform the likelihood function of $\boldsymbol\theta$ into a probability function of $\boldsymbol\theta$, we will divide the likelihood by its integral. So, the probability function of $\boldsymbol\theta$ given the observed data $\textbf{x}$ is 
$$
f(\boldsymbol\theta|\textbf{x}) = \frac{\mathcal{L}(\boldsymbol\theta|\textbf{x})}{m(\boldsymbol\theta|\textbf{x})} = \frac{\mathcal{L}(\boldsymbol\theta|\textbf{x})}{\int_{\mathcal{S}(\boldsymbol\theta)} \mathcal{L}(\boldsymbol\theta|\textbf{x}) d\boldsymbol\theta}.
$$
We comment that distributions derived this way are true statistical distributions because they will always be non-negative, and an integral divided by itself equals 1 (so the total probability will be 1 by definition). In practice, this integral may be impossible to solve, so often numerical routines are used to estimate $f$ directly. Such topics are beyond the scope of this course.


### Fubini's Theorem
One small piece of theory we will need below is to swap the order of integration and summation (which we have done quite loosely up to this point). Basically, if we have two properties: 1) that $f \ge 0$, and $F < \infty$, then 
$$
\int \sum_n f_n(x) dx = \sum_n \int f_n(x) dx.
$$
This is an extension of **Fubini's Theorem**^[<https://en.wikipedia.org/wiki/Fubini%27s_theorem>] which allows us to swap the order of summation and integration, as long as the function $f$ is non-negative and the integral converges. Note that if $f$ is a probability function of a statistical distribution, then we have both properties automatically.

</br>



## Deriving the Distribution
We will begin this process by considering an independent and identical sample $\textbf{x}$, with size $n$, from an Binomial Distribution (with $p$ unknown); that is $x_i \overset{iid}{\sim} \text{Binom}(N, p),\ i = 1, 2, \ldots, n$. Further, we will take a play from the Negative Binomial distribution, and let $r_i$ and $k_i$ denote the number of successes and failures in Binomial sample $i$, respectively. Thus, 
$$
\begin{align}
\mathcal{L}(p|\textbf{x}) &= \prod_{i = 1}^n {N \choose x_i} p^{x_i} (1 - p)^{N - x_i} \\
\Longrightarrow \mathcal{L}(p|\textbf{r},\textbf{k}) &= \prod_{i = 1}^n {r_i + k_i \choose k_i} p^{k_i} (1 - p)^{r_i} \\
&= \left[ \prod_{i = 1}^n {r_i + k_i \choose k_i} \right] \times \left[ \prod_{i = 1}^n p^{k_i} \right] \times \left[ \prod_{i = 1}^n (1 - p)^{r_i} \right] \\
&= \left[ \prod_{i = 1}^n {r_i + k_i \choose k_i} \right] p^{S_k} (1 - p)^{S_r},
\end{align}
$$
where
$$
S_k = \sum_{i = 1}^n k_i,\ \text{and}\ S_r = \sum_{i = 1}^n r_i.
$$

As we discussed in our Formal Foundations section, we can **marginalize** this likelihood to create a probability function $f$, of the parameter $p$, given the **sufficient statistics**^[<https://en.wikipedia.org/wiki/Sufficient_statistic>] of the observed data $S_k$ and $S_r$. That is,
$$
\begin{align}
f(p|S_r, S_k) &= \frac{\mathcal{L}(p|\textbf{r},\textbf{k})}{m(p|\textbf{r},\textbf{k})} \\
&= \frac{\mathcal{L}(p|\textbf{r},\textbf{k})}{\int_{\mathcal{S}(p)} \mathcal{L}(p|\textbf{r},\textbf{k}) dp } \\
&= \frac{ \left[ \prod_{i = 1}^n {r_i + k_i \choose k_i} \right] p^{S_k} (1 - p)^{S_r} }{\int_0^1 \left[ \prod_{i = 1}^n {r_i + k_i \choose k_i} \right] p^{S_k} (1 - p)^{S_r} dp } \\
&= \frac{ \left[ \prod_{i = 1}^n {r_i + k_i \choose k_i} \right] p^{S_k} (1 - p)^{S_r} }{ \left[ \prod_{i = 1}^n {r_i + k_i \choose k_i} \right] \int_0^1 p^{S_k} (1 - p)^{S_r} dp } \\
&= \frac{ p^{S_k} (1 - p)^{S_r} }{ \int_0^1 p^{S_k} (1 - p)^{S_r} dp } \\
&= \frac{ p^{(S_k + 1) - 1} (1 - p)^{(S_r + 1) - 1} }{ \int_0^1 p^{(S_k + 1) - 1} (1 - p)^{(S_r + 1) - 1} dp } \\
&= \frac{ p^{\alpha - 1} (1 - p)^{\beta - 1} }{ \int_0^1 p^{\alpha - 1} (1 - p)^{\beta - 1} dp },
\end{align}
$$
where $\alpha = S_k + 1$ (1 plus the total number of failures in the $n$ Binomial trials) and $\beta = S_r + 1$ (1 plus the total number of successes in the $n$ Binomial trials).

This integral in the denominator should look familiar: it is the definition of the **Complete Beta Function**, which we covered in the "Formal Foundatations" chapter on the Gamma and Beta functions. Thus,
$$
\begin{align}
f(p|S_r, S_k) &= \frac{ p^{\alpha - 1} (1 - p)^{\beta - 1} }{ \int_0^1 p^{\alpha - 1} (1 - p)^{\beta - 1} dp } \\
&= \left[ \int_0^1 p^{\alpha - 1} (1 - p)^{\beta - 1} dp \right]^{-1} p^{\alpha - 1} (1 - p)^{\beta - 1} \\
&= \left[ \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)} \right]^{-1} p^{\alpha - 1} (1 - p)^{\beta - 1} \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha - 1} (1 - p)^{\beta - 1},
\end{align}
$$
which is the standard form of the Beta Distribution with $p\in(0,1)$.

What are the allowed values for $\alpha$ and $\beta$? Because we derived the Beta Distribution as the probability function of the Binomial Distribution's parameter $p$, we had an added restriction that $S_r$ and $S_k$ were non-negative integers (that is, $S_r,\ S_k \in 0\cup\mathbb{N} = 0, 1, 2, 3, \ldots$). This would impose the restriction that $\alpha = S_k + 1$ and $\beta = S_r + 1$ must be elements of $\mathbb{N} = 1, 2, 3, \ldots$ (not including 0). However, notice that the form of $f$ above uses Gamma functions, so it does not require that $\alpha$ and $\beta$ be restricted to the integers. What would it mean to have fractional/decimal counts of successes or failures? Well, some games allow for ties, which could be counted as half a success and half a failure. Other experiments could involve **Likert-scale**^[<https://en.wikipedia.org/wiki/Likert_scale>] responses, where "strongly disagree" maps to 0, "strongly agree" maps to 1, but the values in between map to various fractions between 0 and 1.^[See this discussion for more details: <https://math.stackexchange.com/questions/4244890/intuition-of-beta-distribution-with-less-than-one-parameters>] Thus, we state that $\alpha$ and $\beta$ simply need to be non-negative real numbers ($\alpha,\beta\in\mathbb{R}^+$).



</br>



## Example Random Samples

```{r, random-sample}
set.seed(20150516)

xSymm <- rbeta(n = 500, shape1 = 10, shape2 = 10)
samplesSymm_ls <- list(
  n10  = xSymm[1:10],
  n30  = xSymm[1:30],
  n60  = xSymm[1:60],
  n500 = xSymm
)

xSkew <- rbeta(n = 500, shape1 = 5, shape2 = 1.5)
samplesSkew_ls <- list(
  n10  = xSkew[1:10],
  n30  = xSkew[1:30],
  n60  = xSkew[1:60],
  n500 = xSkew
)

range_num <- c(0, 1)

rm(xSymm, xSkew)
```

```{r}
#| label: shared-density-plotting-function
PlotSharedDensity <- function(x, range_x, bandwidth = "nrd0") {
  
  xDens_ls <- density(x, bw = bandwidth)
  xHist_ls <- hist(x, plot = FALSE)
  yLargest_num <- max(max(xDens_ls$y), max(xHist_ls$density))
  
  hist(
    x, prob = TRUE,
    xlim = range_x, ylim = c(0, yLargest_num)
  )
  lines(xDens_ls, col = 4, lwd = 2)
  
}
```


```{r}
#| label: random-sample-hist-symm
#| fig-show: "hold"

par(mfrow = c(2, 2))

PlotSharedDensity(
  x = samplesSymm_ls$n10, range_x = range_num
)
PlotSharedDensity(
  x = samplesSymm_ls$n30, range_x = range_num
)
PlotSharedDensity(
  x = samplesSymm_ls$n60, range_x = range_num
)
PlotSharedDensity(
  x = samplesSymm_ls$n500, range_x = range_num
)

par(mfrow = c(1, 1))

# , bandwidth = 0.005
```

```{r}
#| label: random-sample-hist-diffuse
#| fig-show: "hold"

par(mfrow = c(2, 2))

PlotSharedDensity(
  x = samplesSkew_ls$n10, range_x = range_num
)
PlotSharedDensity(
  x = samplesSkew_ls$n30, range_x = range_num
)
PlotSharedDensity(
  x = samplesSkew_ls$n60, range_x = range_num
)
PlotSharedDensity(
  x = samplesSkew_ls$n500, range_x = range_num
)

par(mfrow = c(1, 1))
```


</br>



## Show that this is a Distribution
Given all our work to derive this distribution, we can show that it is a distribution directly. First, note that because $p\in(0,1)$ and $\alpha,\beta > 0$, we have that $f(p|\alpha,\beta) > 0$. Then, starting with the Riemann-Stieltjes integral and applying the definition of the **Complete Beta Function**^[Covered in our Formal Foundations chapter on the Gamma and Beta functions] we have
$$
\begin{align}
\int_{\mathcal{S}(p)} dF(p|\alpha,\beta) &= \int_0^1 \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha - 1} (1 - p)^{\beta - 1} dp \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \int_0^1 p^{\alpha - 1} (1 - p)^{\beta - 1} dp \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \left[ \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)} \right] \\
&= 1.
\end{align}
$$
Therefore, the Beta Distribution is a proper distribution.


</br>



## Derive the Moment Generating Function
When I was in grad school, some of my professors ignored deriving the Moment Generating Function of the Beta Distribution. When you look at its form in the back of a statistical theory textbook, you can probably see why (it's unpleasant). However, we are going to derive it anyway. Many derivations you might find online involve using the **Kummer's Function of the First Kind**^[<https://mathworld.wolfram.com/ConfluentHypergeometricFunctionoftheFirstKind.html>], which requires even more theoretical foundations to cover than I would ever want to write. Instead, we will opt for a longer derivation, but one that uses Formal Foundations that we have already covered, namely the Riemann-Stieljes Integral (that you should be comfortable with by now), the **MacLaurin Series**^[<https://gabriel.quarto.pub/stat-distributions-primer/chapters/negative_binomial_20250310.html#taylormaclaurin-series>] of $e^x$, swapping the order of integration and summation via **Fubini's Theorem**,^[<https://en.wikipedia.org/wiki/Fubini%27s_theorem>] the definition of the **Complete Beta Function**,^[<https://gabriel.quarto.pub/stat-distributions-primer/chapters/theory_gamma_function_20250707.html#the-complete-beta-function>] and the **Continued Recurrence Property** of the Gamma Function.^[<https://gabriel.quarto.pub/stat-distributions-primer/chapters/theory_gamma_function_20250707.html#the-gamma-continued-recurrence-equation>]

Let's begin:
$$
\begin{aligned}
M_p(t) &= \int_{\mathcal{S}(p)} e^{tp}dF(p|\alpha,\beta) \\
&= \int_0^1 e^{tp} \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha - 1} (1 - p)^{\beta - 1} dp \\
&\qquad\text{\emph{MacLaurin Series of }} e^{tp} \text{\emph{...}} \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \int_0^1 \left[ \sum_{k = 0}^{\infty} \frac{(tp)^k}{k!} \right] p^{\alpha - 1} (1 - p)^{\beta - 1} dp \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \int_0^1 \sum_{k = 0}^{\infty} \frac{t^k}{k!} p^k p^{\alpha - 1} (1 - p)^{\beta - 1} dp \\
&\qquad\text{\emph{Fubini's Theorem...}} \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \sum_{k = 0}^{\infty} \int_0^1 \frac{t^k}{k!} p^k p^{\alpha - 1} (1 - p)^{\beta - 1} dp \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \sum_{k = 0}^{\infty} \frac{t^k}{k!} \int_0^1 p^{\alpha + k - 1} (1 - p)^{\beta - 1} dp \\
&\qquad\text{\emph{Defn. of Beta Function...}} \\
&= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \sum_{k = 0}^{\infty} \frac{t^k}{k!} \left[ \frac{\Gamma(\alpha + k)\Gamma(\beta)}{\Gamma(\alpha + \beta + k)} \right] \\
&= \sum_{k = 0}^{\infty} \frac{t^k}{k!} \left[ \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha + \beta + k)} \frac{\Gamma(\alpha + k)}{\Gamma(\alpha)} \right] \\
&\qquad\text{\emph{``Peel off'' the first summand...}} \\
&= \frac{t^0}{0!} \left[ \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha + \beta + 0)} \frac{\Gamma(\alpha + 0)}{\Gamma(\alpha)} \right] + \sum_{k = 1}^{\infty} \frac{t^k}{k!} \left[ \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha + \beta + k)} \frac{\Gamma(\alpha + k)}{\Gamma(\alpha)} \right] \\
&\qquad\text{\emph{Gamma Function Recurrence Property...}} \\
&= 1 + \sum_{k = 1}^{\infty} \frac{t^k}{k!} \left[ \frac{\Gamma(\alpha + \beta)}{ \prod_{j = 0}^{k - 1} (\alpha + \beta + j) \Gamma(\alpha + \beta) } \frac{ \prod_{j = 0}^{k - 1} (\alpha + j) \Gamma(\alpha) }{\Gamma(\alpha)} \right] \\
&= 1 + \sum_{k = 1}^{\infty} \frac{t^k}{k!} \left[ \frac{1}{ \prod_{j = 0}^{k - 1} (\alpha + \beta + j) } \frac{ \prod_{j = 0}^{k - 1} (\alpha + j) }{1} \right] \\
&= 1 + \sum_{k = 1}^{\infty} \frac{t^k}{k!} \left[ \prod_{j = 0}^{k - 1} \frac{\alpha + j}{\alpha + \beta + j} \right],
\end{aligned}
$$
which is the standard form of the Beta Distribution's MGF. We "peeled off" the first summand (incrementing from $k = 0$ to $k = 1$) to make taking the first derivative easier. When we are ready to take the second derivative, we will "peel off" the second summand (incrementing from $k = 1$ to $k = 2$) then.


</br>



## Method of Moments Estimates from Observed Data
Let's generate some random data...


### $\mathbb{E}[k]$


### $\mathbb{E}[k^2]$ and $\text{Var}[k]$


### Solving the System


</br>



## Maximum Likelihood Estimators


</br>



## Exercises

To be determined.


## Footnotes 


